{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activate line execution\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# general\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "import pickle\n",
    "\n",
    "# plotly\n",
    "import plotly.express as px  # (version 4.7.0 or higher)\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# import custom libraries\n",
    "import sys\n",
    "sys.path.append(\"C:\\\\DATA\\\\Tasks\\\\lib\\\\hk\")\n",
    "import hk_utils\n",
    "\n",
    "# folder paths\n",
    "ADD_DATA = \"C:\\\\DATA\\\\data\\\\raw\\\\mimic4\\\\lookup\\\\\"\n",
    "ADD_DATA_proc = \"C:/DATA/data/processed/\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries for THP\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import transformer.Constants as Constants\n",
    "import Utils\n",
    "\n",
    "# from preprocess.Dataset import get_dataloader, get_dataloader2\n",
    "# from transformer.Models import Transformer\n",
    "# from transformer.hk_transformer import Transformer\n",
    "from tqdm import tqdm\n",
    "\n",
    "# from torchinfo import summary\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "# torch.cuda.empty_cache()\n",
    "# torch.cuda.memory_allocated()\n",
    "# torch.cuda.memory_reserved()\n",
    "\n",
    "from sklearn import metrics\n",
    "# from hk_pytorch import save_checkpoint,load_checkpoint\n",
    "# import hk_pytorch\n",
    "\n",
    "\n",
    "# from custom2 import myparser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_add = 'example.pkl'\n",
    "str_add = 'example_so_new.pkl'\n",
    "with open(str_add, 'rb') as f:\n",
    "    example = pickle.load(f)\n",
    "\n",
    "num_samples = 100\n",
    "i_batch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example.keys()\n",
    "for key,item in example.items():\n",
    "    print(key,\"\\t\\t\\t\",item.shape)\n",
    "\n",
    "# diff_time = (example['event_time'][:, 1:] - example['event_time'][:, :-1]) *  example['non_pad_mask'][:, 1:] # [B,L-1]\n",
    "# unbiased_integral =  torch.sum(example['all_lambda'], dim=2) / num_samples * diff_time.unsqueeze(-1) # [B,L-1,K] \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example['type_mask'].shape\n",
    "example['type_mask'].transpose(0,2,1)[:,None,:,:].shape\n",
    "example['self_attn'].shape\n",
    "E_t = example['type_mask'].transpose(0,2,1)[:,None,:,:]\n",
    "E = example['type_mask'][:,None,:,:]\n",
    "att_agg = E_t @ example['self_attn'] @ E\n",
    "att_agg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = example['all_lambda'].shape[-1]\n",
    "example['all_lambda'].shape\n",
    "\n",
    "def cal_intensity_time(all_lambda, int_time, example):\n",
    "    i = all_lambda # [B,L-1,ns,K]\n",
    "    i = i * example['non_pad_mask'][:,:-1,None,None]\n",
    "    i = i[i_batch].reshape(-1,K)\n",
    "    # i.shape\n",
    "\n",
    "    # int_time.shape\n",
    "    t = (example['event_time'][:,[0],None]+int_time) # [B,L,ns]\n",
    "    # t = t * example['non_pad_mask'][:,:-1,None]\n",
    "    t = t[i_batch].flatten() # [L*ns]\n",
    "    # t.shape\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    all_lambda_int = np.sum(all_lambda, axis=2) / num_samples # [B,L-1,K]\n",
    "    all_lambda_int.shape\n",
    "\n",
    "\n",
    "\n",
    "    # i_batch=2\n",
    "    # example['event_time'][:,0]\n",
    "\n",
    "    t = (example['event_time'][i_batch,0,None]+int_time[i_batch]) # [B,L-1,ns]\n",
    "\n",
    "    t = t.flatten() # [L*ns]\n",
    "\n",
    "    return i,t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vis intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "\n",
    "# t[::10]\n",
    "# i[::10,0]\n",
    "\n",
    "# go.Figure(data=go.Scatter(x=t[::10], y=i[::10,0], mode='markers')).show()\n",
    "# go.Figure(data=go.Scatter(x=t[::10], y=i[::10,2], mode='markers')).show()\n",
    "K_limit = K\n",
    "fig = make_subplots(rows=int(K_limit/3)+1, cols=3, shared_xaxes=True)\n",
    "step=1\n",
    "\n",
    "i, t = cal_intensity_time(example['all_lambda'], example['int_time'], example)\n",
    "i_B, t = cal_intensity_time(example['all_lambda_B'], example['int_time'], example)\n",
    "i_H, t = cal_intensity_time(example['all_lambda_H'], example['int_time'], example)\n",
    "i_BH, t = cal_intensity_time(example['all_lambda_BH'], example['int_time'], example)\n",
    "\n",
    "for ii in range(K_limit):\n",
    "    \n",
    "    row = int(ii/3)+1\n",
    "    col = ii%3 + 1\n",
    "\n",
    "    # plot intensity\n",
    "    x = t[::step]\n",
    "\n",
    "    ind = x.argsort()\n",
    "    x=x[ind]\n",
    "    # x.min()\n",
    "    \n",
    "    y=i[::step,ii][ind]\n",
    "    _ = fig.add_trace(\n",
    "        go.Scatter(x=x, y=y, mode='lines',marker_color='black', name='int'),\n",
    "        row=row, col=col,\n",
    "    )\n",
    "    \n",
    "    y=i_B[::step,ii][ind]\n",
    "    _ = fig.add_trace(\n",
    "        go.Scatter(x=x, y=y, mode='lines',marker_color='yellow', name='int_B'),\n",
    "        row=row, col=col,\n",
    "    )\n",
    "    \n",
    "    y=i_H[::step,ii][ind]\n",
    "    _ = fig.add_trace(\n",
    "        go.Scatter(x=x, y=y, mode='lines',marker_color='orange', name='int_H'),\n",
    "        row=row, col=col,\n",
    "    )\n",
    "    \n",
    "    y=i_BH[::step,ii][ind]\n",
    "    _ = fig.add_trace(\n",
    "        go.Scatter(x=x, y=y, mode='lines',marker_color='purple', name='int_BH'),\n",
    "        row=row, col=col,\n",
    "    )\n",
    "    \n",
    "    # example['event_time'][i_batch,:3]\n",
    "    # x\n",
    "    # y\n",
    "    \n",
    "    # print(np.trapz(y,x=x), all_lambda_int[i_batch,0,ii].sum(), example['unbiased_integral'][i_batch,0,ii].sum() )\n",
    "    # term\n",
    "    print(np.trapz(y,x=x)/ example['unbiased_integral'][i_batch,:,ii].sum())\n",
    "\n",
    "    # plot occured events\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    x = example['event_time'][i_batch][example['event_type'][i_batch]==ii+1]\n",
    "\n",
    "    y = example['type_lambda'][i_batch][example['event_type'][i_batch]==ii+1].flatten()\n",
    "    _ = fig.add_trace(\n",
    "        go.Scatter(x=x, y=y, mode='markers',marker_color='black', name='type_lam'),\n",
    "        row=row, col=col\n",
    "    )\n",
    "    \n",
    "    y = example['type_lambda_B'][i_batch][example['event_type'][i_batch]==ii+1].flatten() \n",
    "    _ = fig.add_trace(\n",
    "        go.Scatter(x=x, y=y, mode='markers',marker_color='yellow', name='type_lam_B'),\n",
    "        row=row, col=col\n",
    "    )\n",
    "    \n",
    "    y = example['type_lambda_H'][i_batch][example['event_type'][i_batch]==ii+1].flatten() \n",
    "    _ = fig.add_trace(\n",
    "        go.Scatter(x=x, y=y, mode='markers',marker_color='orange', name='type_lam_H'),\n",
    "        row=row, col=col\n",
    "    )\n",
    "\n",
    "    y = example['type_lambda_BH'][i_batch][example['event_type'][i_batch]==ii+1].flatten() \n",
    "    _ = fig.add_trace(\n",
    "        go.Scatter(x=x, y=y, mode='markers',marker_color='purple', name='type_lam_BH'),\n",
    "        row=row, col=col\n",
    "    )\n",
    "\n",
    "# for y in example['event_time'][i_batch]:\n",
    "#     type(y)\n",
    "#     _ = fig.add_vline(x=y,row='all', col=1)\n",
    "\n",
    "_ = fig.update_xaxes(matches='x')\n",
    "_ = fig.update_layout(hovermode=\"x unified\")\n",
    "fig.show()\n",
    "fig.write_html(ADD_DATA+\"/intensity.html\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vis att"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 5\n",
    "max_len = example['self_attn'].shape[-1]\n",
    "nheads = example['self_attn'].shape[1]\n",
    "\n",
    "\n",
    "fig = make_subplots(rows=1, cols=nheads,shared_xaxes=True)\n",
    "\n",
    "for i_head in range(nheads):\n",
    "    \n",
    "    mat = example['self_attn'][i_batch,i_head] * (~example['slf_attn_mask'][i_batch])  \n",
    "    \n",
    "    mat = mat * (np.arange(mat.shape[0])+1)[:,None]\n",
    "    \n",
    "    mat = mat[:max_len,:max_len]\n",
    "\n",
    "    # mat[mat<1.05]=0\n",
    "    labels = [f\"E{i}_{event}\" for i,event in enumerate(example['event_type'][i_batch])] [:max_len]\n",
    "    # mat = mat / np.sum(mat,axis=1,keepdims=True)\n",
    "    \n",
    "    \n",
    "    # fig2 = px.imshow(mat,x = labels,y = labels).update_layout(width=500, height=500)\n",
    "    # fig2.show()\n",
    "    x = labels.copy()\n",
    "    y = labels.copy()\n",
    "    \n",
    "    y.reverse()\n",
    "\n",
    "\n",
    "    mat2= np.flip(mat,axis=0)\n",
    "    _ = fig.add_trace(\n",
    "        go.Heatmap(z=mat2, x= x, y=y),\n",
    "        row = 1, col=i_head+1,\n",
    "        \n",
    "    )\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# #     # _ = fig.add_trace(go.Heatmap(z=mat),\n",
    "# #     #     row=i_head+1, col=1).update_layout(width=500, height=500)\n",
    "# # # fig.update_layout(width=500, height=500)\n",
    "# # # fig.show()\n",
    "\n",
    "fig.write_html(ADD_DATA+\"/att.html\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vis aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = example['event_time'].flatten()\n",
    "event_gap = (example['event_time'][:,1:] - example['event_time'][:,:-1] ) * example['non_pad_mask'][:,1:]\n",
    "# event_gap[0]\n",
    "# example['event_time'][0]\n",
    "event_gap= event_gap[event_gap>0]\n",
    "\n",
    "event_gap.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.arange(10)\n",
    "y=np.arange(9,-1,step=-1)\n",
    "x\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "fig = make_subplots(rows=int(K_limit/3)+1, cols=3, shared_xaxes=True)\n",
    "\n",
    "example['type_mask'].shape\n",
    "example['type_mask'].transpose(0,2,1)[:,None,:,:].shape\n",
    "example['self_attn'].shape\n",
    "E_t = example['type_mask'].transpose(0,2,1)[:,None,:,:]\n",
    "E = example['type_mask'][:,None,:,:]\n",
    "att_agg = E_t @ example['self_attn'] @ E\n",
    "att_agg.shape\n",
    "norm = (E_t @ E)\n",
    "norm.shape\n",
    "norm = norm.sum(0).sum(0)\n",
    "np.diag(norm)\n",
    "(np.diag(norm) / np.diag(norm).sum() *100).astype(int)\n",
    "# np.diag(norm[0,0])\n",
    "# norm[0,0]\n",
    "# np.linalg.inv(norm[0,0])\n",
    "\n",
    "list_temp = [[1., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
    "       [0., 1., 0., 0., 1., 0., 0., 0., 0., 1.],\n",
    "       [0., 0., 1., 0., 1., 1., 0., 0., 0., 0.],\n",
    "       [0., 0., 0., 1., 0., 0., 0., 0., 1., 0.],\n",
    "       [0., 0., 0., 0., 1., 0., 1., 0., 0., 0.],\n",
    "       [0., 0., 0., 1., 0., 1., 0., 0., 1., 0.],\n",
    "       [0., 0., 0., 0., 0., 1., 1., 0., 1., 0.],\n",
    "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
    "       [0., 1., 0., 0., 0., 0., 1., 0., 1., 0.],\n",
    "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 1.]]\n",
    "gt = np.array(list_temp)\n",
    "\n",
    "gt= np.ones((K,K))\n",
    "\n",
    "\n",
    "gt[gt>0]=1\n",
    "gt\n",
    "\n",
    "x=np.arange(K)\n",
    "y=np.arange(K-1,-1,step=-1)\n",
    "x=[str(i) for i in x]\n",
    "y=[str(i) for i in y]\n",
    "fig = make_subplots(rows=3, cols=4, shared_xaxes=True)\n",
    "\n",
    "for i_head in range(nheads):\n",
    "    \n",
    "\n",
    "\n",
    "    print('att_agg')\n",
    "    mat = att_agg[i_batch,i_head,:,:]\n",
    "    mat = att_agg[:,i_head,:,:].sum(0)  # sum across batches\n",
    "    _ = fig.add_trace(\n",
    "        go.Heatmap(z=np.flip(mat, axis=0), x=x, y=y),\n",
    "        row = 1, col=i_head+1\n",
    "\n",
    "    )\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(gt.flatten(), mat.flatten(), pos_label=1)\n",
    "    metrics.auc(fpr, tpr) \n",
    "\n",
    "    # print('att_agg new')\n",
    "    # mat =  np.linalg.inv(norm)[None,:,:] @ att_agg[:,i_head,:,:] @ np.linalg.inv(norm)[None,:,:]*1000\n",
    "    # mat = mat.sum(0)\n",
    "    # _ = fig.add_trace(\n",
    "    #     go.Heatmap(z=np.flip(mat, axis=0), x=x, y=y),\n",
    "    #     row = 2, col=i_head+1,\n",
    "        \n",
    "    # )    \n",
    "    # fpr, tpr, thresholds = metrics.roc_curve(gt.flatten(), mat.flatten(), pos_label=1)\n",
    "    # metrics.auc(fpr, tpr)  \n",
    "\n",
    "\n",
    "\n",
    "print('A_reg')\n",
    "mat =  example['A_reg']\n",
    "\n",
    "_ = fig.add_trace(\n",
    "    go.Heatmap(z=np.flip(mat, axis=0), x=x, y=y),\n",
    "    row = 3, col=1\n",
    ")\n",
    "fpr, tpr, thresholds = metrics.roc_curve(gt.flatten(), mat.flatten(), pos_label=1)\n",
    "metrics.auc(fpr, tpr)\n",
    "\n",
    "print('gt')\n",
    "mat =  gt\n",
    "_ = fig.add_trace(\n",
    "    go.Heatmap(z=np.flip(mat, axis=0), x=x, y=y),\n",
    "    row = 3, col=2\n",
    ")\n",
    "\n",
    "\n",
    "_ = fig.update_xaxes(matches='x')\n",
    "fig.show()\n",
    "\n",
    "\n",
    "fig.write_html(ADD_DATA+\"/inf.html\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vis masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# self attention mask\n",
    "mat = (~example['slf_attn_mask'][i_batch]).astype(int) [:max_len,:max_len]\n",
    "fig = px.imshow(mat,x = labels,y = labels).update_layout(width=500, height=500)\n",
    "fig.show()\n",
    "\n",
    "# regulariztion mask\n",
    "mat = (example['mask2'][i_batch]) [:max_len,:max_len]\n",
    "fig = px.imshow(mat,x = labels,y = labels).update_layout(width=500, height=500)\n",
    "fig.show()\n",
    "\n",
    "# A_reg\n",
    "mat = example['A_reg']\n",
    "fig = px.imshow(mat).update_layout(width=500, height=500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('dashVis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c2f29e1a05e7eec16e11fbddc27661320510c37e25360333d406961ee2486f09"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
