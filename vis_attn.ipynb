{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activate line execution\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# general\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "# import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "import pickle\n",
    "\n",
    "# plotly\n",
    "import plotly.express as px  # (version 4.7.0 or higher)\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import custom libraries\n",
    "import sys\n",
    "# sys.path.append(\"C:\\\\DATA\\\\Tasks\\\\lib\\\\hk\")\n",
    "# import hk_utils\n",
    "\n",
    "# folder paths\n",
    "ADD_DATA = \"C:\\\\DATA\\\\data\\\\raw\\\\mimic4\\\\lookup\\\\\"\n",
    "ADD_DATA_proc = \"C:/DATA/data/processed/\"\n",
    "\n",
    "\n",
    "PATH_PAPER = \"C:\\\\DATA\\\\Tasks\\\\220704\\\\Alternate-Transactions-Articles-LaTeX-template\\\\images\\\\\"\n",
    "\n",
    "\n",
    "PATH_SYS=\"/mlodata1/hokarami/tedam/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/paper2022/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# libraries for THP\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import transformer.Constants as Constants\n",
    "import Utils\n",
    "\n",
    "# from preprocess.Dataset import get_dataloader, get_dataloader2\n",
    "# from transformer.Models import Transformer\n",
    "# from transformer.hk_transformer import Transformer\n",
    "from tqdm import tqdm\n",
    "\n",
    "# from torchinfo import summary\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "# torch.cuda.empty_cache()\n",
    "# torch.cuda.memory_allocated()\n",
    "# torch.cuda.memory_reserved()\n",
    "\n",
    "from sklearn import metrics\n",
    "# from hk_pytorch import save_checkpoint,load_checkpoint\n",
    "# import hk_pytorch\n",
    "\n",
    "\n",
    "# from custom2 import myparser\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Main\n",
    "import webbrowser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sudo conda install -c conda-forge dash --name paper2022\n",
    "# sudo conda install -c conda-forge jupyter-dash --name paper2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsnecuda import TSNE\n",
    "from MulticoreTSNE import MulticoreTSNE as TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install wandb -qqq\n",
    "import wandb\n",
    "# wandb.login()\n",
    "api = wandb.Api()\n",
    "import os\n",
    "\n",
    "os.environ[\"WANDB_API_KEY\"] = \"0f780ac8a470afe6cb7fc474ff3794772c660465\"\n",
    "\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"jup_res\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import base64\n",
    "import pickle\n",
    "import gzip\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from jupyter_dash import JupyterDash\n",
    "from dash import dcc, html, Input, Output, no_update\n",
    "import dash_bootstrap_components as dbc\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from PIL import ImageDraw, Image\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Helper functions\n",
    "def np_image_to_base64(im_matrix,scale=4):\n",
    "\n",
    "    im_matrix = np.repeat(np.repeat(im_matrix,scale,axis=0),scale,axis=1)\n",
    "    im = Image.fromarray(im_matrix)\n",
    "    buffer = io.BytesIO()\n",
    "    im.save(buffer, format=\"jpeg\")\n",
    "    encoded_image = base64.b64encode(buffer.getvalue()).decode()\n",
    "    im_url = \"data:image/jpeg;base64, \" + encoded_image\n",
    "    return im_url\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def binary_matrix_to_image(binary_matrix, grid_size=8, border_size=1):\n",
    "    # Calculate the size of the output image based on the size of the binary matrix\n",
    "    height, width = binary_matrix.shape[:2]\n",
    "    image_width = width * grid_size + (width + 1) * border_size\n",
    "    image_height = height * grid_size + (height + 1) * border_size\n",
    "    \n",
    "    # Create a new image and a draw object to draw the grid and borders\n",
    "    image = Image.new('RGB', (image_width, image_height), color='black')\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    \n",
    "    # Draw the white grids\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            if binary_matrix[i, j] == 1:\n",
    "                x1 = j * (grid_size + border_size) + border_size\n",
    "                y1 = i * (grid_size + border_size) + border_size\n",
    "                x2 = x1 + grid_size\n",
    "                y2 = y1 + grid_size\n",
    "                draw.rectangle((x1, y1, x2, y2), fill='white')\n",
    "                \n",
    "    \n",
    "    # Draw the black borders\n",
    "    for i in range(height + 1):\n",
    "        y = i * (grid_size + border_size)\n",
    "        draw.line((0, y, image_width, y), fill='white', width=border_size)\n",
    "        \n",
    "    for j in range(width + 1):\n",
    "        x = j * (grid_size + border_size)\n",
    "        draw.line((x, 0, x, image_height), fill='white', width=border_size)\n",
    "        \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_rgb(num, **rgb_params):\n",
    "    \n",
    "    \n",
    "    \n",
    "    if len(rgb_params)>0:\n",
    "\n",
    "        normalized = (num - rgb_params['offset'])/rgb_params['range']\n",
    "\n",
    "        \n",
    "        # Map to a color between blue, gray, and red\n",
    "        rgb_lower = rgb_params['rgb_lower']\n",
    "        rgb_middle = rgb_params['rgb_middle']\n",
    "        rgb_upper = rgb_params['rgb_upper']\n",
    "    else:\n",
    "    \n",
    "        # Normalize to the range of 0 to 1\n",
    "    \n",
    "    \n",
    "    \n",
    "        normalized = (num + 2) / 4\n",
    "        \n",
    "        # Map to a color between blue, gray, and red\n",
    "        rgb_lower = (0, 0, 255,1)\n",
    "        rgb_middle = (128, 128, 128,1)\n",
    "        rgb_upper = (255, 0, 0,1)\n",
    "    \n",
    "    if normalized < 0.5:\n",
    "        r = int((2 * normalized) * rgb_middle[0] + (1 - 2 * normalized) * rgb_lower[0])\n",
    "        g = int((2 * normalized) * rgb_middle[1] + (1 - 2 * normalized) * rgb_lower[1])\n",
    "        b = int((2 * normalized) * rgb_middle[2] + (1 - 2 * normalized) * rgb_lower[2])\n",
    "        a = int((2 * normalized) * rgb_middle[3] + (1 - 2 * normalized) * rgb_lower[3])\n",
    "    else:\n",
    "        r = int((2 * normalized - 1) * rgb_upper[0] + (2 - 2 * normalized) * rgb_middle[0])\n",
    "        g = int((2 * normalized - 1) * rgb_upper[1] + (2 - 2 * normalized) * rgb_middle[1])\n",
    "        b = int((2 * normalized - 1) * rgb_upper[2] + (2 - 2 * normalized) * rgb_middle[2])\n",
    "        a = int((2 * normalized - 1) * rgb_upper[3] + (2 - 2 * normalized) * rgb_middle[3])\n",
    "    \n",
    "    # if normalized>0.5:\n",
    "    #     print(normalized,a,rgb_upper[3])\n",
    "    #     term\n",
    "    return (r, g, b,a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import ImageDraw, Image, ImageFont\n",
    "\n",
    "def binary_matrix_to_image(binary_matrix, row_labels=None, font_path=None, grid_size=10, border_size=1, label_size=15, is_fill=True,**rgb_params):\n",
    "    # Add a dummy column to the binary matrix\n",
    "    ddd=2\n",
    "\n",
    "    height, width = binary_matrix.shape[:2]\n",
    "    binary_matrix = np.concatenate((np.zeros((height, ddd)), binary_matrix), axis=1)\n",
    "    width += ddd\n",
    "    \n",
    "    # Calculate the size of the output image based on the size of the binary matrix\n",
    "    image_width = (width + 1) * grid_size + (width + 2) * border_size\n",
    "    image_height = height * grid_size + (height + 1) * border_size\n",
    "    \n",
    "    # Create a new image and a draw object to draw the grid and borders\n",
    "    image = Image.new('RGBA', (image_width, image_height), color=(0,0,0,0))\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    \n",
    "    # Draw the white grids\n",
    "    for i in range(height):\n",
    "        for j in range(1, width):\n",
    "            # if binary_matrix[i, j] == 1:\n",
    "            #     x1 = j * (grid_size + border_size) + border_size\n",
    "            #     y1 = i * (grid_size + border_size) + border_size\n",
    "            #     x2 = x1 + grid_size\n",
    "            #     y2 = y1 + grid_size\n",
    "            #     draw.rectangle((x1, y1, x2, y2), fill='white')\n",
    "\n",
    "            if binary_matrix[i, j] != 0:\n",
    "                x1 = j * (grid_size + border_size) + border_size\n",
    "                y1 = i * (grid_size + border_size) + border_size\n",
    "                x2 = x1 + grid_size\n",
    "                y2 = y1 + grid_size\n",
    "\n",
    "                int_color = ( int(binary_matrix[i, j]*96),\n",
    "                             int(binary_matrix[i, j]*96),\n",
    "                             int(binary_matrix[i, j]*96))\n",
    "\n",
    "                \n",
    "                int_color = map_to_rgb(binary_matrix[i, j], **rgb_params)\n",
    "                if is_fill:\n",
    "                    draw.rectangle((x1, y1, x2, y2), fill= int_color)\n",
    "                else:\n",
    "                    draw.rectangle((x1, y1, x2, y2), outline=int_color,width=2, fill= None)\n",
    "\n",
    "\n",
    "    # Draw the borders\n",
    "    color_border = (0,0,0,1)\n",
    "    for i in range(height + 1):\n",
    "        y = i * (grid_size + border_size)\n",
    "        draw.line((grid_size, y, image_width, y), fill=color_border, width=border_size)\n",
    "        \n",
    "    for j in range(width + 1):\n",
    "        x = j * (grid_size + border_size)\n",
    "        draw.line((x, 0, x, image_height), fill=color_border, width=border_size)\n",
    "\n",
    "    \n",
    "    # Draw the row labels\n",
    "    if row_labels is not None:\n",
    "        font = ImageFont.truetype(PATH_SYS+'arial.ttf', size=label_size)\n",
    "        max_label_width = max([font.getsize(str(label))[0] for label in row_labels])\n",
    "        label_x = 0\n",
    "        label_y = border_size\n",
    "        for i, label in enumerate(row_labels):\n",
    "            draw.text((label_x, label_y), str(label), font=font, fill='white',align=\"right\")\n",
    "            label_y += grid_size + border_size\n",
    "            # if i == 0:\n",
    "            #     label_x += max_label_width + border_size + grid_size\n",
    "        \n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "def create_barplot_image(data, labels, filename):\n",
    "    \"\"\"\n",
    "    Creates a bar plot image of the input data and saves it as a PNG file with the given filename.\n",
    "\n",
    "    Args:\n",
    "        data (numpy.ndarray): A 1D array of data to plot.\n",
    "        labels (list): A list of labels for each data point.\n",
    "        filename (str): The name of the output PNG file.\n",
    "\n",
    "    Returns:\n",
    "        PIL.Image.Image: A PIL image object of the bar plot.\n",
    "    \"\"\"\n",
    "    # Create a figure and axis object\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Create a bar plot\n",
    "    _ = ax.bar(np.arange(len(data)), data)\n",
    "\n",
    "    # Set axis labels and title\n",
    "    _ = ax.set_xlabel('Index')\n",
    "    _ = ax.set_ylabel('Value')\n",
    "    _ = ax.set_title('Bar plot')\n",
    "\n",
    "    # Set x-tick labels\n",
    "    _ = ax.set_xticks(np.arange(len(data)))\n",
    "    _ = ax.set_xticklabels(labels, rotation=45)\n",
    "\n",
    "    # Save the plot as a PNG file\n",
    "    _ = fig.savefig(filename)\n",
    "    plt.close(fig)\n",
    "    # Load the PNG image and return as a PIL image object\n",
    "    return Image.open(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def event2mat(event_type, event_time,P):\n",
    "\n",
    "    m = event_type.sum(1)>0 # False are masked\n",
    "    e=event_type[m,:]\n",
    "    t=event_time[m]\n",
    "    # print(t)\n",
    "\n",
    "    indices = e.nonzero()\n",
    "    indices[:,0] = t[indices[:,0]].int()\n",
    "    # print(t[indices[:,0]])\n",
    "    # print(indices[:,0])\n",
    "\n",
    "    M = torch.zeros((P, e.shape[-1]))\n",
    "    M[indices[:,0],indices[:,1]]=1\n",
    "\n",
    "    return M.detach().cpu().numpy().transpose() # [M,P]\n",
    "\n",
    "def att_event2mat(event_type, event_time,P, tee_att):\n",
    "    # tee_att [h,L]\n",
    "    h = tee_att.shape[0]\n",
    "\n",
    "    m = event_type.sum(1)>0 # False are masked\n",
    "    e=event_type[m,:]\n",
    "    t=event_time[m]\n",
    "    tee_att = tee_att[:,m]\n",
    "\n",
    "    # indices = e.nonzero()\n",
    "    # indices[:,0] = t[indices[:,0]].int()\n",
    "\n",
    "    # M = torch.zeros(h, len(t))\n",
    "    M = torch.zeros(( h , P))\n",
    "\n",
    "    M[:,t.long()]=tee_att\n",
    "\n",
    "    return M.detach().cpu().numpy() # [h,L]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state2mat(time, mod,M):\n",
    "    P = time.int().max().item() + 1\n",
    "\n",
    "    M = torch.zeros(P, M)\n",
    "    M[time[mod!=0].long(), mod[mod!=0]-1] = 1\n",
    "\n",
    "\n",
    "    return M.cpu().numpy().transpose() # [M,P]\n",
    "\n",
    "def att_state2mat(time, mod,M, dam_att):\n",
    "    # dam_att [P,h]\n",
    "    # h = dam_att.shape[-1]\n",
    "\n",
    "    # dam_att = dam_att[:,0] # [P]\n",
    "    P = time.int().max().item() + 1\n",
    "\n",
    "    M = torch.zeros(P, M)\n",
    "    \n",
    "    M[time[mod!=0].long(),  mod[mod!=0]-1] = dam_att[mod!=0]\n",
    "\n",
    "\n",
    "    return M.cpu().numpy().transpose() # [M,P]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cool_image(out,i_b,i,opt):\n",
    "\n",
    "\n",
    "    label_size = 12\n",
    "    rgb_params_values = {\n",
    "    'rgb_lower':(0, 0, 255,255),\n",
    "    'rgb_middle':(128, 128, 128,255),\n",
    "    'rgb_upper':(255, 0, 0,255),\n",
    "    'offset':-2,\n",
    "    'range':4\n",
    "\n",
    "    }\n",
    "    rgb_params_events = {\n",
    "    'rgb_lower':(0, 0, 0,255),\n",
    "    'rgb_middle':(128, 128, 128,255),\n",
    "    'rgb_upper':(255, 255, 255,255),\n",
    "    'offset':0,\n",
    "    'range':1\n",
    "\n",
    "    }\n",
    "    # rgb_params_att = {\n",
    "    #     'rgb_lower':(64, 64, 64,0),\n",
    "    #     'rgb_middle':(164, 164, 32,32),\n",
    "    #     'rgb_upper':(255, 255, 0,255),\n",
    "    #     'offset':0,\n",
    "    #     'range':0.1\n",
    "\n",
    "    # }\n",
    "\n",
    "\n",
    "    rgb_params_att = {\n",
    "        'rgb_lower':(128, 128, 128,32),\n",
    "        # 'rgb_middle':(8, 164, 32,196),\n",
    "        'rgb_upper':(0, 255, 0,255),\n",
    "        'offset':0,\n",
    "        'range':0.2\n",
    "\n",
    "    }\n",
    "\n",
    "\n",
    "    rgb_params_att['rgb_middle'] = tuple([(int(i+j)/2) for i,j in zip(rgb_params_att['rgb_lower'],rgb_params_att['rgb_upper'])])\n",
    "    rgb_params_att['rgb_middle']\n",
    "    state_labels = opt.dict_map_states.keys()\n",
    "    event_labels = opt.dict_map_events.keys()\n",
    "    \n",
    "\n",
    "    # if len(out['event_type_list']) > 0:\n",
    "        \n",
    "\n",
    "    if len(out['state_time_list']) > 0:\n",
    "        st=out['state_time_list'][i_b][i]\n",
    "        sm=out['state_mod_list'][i_b][i]\n",
    "        sv=( out['state_value_list'][i_b][i] )\n",
    "\n",
    "        dam_att = out['list_DAM_att'][i_b][i] # [P,h]\n",
    "\n",
    "        n_state_mods = len(opt.dict_map_states.keys())\n",
    "\n",
    "        # ev.shape, t.shape\n",
    "        P = st.int().max().item() + 1\n",
    "\n",
    "        \n",
    "        # list_img_att = []\n",
    "        # for i_head in range(dam_att.shape[-1]):\n",
    "        #     binary_matrix = att_state2mat(st, sm, n_state_mods, dam_att[:,i_head])\n",
    "        #     img_att = binary_matrix_to_image(binary_matrix, row_labels=state_labels, font_path=None, grid_size=10, border_size=1, label_size=label_size,is_fill=False,**rgb_params_att)\n",
    "        #     list_img_att.append(img_att.convert(\"RGB\"))\n",
    "\n",
    "        binary_matrix = att_state2mat(st, sm, n_state_mods, dam_att.sum(1))\n",
    "        img_att = binary_matrix_to_image(binary_matrix, row_labels=state_labels, font_path=None, grid_size=10, border_size=1, label_size=label_size,is_fill=False,**rgb_params_att)\n",
    "\n",
    "\n",
    "        binary_matrix = att_state2mat(st, sm, n_state_mods, sv)\n",
    "        img_val = binary_matrix_to_image(binary_matrix, row_labels=state_labels, font_path=None, grid_size=10, border_size=1, label_size=label_size,is_fill=True,**rgb_params_values)\n",
    "\n",
    "        merged_img = Image.new('RGBA', img_val.size)\n",
    "        merged_img = Image.alpha_composite(merged_img, img_val)\n",
    "        merged_img = Image.alpha_composite(merged_img, img_att).convert(\"RGB\")\n",
    "    else:\n",
    "        ev = out['event_type_list'][i_b][i]\n",
    "        t = out['event_time_list'][i_b][i]\n",
    "        tee_att = out['list_TE_att'][i_b][i,:,-1,:] # [h,L]\n",
    "\n",
    "        binary_matrix = event2mat(ev,t,P)\n",
    "        merged_img = binary_matrix_to_image(binary_matrix, row_labels=event_labels, font_path=None, grid_size=10, border_size=1, label_size=label_size,**rgb_params_events)\n",
    "\n",
    "        \n",
    "    return merged_img,(img_att.convert(\"RGB\"), img_val.convert(\"RGB\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_summary(df,out, point_ids,res_labels, fig=None):\n",
    "\n",
    "    if fig is None:\n",
    "        fig = go.Figure()\n",
    "\n",
    "\n",
    "\n",
    "    list_summary = []\n",
    "    for pid in point_ids:\n",
    "\n",
    "        i_b = df.iloc[pid]['i_b']\n",
    "        i = df.iloc[pid]['i']\n",
    "\n",
    "        ev = out['event_type_list'][i_b][i]\n",
    "        t = out['event_time_list'][i_b][i]\n",
    "        st=out['state_time_list'][i_b][i]\n",
    "        \n",
    "        P = st.int().max().item() + 1\n",
    "\n",
    "        M = event2mat(ev,t,P)\n",
    "\n",
    "\n",
    "        vector = M.sum(1)/M.shape[1]*24\n",
    "        list_summary.append(vector)\n",
    "\n",
    "    vec_mean = np.mean(list_summary,axis=0)\n",
    "    vec_std = np.std(list_summary,axis=0)\n",
    "\n",
    "    sum(vec_std)\n",
    "\n",
    "    \n",
    "    _ = fig.add_trace(go.Bar(\n",
    "        name=f'Summary',\n",
    "        x=list(res_labels), y=vec_mean,\n",
    "        error_y=dict(type='data', array=vec_std)\n",
    "    ))\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_from_wandb(run_path):\n",
    "\n",
    "    run = api.run(run_path)\n",
    "    for file in run.files():\n",
    "        file.download(replace=True,root=f'./local/{run_path}/')\n",
    "\n",
    "    opt = pickle.load(open(f'./local/{run_path}/opt.pkl','rb'))\n",
    "    opt = Main.config(opt, justLoad=True)\n",
    "\n",
    "    checkpoint = torch.load(f'./local/{run_path}/best_model.pkl')\n",
    "\n",
    "    model = Main.ATHP(\n",
    "       n_marks=opt.num_marks,\n",
    "        TE_config = opt.TE_config,\n",
    "        DAM_config = opt.DAM_config,\n",
    "        NOISE_config = opt.NOISE_config,\n",
    "\n",
    "        CIF_config = opt.CIF_config,\n",
    "        next_time_config = opt.next_time_config,\n",
    "        next_type_config = opt.next_type_config,\n",
    "        label_config = opt.label_config,\n",
    "\n",
    "        demo_config = opt.demo_config,\n",
    "\n",
    "        device=opt.device,\n",
    "    )\n",
    "\n",
    "    _ = model.to(opt.device)\n",
    "    _ = model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    _ = model.eval()\n",
    "\n",
    "    return model, opt, run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_knn_pids (X, id_origin, n_knn=10):\n",
    "\n",
    "    # X [N,d] np.array\n",
    "    r = np.sqrt(   ((X-X[id_origin])**2).sum(-1)   )\n",
    "    knn_pids = list(np.argpartition(r,n_knn)[:n_knn])\n",
    "\n",
    "    if id_origin not in knn_pids:\n",
    "        print('bad')\n",
    "    else:\n",
    "        knn_pids.remove(id_origin)\n",
    "\n",
    "    # print(X.shape)\n",
    "    # term\n",
    "\n",
    "    \n",
    "    # x0 = df.iloc[id_origin]['x']\n",
    "    # y0 = df.iloc[id_origin]['y']\n",
    "\n",
    "    # df['r'] = df.apply(lambda row: ( (row['x']-x0)**2 + (row['y']-y0)**2  ), axis=1)\n",
    "\n",
    "    # knn_pids = list(df.nsmallest(n_knn,'r').index)\n",
    "\n",
    "\n",
    "    return knn_pids\n",
    "\n",
    "def cal_similarity(df, out, pid, knn_pids):\n",
    "\n",
    "    list_summary = []\n",
    "    for pid in knn_pids:\n",
    "        \n",
    "\n",
    "        i_b = df.iloc[pid]['i_b']\n",
    "        i = df.iloc[pid]['i']\n",
    "\n",
    "        ev = out['event_type_list'][i_b][i]\n",
    "        t = out['event_time_list'][i_b][i]\n",
    "        st=out['state_time_list'][i_b][i]\n",
    "        \n",
    "        P = st.int().max().item() + 1\n",
    "\n",
    "        M = event2mat(ev,t,P)\n",
    "\n",
    "        \n",
    "\n",
    "        vector = M.sum(1)/M.shape[1]*24\n",
    "\n",
    "        \n",
    "        list_summary.append(vector)\n",
    "        \n",
    "\n",
    "    dotp = [ np.dot(j,list_summary[0])/(np.linalg.norm(j) * np.linalg.norm(list_summary[0])) for  j in list_summary]\n",
    "    sim_score = np.mean( dotp )\n",
    "\n",
    "\n",
    "    return sim_score, list_summary\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hokarami/TEEDAM_supervised/56ecgyrq'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs_path=[\n",
    "# \"hokarami/TEEDAM_supervised/5uzxzoxd\",\n",
    "\"hokarami/TEEDAM_supervised/sb9zf1mm\",\n",
    "\"hokarami/TEEDAM_supervised/hue1qxw4\",  # seft [Q10-TE__nextmark-concat]1566371 with label\n",
    "\n",
    "# \"hokarami/TEEDAM_supervised/t43m0t0u\", # [Q10-DA__base-concat]1563864\n",
    "\n",
    "\"hokarami/TEEDAM_supervised/9gxq3dgy\", # [Q10-TEDA__nextmark-concat]1577576 with label\n",
    "\n",
    "\"hokarami/TEEDAM_supervised/56ecgyrq\", # [Q20-TEDA__nextmark-concat]1588433\n",
    "# \"hokarami/TEEDAM_supervised/g4x0ibmk\", # [Q20-TE__nextmark-concat]1585936 with label\n",
    "\n",
    "# \"hokarami/TEEDAM_supervised/lzvf7erg\", # [Q20-DA__base-concat]1586915\n",
    "\n",
    "]\n",
    "\n",
    "run_path = runs_path[-1]\n",
    "run_path\n",
    "\n",
    "\n",
    "# run = api.run(run_path)\n",
    "# for file in run.files():\n",
    "#     file.download(replace=True,root='./local/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ATT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out.keys()\n",
    "# bs = opt.batch_size\n",
    "\n",
    "\n",
    "# out['event_type_list'][0].shape\n",
    "# out['event_time_list'][0].shape\n",
    "# out['non_pad_mask_list'][0].shape\n",
    "# out['list_TE_att'][0].shape\n",
    "\n",
    "# out['state_mod_list'][0].shape\n",
    "# out['list_DAM_att'][0].shape\n",
    "\n",
    "# out['y_state_true'].shape\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary_matrix = state2mat(st, sm,n_state_mods)\n",
    "\n",
    "# # binary_matrix_to_image(binary_matrix, row_labels=state_labels, font_path=None, grid_size=10, border_size=1, label_size=8)\n",
    "\n",
    "\n",
    "# M = [state2mat(st, sm,n_state_mods) +  att_state2mat(st, sm, n_state_mods, dam_att.sum(1))*0,\n",
    "     \n",
    "#      att_event2mat(ev, t,P, tee_att)*12\n",
    "     \n",
    "#      ]\n",
    "\n",
    "# all_labels = [*state_labels,\n",
    "#               *[f\"Head_{i}\" for i in range(tee_att.shape[0])]\n",
    "#               ]\n",
    "# binary_matrix = np.concatenate(M, axis=0)\n",
    "\n",
    "# # binary_matrix_to_image(binary_matrix, row_labels=all_labels, font_path=None, grid_size=10, border_size=1, label_size=8)\n",
    "\n",
    "\n",
    "# # binary_matrix = event2mat(ev,t,P)\n",
    "# # event_labels = opt.dict_map_events.keys()\n",
    "\n",
    "# # binary_matrix_to_image(binary_matrix, row_labels=None, font_path=None, grid_size=10, border_size=1, label_size=8)\n",
    "\n",
    "\n",
    "# binary_matrix = att_state2mat(st, sm, n_state_mods, dam_att.sum(1))\n",
    "# img_att = binary_matrix_to_image(binary_matrix, row_labels=state_labels, font_path=None, grid_size=10, border_size=1, label_size=8,is_fill=False,**rgb_params_att)\n",
    "\n",
    "\n",
    "# binary_matrix = att_state2mat(st, sm, n_state_mods, sv)\n",
    "# img_val = binary_matrix_to_image(binary_matrix, row_labels=state_labels, font_path=None, grid_size=10, border_size=1, label_size=8,is_fill=True,**rgb_params_values)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # binary_matrix[binary_matrix!=0].shape\n",
    "# # binary_matrix.shape\n",
    "# # binary_matrix.min()\n",
    "# # binary_matrix.max()\n",
    "\n",
    "# i_b=3\n",
    "# i=18\n",
    "\n",
    "# merged_img,temp = cool_image(out,i_b,i,opt)\n",
    "\n",
    "# temp[2][0]\n",
    "# temp[2][1]\n",
    "# temp[0]\n",
    "# merged_img\n",
    "\n",
    "# map_to_rgb(-0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if 'y_state_true' in out:\n",
    "\n",
    "#     y_state_pred = out['y_state_pred']\n",
    "#     y_state_true = out['y_state_true']\n",
    "#     y_state_score = out['y_state_score']\n",
    "# else:\n",
    "#     y_state_pred = None\n",
    "#     y_state_true = None\n",
    "#     y_state_score = None\n",
    "\n",
    "# y_pred = out['y_pred']\n",
    "# y_true = out['y_true']\n",
    "# y_score = out['y_score']\n",
    "\n",
    "\n",
    "# res=list()\n",
    "\n",
    "\n",
    "# if len(out['state_mod_list'])>0 and 0:\n",
    "\n",
    "#     res_labels = opt.dict_map_states.keys()\n",
    "\n",
    "#     n_cols = len(opt.dict_map_states.keys())\n",
    "\n",
    "#     state_mod_list = out['state_mod_list']\n",
    "#     state_time_list = out['state_time_list']\n",
    "#     len(state_mod_list)\n",
    "#     state_mod_list[0].shape\n",
    "\n",
    "#     for state_mod,state_time in zip(state_mod_list,state_time_list):\n",
    "#         xs = torch.unbind(state_time,0)\n",
    "#         ys = torch.unbind(state_mod,0)\n",
    "\n",
    "#         for x,y in zip(xs,ys):\n",
    "#             # y = y[y~=0]\n",
    "#             n_rows = x.int().max().item() + 1\n",
    "#             matrix = torch.zeros(n_rows, n_cols)\n",
    "#             matrix[x[y!=0].long(), y[y!=0]-1] = 1\n",
    "#             res.append(matrix.cpu().numpy().transpose()) # [n_marks * times]\n",
    "\n",
    "\n",
    "# else:\n",
    "#     non_pad_mask_list = out['non_pad_mask_list']\n",
    "#     event_type_list = out['event_type_list']\n",
    "#     event_time_list = out['event_time_list']\n",
    "\n",
    "#     event_type_list[0].shape\n",
    "#     non_pad_mask_list[0].shape\n",
    "\n",
    "#     num_marks = event_type_list[0].shape[-1]\n",
    "#     res_labels = opt.dict_map_events.keys()\n",
    "\n",
    "\n",
    "\n",
    "#     for event_type, event_time, non_pad_mask in zip(event_type_list,event_time_list,non_pad_mask_list):\n",
    "\n",
    "#         B = event_type.shape[0]\n",
    "#         for i in range(B):\n",
    "#             m = non_pad_mask[i]\n",
    "#             e=event_type[i,:m.sum().int(),:]\n",
    "#             t=event_time[i,:m.sum().int()]\n",
    "            \n",
    "#             indices = e.nonzero()\n",
    "#             indices[:,0] = t[indices[:,0]]\n",
    "\n",
    "#             M = torch.zeros((indices[:,0].max()+1, e.shape[-1]))\n",
    "#             M[indices[:,0],indices[:,1]]=1\n",
    "\n",
    "\n",
    "#             res.append( M.cpu().numpy().astype(np.uint8).transpose() )\n",
    "\n",
    "\n",
    "#         # temp = torch.unbind(event_type,0)\n",
    "#         # lens = non_pad_mask.sum(1).long()\n",
    "#         # term\n",
    "#         # for i,x in enumerate(temp):\n",
    "#         #     res.append( x[:lens[i],:].cpu().numpy().astype(np.uint8).transpose() )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# res[1].shape\n",
    "\n",
    "# len(res_labels)\n",
    "# res_labels\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # for i,pattern in enumerate(res):\n",
    "# #     image = Image.fromarray(pattern)\n",
    "\n",
    "\n",
    "# #     # row_labels = opt.dict_map_states.keys()\n",
    "# #     # image = binary_matrix_to_image(pattern, row_labels=row_labels, grid_size=50, border_size=2, label_size=20)\n",
    "# #     # image.save(f'./local/images/img{i}.jpeg')\n",
    "# all_images = [f'./local/images/img{i}.jpeg' for i in range(len(res))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSNE of Learned Rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "TSNE_LIMIT = 6000\n",
    "\n",
    "def compute_tsne(r_enc_list, model):\n",
    "    tsne = TSNE(n_components=2, perplexity=30, learning_rate=10,n_jobs=4)\n",
    "\n",
    "    # r_enc_list = out['r_enc_list']\n",
    "\n",
    "    X = np.concatenate(r_enc_list,axis=0)[:,:]\n",
    "    X_tsne = tsne.fit_transform(X[:TSNE_LIMIT,:])\n",
    "\n",
    "    X_tsne_split=dict()\n",
    "    if model.d_out_te>0:\n",
    "        X_te = np.concatenate(r_enc_list,axis=0)[:,:model.d_out_te]\n",
    "        X_te_tsne = tsne.fit_transform(X_te[:TSNE_LIMIT,:])\n",
    "        X_tsne_split['tee']=X_te_tsne\n",
    "\n",
    "    if model.d_out_dam>0:    \n",
    "        X_dam = np.concatenate(r_enc_list,axis=0)[:,model.d_out_te:]\n",
    "        X_dam_tsne = tsne.fit_transform(X_dam[:TSNE_LIMIT,:])\n",
    "        X_tsne_split['dam']=X_dam_tsne\n",
    "    return X_tsne, X_tsne_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_df(out,opt, X_tsne):\n",
    "    if 'y_state_true' in out:\n",
    "\n",
    "        y_state_pred = out['y_state_pred']\n",
    "        y_state_true = out['y_state_true']\n",
    "        y_state_score = out['y_state_score']\n",
    "    else:\n",
    "        y_state_pred = None\n",
    "        y_state_true = None\n",
    "        y_state_score = None\n",
    "\n",
    "    y_pred = out['y_pred']\n",
    "    y_true = out['y_true']\n",
    "    y_score = out['y_score']\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    df['x']=X_tsne[:,0]\n",
    "    df['y']=X_tsne[:,1]\n",
    "\n",
    "    # df['x']=X_te_tsne[:,0]\n",
    "    # df['y']=X_te_tsne[:,1]\n",
    "\n",
    "    # df['x']=X_dam_tsne[:,0]\n",
    "    # df['y']=X_dam_tsne[:,1]\n",
    "\n",
    "    df['color']=0\n",
    "    df['id']=np.arange(len(df))\n",
    "\n",
    "\n",
    "    if y_state_true is not None:\n",
    "\n",
    "        TP = (y_state_true[:TSNE_LIMIT]*y_state_pred[:TSNE_LIMIT])==1\n",
    "        FN = (y_state_true[:TSNE_LIMIT]-y_state_pred[:TSNE_LIMIT])==1\n",
    "        FP = (y_state_true[:TSNE_LIMIT]-y_state_pred[:TSNE_LIMIT])==-1\n",
    "\n",
    "        TN = (y_state_true[:TSNE_LIMIT]+y_state_pred[:TSNE_LIMIT])==0\n",
    "\n",
    "        FP_FN = (y_state_true[:TSNE_LIMIT]+y_state_pred[:TSNE_LIMIT])==1\n",
    "        TP_TN = (y_state_true[:TSNE_LIMIT]-y_state_pred[:TSNE_LIMIT])==0\n",
    "\n",
    "\n",
    "        # df.loc[TN, 'color']='True Negatives'\n",
    "        df.loc[TP, 'color']='True Positives'\n",
    "        df.loc[FN, 'color']='False Negatives'\n",
    "        df.loc[FP, 'color']='False Positives'\n",
    "        df.loc[TN, 'color']='True Negatives'\n",
    "\n",
    "        df.loc[TP_TN, 'color_true_pred']='True Predicted'\n",
    "        df.loc[FP_FN, 'color_true_pred']='False Predicted'\n",
    "\n",
    "\n",
    "        df.loc[y_state_true[:TSNE_LIMIT].astype(bool).flatten(), 'color_true']='Positive Samples'\n",
    "        df.loc[~y_state_true[:TSNE_LIMIT].astype(bool).flatten(), 'color_true']='Negative Samples'\n",
    "\n",
    "\n",
    "        df.loc[y_state_pred[:TSNE_LIMIT].astype(bool).flatten(), 'color_pred']='Positive Predicted'\n",
    "        df.loc[~y_state_pred[:TSNE_LIMIT].astype(bool).flatten(), 'color_pred']='Negative Predicted'\n",
    "\n",
    "        # df.loc[y_state_pred[:TSNE_LIMIT].astype(bool).flatten(), 'color_true_pred']='Positive Predicted'\n",
    "        # df.loc[~y_state_pred[:TSNE_LIMIT].astype(bool).flatten(), 'color_true_pred']='Negative Predicted'\n",
    "\n",
    "    df['i_b'] = df['id'].apply(lambda x:int(x / opt.batch_size) )\n",
    "    df['i'] = df['id'].apply(lambda x:x % opt.batch_size)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_map = {\n",
    "    'Positive Samples': \"#E52B50\",\n",
    "    'Negative Samples': \"#3B7A57\",\n",
    "    'True Predicted': \"#E52B50\",\n",
    "    'False Predicted': \"#3B7A57\",\n",
    "\n",
    "    \n",
    "    0: \"#3B7A57\",\n",
    "    # 'Positive Predicted': \"#3DDC84\",\n",
    "    # 'Negative Predicted': \"#FFBF00\",\n",
    "\n",
    "    'Positive Predicted': \"#E52B50\",\n",
    "    'Negative Predicted': \"#3B7A57\",\n",
    "\n",
    "    5: \"#915C83\",\n",
    "    'True Positives': \"#008000\",\n",
    "    'False Negatives': \"#7FFFD4\",\n",
    "    'False Positives': \"#E9D66B\",\n",
    "    'True Negatives': \"#007FFF\",\n",
    "}\n",
    "\n",
    "def plot_tsne(df, title=\"\"):\n",
    "    labels = df['color_true'].values\n",
    "    colors = [color_map[label] for i,label in enumerate(labels)]\n",
    "    fig = go.Figure()\n",
    "\n",
    "    _ = fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df['x'],\n",
    "            y=df['y'],\n",
    "            # z=tsne[:, 2],\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                # size=2,\n",
    "                color=colors,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    labels = df['color_pred'].values\n",
    "    colors = [color_map[label] for i,label in enumerate(labels)]\n",
    "    _ = fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df['x'],\n",
    "            y=df['y'],\n",
    "            # z=tsne[:, 2],\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                symbol='circle-open',\n",
    "                # size=2,\n",
    "                color=colors,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    )\n",
    "    # fig = go.Figure(data=[])\n",
    "\n",
    "    _=fig.update_layout(\n",
    "        # autosize=False,\n",
    "        title=title,\n",
    "        width=600,\n",
    "        height=600,\n",
    "        showlegend=False,\n",
    "\n",
    "    )\n",
    "    _=fig.update_traces(\n",
    "        hoverinfo=\"none\",\n",
    "        hovertemplate=None,\n",
    "    )\n",
    "    # _=fig.update_layout(\n",
    "    #     scene=dict(\n",
    "    #         xaxis=dict(range=[-10,10]),\n",
    "    #         yaxis=dict(range=[-10,10]),\n",
    "    #         # zaxis=dict(range=[-10,10]),   \n",
    "    #     )\n",
    "    # )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # save to run\n",
    "    # fig.write_html(f\"local/{run.name}.html\")\n",
    "    # run.upload_file(f\"local/{run.name}.html\")\n",
    "\n",
    "\n",
    "    # tsne of TE_nextmark[label]\n",
    "        # https://storage.googleapis.com/wandb-production.appspot.com/hokarami/TEEDAM_supervised/hue1qxw4/local/temp.html?Expires=1676986614&GoogleAccessId=wandb-production%40appspot.gserviceaccount.com&Signature=xLOuNCu8qoWVwFRPCspoPKTFbpF5aOSJMAFICqsDRYxf2wfudxEiFFEIlXBIq9YyYZcPtpSKSzYb6nUr0lloLZ6GHg1w4AOBZyieBKBsuKmIDGqhRY4ojK0FPHZHD%2BeoKERgjD42F19vP8E5Qf%2BA7PlgB2E%2BWutwJxx1sc2TtCgjUdkEK%2BEwaTzfQBQ0hXGIWC9MeirU7hRSmn4%2BXzIRaRcUFjF0vOtxCHBjsEhldGSwaUFv21kt4qvr2hSeR5Ku5gS7webtvzVi6fw55Muq78%2FB90r3EqWqy9Sn68T%2FDKx%2F%2FzHVfge4TsxlIjRE%2F9HBCo7qZeNeeHnlHjVZXdvTKg%3D%3D\n",
    "\n",
    "    # tsne of DA[label]\n",
    "        # https://storage.googleapis.com/wandb-production.appspot.com/hokarami/TEEDAM_supervised/t43m0t0u/local/temp.html?Expires=1676987035&GoogleAccessId=wandb-production%40appspot.gserviceaccount.com&Signature=jX44t4Nblmtzd0CCZC2Gn0cw43iZZbZtuofN%2BrlmzgennSxNz36YE4BwYU%2Ft21iuFdSwmqPLnnI%2B2saLWT9kZsBHNo0e2Nsti0vhf7216iT1wsnnFukn%2B8CswPFeQUQBmSyvEO0IJRTE%2BLmjORdY5NFMdgeXchVwLlf8LBIJFoxAfyiaYLmCNcjWwSmbkvVf1DwOxL2sjneA8TtkgQiSCZiC3GgMJBfh8wg1bf6wS%2Bxa95APq%2BPo6J7%2Ffq0sqmqCiAp28E309PlM29C0C89y63dvzqkRhBhvdffx3O%2FFUAmK%2FjRF82ohd7JSgxMva9oWz%2By7aHESGKr0b49KrUxM2Q%3D%3D\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_dash_app(fig_tsne,out,opt, df,port=None):\n",
    "    if port is None:\n",
    "        port = np.random.randint(2000,5000)\n",
    "\n",
    "    app = JupyterDash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])\n",
    "\n",
    "    app.layout = dbc.Container([\n",
    "        # className=\"container\",\n",
    "        # children=[\n",
    "\n",
    "            dbc.Row([\n",
    "                    html.Div(id=\"dummy2\"),\n",
    "                    html.Div(id=\"dummy\"),\n",
    "                ]),\n",
    "\n",
    "            dbc.Row([\n",
    "                \n",
    "                dbc.Col(\n",
    "                    dcc.Graph(id=\"graph-5\", figure=fig_tsne, clear_on_unhover=True,),\n",
    "\n",
    "                    \n",
    "                    width=6),  # first column with graph\n",
    "\n",
    "\n",
    "\n",
    "                dbc.Col([\n",
    "                    html.Img(id='image_merge',src='./local/images/C0-1296.jpeg',style={\"height\": \"400px\", 'display': 'block', 'margin': '0 auto'},),\n",
    "\n",
    "                    html.Img(id='image_att',src='./local/images/C0-1296.jpeg',style={\"height\": \"400px\", 'display': 'block', 'margin': '0 auto'},),\n",
    "\n",
    "                ], width=6),  # second column with image\n",
    "            ]),\n",
    "\n",
    "            dbc.Row([\n",
    "                \n",
    "                dbc.Col(\n",
    "                    dcc.Graph(id=\"graph-summary\", figure=go.Figure(), clear_on_unhover=True,),\n",
    "\n",
    "                    \n",
    "                    width=12),  # first column with graph\n",
    "\n",
    "\n",
    "\n",
    "                # dbc.Col(\n",
    "                #     html.Img(id='image',src='./local/images/C0-1296.jpeg',style={\"height\": \"400px\", 'display': 'block', 'margin': '0 auto'},),\n",
    "                \n",
    "                \n",
    "                # width=6),  # second column with image\n",
    "            ]),\n",
    "\n",
    "            dcc.Tooltip(id=\"graph-tooltip-5\", direction='bottom'),\n",
    "\n",
    "\n",
    "        \n",
    "        ])\n",
    "\n",
    "    @app.callback(\n",
    "        # Output(\"graph-tooltip-5\", \"show\"),\n",
    "        # Output(\"graph-tooltip-5\", \"bbox\"),\n",
    "        # Output(\"graph-tooltip-5\", \"children\"),\n",
    "        Output('image_merge', 'src'),\n",
    "        Output('image_att', 'src'),\n",
    "        Output(\"dummy2\", \"children\"),\n",
    "        Input(\"graph-5\", \"hoverData\"),\n",
    "    )\n",
    "    def display_hover(hoverData):\n",
    "        if hoverData is None:\n",
    "            # return False, no_update, no_update, no_update, no_update\n",
    "            return no_update,no_update, no_update\n",
    "\n",
    "        num = 111111\n",
    "        # demo only shows the first point, but other points may also be available\n",
    "        hover_data = hoverData[\"points\"][0]\n",
    "        bbox = hover_data[\"bbox\"]\n",
    "        num = hover_data[\"pointNumber\"]\n",
    "\n",
    "\n",
    "        # im_matrix = res[num].astype(int)\n",
    "        # # im_url = np_image_to_base64(im_matrix)\n",
    "        # # im_url = binary_matrix_to_image(im_matrix)\n",
    "        # im_url = binary_matrix_to_image(im_matrix, row_labels=res_labels, grid_size=50, border_size=2, label_size=20)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        # # bar plot\n",
    "        # vector = im_matrix.sum(1)/im_matrix.shape[1]*24\n",
    "        # # im_url = plot_bar_chart(vector, labels=res_labels)\n",
    "        # im_url = create_barplot_image(vector, res_labels, './local/images/temp.png')\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "        # NEW\n",
    "        i_b = df.iloc[num]['i_b']\n",
    "        i = df.iloc[num]['i']\n",
    "        im_url, temp = cool_image(out,i_b,i,opt)\n",
    "\n",
    "        \n",
    "        output_str = f\"{num} - {df.iloc[num]['color']} - i_b {i_b} - i {i}\"\n",
    "        \n",
    "        im_url.save(\"./local/images/hover_img.png\")\n",
    "        im_url_path = './local/images/C2-203.jpeg'\n",
    "        \n",
    "        \n",
    "        \n",
    "        children = [\n",
    "            html.Div([\n",
    "                html.Img(\n",
    "                    src=im_url,\n",
    "                    style={\"height\": \"400px\", 'display': 'block', 'margin': '0 auto'},\n",
    "                ),\n",
    "                # html.P(\"MNIST Digit \" + str(labels[num]), style={'font-weight': 'bold'})\n",
    "                html.P(f\"Patterns-id={num} - i_b {i_b} - i {i}\" , style={'font-weight': 'bold'})\n",
    "\n",
    "            ])\n",
    "            \n",
    "        ]\n",
    "\n",
    "\n",
    "        # return True, bbox, children,im_url, output_str\n",
    "        return im_url,no_update, output_str        # temp[0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Define a callback function to print the selected point IDs\n",
    "    @app.callback(Output(\"dummy\", \"children\"),Output(\"graph-summary\", \"figure\"), [Input(\"graph-5\", \"selectedData\"), Input(\"graph-summary\", \"figure\")])\n",
    "    def display_selected_data(selected_data, fig_prev):\n",
    "        if selected_data is None:\n",
    "            return \"No points selected.\",no_update\n",
    "        else:\n",
    "\n",
    "\n",
    "            new_fig = go.Figure(data=fig_prev['data'],layout=fig_prev['layout'])\n",
    "            point_ids = [point[\"pointIndex\"] for point in selected_data[\"points\"]]\n",
    "\n",
    "            new_fig = bar_summary(df,out, point_ids,res_labels, fig=new_fig)\n",
    "            \n",
    "\n",
    "            # # save selected to local\n",
    "            # for pid in point_ids:\n",
    "            #     # NEW\n",
    "            #     i_b = df.iloc[pid]['i_b']\n",
    "            #     i = df.iloc[pid]['i']\n",
    "            #     im_url, temp = cool_image(out,i_b,i,opt)\n",
    "            #     im_url.save(f\"./local/images/selected{pid}.png\")\n",
    "\n",
    "            # print(f\"{point_ids},\\n\")\n",
    "            return f\"{point_ids},\\n\",new_fig\n",
    "\n",
    "    if __name__ == \"__main__\":\n",
    "        # app.run_server(mode='inline', debug=True)\n",
    "        app.run_server(mode='external',port=port)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEDAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT TEDAM --> none-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p19-rand/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='', freeze='', ES_pat=100, setting='rand', test_center='', split='', log='log.txt', user_prefix='[Q10-TEDA__nextmark-concat]', pos_alpha=1.0, epoch=50, batch_size=128, lr=0.01, smooth=0.0, weight_decay=0.1, event_enc=1, time_enc='concat', te_d_mark=8, te_d_time=8, te_d_rnn=256, te_d_inner=16, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=False, num_states=1, noise=False, mod='none', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=0, w_time=1.0, sample_label=1, w_pos_label=0.5, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p19/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'freeze': '', 'ES_pat': 100, 'setting': 'rand', 'test_center': '', 'split': '', 'log': 'log.txt', 'user_prefix': '[Q10-TEDA__nextmark-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 128, 'lr': 0.01, 'smooth': 0.0, 'weight_decay': 0.1, 'event_enc': 1, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 8, 'te_d_rnn': 256, 'te_d_inner': 16, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': False, 'num_states': 1, 'noise': False, 'mod': 'none', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 0, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 0.5, 'w_sample_label': 100.0}, date='22-02-23--16-18-04', run_id='1583061', dataset='P19', str_config='-rand', run_name='[Q10-TEDA__nextmark-concat]1583061', run_path='/mlodata1/hokarami/tedam/p19-rand/[Q10-TEDA__nextmark-concat]1583061/', device=device(type='cuda'), INPUT='TEDAM', OUTPUT='none-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.0771\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    }
   ],
   "source": [
    "run_path = \"hokarami/TEEDAM_supervised/56ecgyrq\" # [Q20-TEDA__nextmark-concat]1588433\n",
    "\n",
    "# p19\n",
    "run_path = \"hokarami/TEEDAM_supervised/bfjurg4g\" # [Q10-TEDA__nextmark-concat]1583061\n",
    "\n",
    "model1, opt1, run1 = read_from_wandb(run_path)\n",
    "dict_metrics1, out1 = Main.valid_epoch_tsne(model1, opt1.validloader, opt1.pred_loss_func, opt1)\n",
    "X_tsne1, X_tsne_split1 = compute_tsne(out1['r_enc_list'], model1)\n",
    "\n",
    "res_labels = opt1.dict_map_events.keys()\n",
    "\n",
    "df1 = build_df(out1,opt1, X_tsne1)\n",
    "fig_tsne1 = plot_tsne(df1,title=run1.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out1.keys()\n",
    "out1['event_type_list'][i_b][i].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEW\n",
    "\n",
    "len(df2)\n",
    "pid = 22\n",
    "i_b = df2.iloc[pid]['i_b']\n",
    "i = df2.iloc[pid]['i']\n",
    "i_b, i\n",
    "im_url, temp = cool_image(out2,i_b,i,opt2)\n",
    "\n",
    "im_url\n",
    "\n",
    "temp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash app running on http://127.0.0.1:4418/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17637/3891269842.py:62: DeprecationWarning:\n",
      "\n",
      "getsize is deprecated and will be removed in Pillow 10 (2023-07-01). Use getbbox or getlength instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "run_dash_app(fig_tsne1,out1,opt1,df1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT DAM --> none-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p19-rand/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='', freeze='', ES_pat=100, setting='rand', test_center='', split='', log='log.txt', user_prefix='[Q10-DA__base-concat]', pos_alpha=1.0, epoch=50, batch_size=128, lr=0.01, smooth=0.0, weight_decay=0.1, event_enc=0, time_enc='concat', te_d_mark=8, te_d_time=8, te_d_rnn=256, te_d_inner=16, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=False, num_states=1, noise=False, mod='none', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=1, w_time=1.0, sample_label=1, w_pos_label=0.5, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p19/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'freeze': '', 'ES_pat': 100, 'setting': 'rand', 'test_center': '', 'split': '', 'log': 'log.txt', 'user_prefix': '[Q10-DA__base-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 128, 'lr': 0.01, 'smooth': 0.0, 'weight_decay': 0.1, 'event_enc': 0, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 8, 'te_d_rnn': 256, 'te_d_inner': 16, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': False, 'num_states': 1, 'noise': False, 'mod': 'none', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 1, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 0.5, 'w_sample_label': 100.0}, date='22-02-23--16-18-04', run_id='1589967', dataset='P19', str_config='-rand', run_name='[Q10-DA__base-concat]1589967', run_path='/mlodata1/hokarami/tedam/p19-rand/[Q10-DA__base-concat]1589967/', device=device(type='cuda'), INPUT='DAM', OUTPUT='none-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.0771\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    }
   ],
   "source": [
    "run_path =  \"hokarami/TEEDAM_supervised/lzvf7erg\" # [Q20-DA__base-concat]1586915\n",
    "\n",
    "# p19\n",
    "run_path =  \"hokarami/TEEDAM_supervised/467tzbt1\" # [Q10-DA__base-concat]1589967\n",
    "\n",
    "\n",
    "\n",
    "model2, opt2, run2 = read_from_wandb(run_path)\n",
    "dict_metrics2, out2 = Main.valid_epoch_tsne(model2, opt2.validloader, opt2.pred_loss_func, opt2)\n",
    "X_tsne2, X_tsne_split2 = compute_tsne(out2['r_enc_list'], model2)\n",
    "\n",
    "res_labels = opt2.dict_map_events.keys()\n",
    "\n",
    "df2 = build_df(out2,opt2, X_tsne2)\n",
    "fig_tsne2 = plot_tsne(df2,title=run2.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "run_dash_app(fig_tsne2,out2,opt2,df2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot subset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K nearest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head(2)\n",
    "df2.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 9/336 [00:00<00:03, 83.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 32/336 [00:00<00:03, 101.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|        | 56/336 [00:00<00:02, 110.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|       | 80/336 [00:00<00:02, 109.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|       | 103/336 [00:00<00:02, 109.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|      | 128/336 [00:01<00:01, 113.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|     | 152/336 [00:01<00:01, 113.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|    | 176/336 [00:01<00:01, 114.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 200/336 [00:01<00:01, 114.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|   | 224/336 [00:02<00:00, 113.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|  | 248/336 [00:02<00:00, 114.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|  | 272/336 [00:02<00:00, 114.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%| | 296/336 [00:02<00:00, 115.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|| 320/336 [00:02<00:00, 113.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 336/336 [00:03<00:00, 111.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "n_knn=10\n",
    "\n",
    "pid_positive = list(df1[df1.color_true=='Positive Samples'].index)\n",
    "\n",
    "list_sim_score1 = []\n",
    "list_sim_score2 = []\n",
    "\n",
    "X1 = np.concatenate(out1['r_enc_list'],axis=0)[:,:model1.d_out_te]\n",
    "X2 = np.concatenate(out2['r_enc_list'],axis=0)[:,:]\n",
    "\n",
    "for pid in tqdm( pid_positive ):\n",
    "    id_origin = pid\n",
    "\n",
    "    knn_pids = find_knn_pids (X1, id_origin, n_knn=n_knn)\n",
    "\n",
    "    sim_score, list_summary = cal_similarity(df1, out1, pid, knn_pids)    \n",
    "    list_sim_score1.append(sim_score)\n",
    "\n",
    "    knn_pids = find_knn_pids (X2, id_origin, n_knn=n_knn)\n",
    "    sim_score, list_summary = cal_similarity(df2, out2, pid, knn_pids)    \n",
    "    list_sim_score2.append(sim_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.81876135, 0.08549328)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(0.7836602, 0.0887964)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.035101090158735006"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(list_sim_score1), np.std(list_sim_score1)\n",
    "np.mean(list_sim_score2), np.std(list_sim_score2)\n",
    "\n",
    "diff = np.array(list_sim_score1) - np.array(list_sim_score2)\n",
    "diff.sum()/len(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clusters = [\n",
    "\n",
    "[1715, 1212, 957, 834, 1401, 1532, 33, 514, 559, 1493],\n",
    "[1715, 1542, 808, 957, 1541, 1296, 252, 978, 34, 1204]\n",
    "\n",
    "\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "df = df1\n",
    "out = out1\n",
    "\n",
    "fig2 = go.Figure()\n",
    "for i_c, cluster in enumerate(clusters):\n",
    "    list_summary = []\n",
    "    for pid in cluster:\n",
    "        \n",
    "\n",
    "        i_b = df.iloc[pid]['i_b']\n",
    "        i = df.iloc[pid]['i']\n",
    "\n",
    "        ev = out['event_type_list'][i_b][i]\n",
    "        t = out['event_time_list'][i_b][i]\n",
    "        st=out['state_time_list'][i_b][i]\n",
    "        \n",
    "        P = st.int().max().item() + 1\n",
    "\n",
    "        M = event2mat(ev,t,P)\n",
    "\n",
    "        \n",
    "\n",
    "        vector = M.sum(1)/M.shape[1]*24\n",
    "\n",
    "        \n",
    "        list_summary.append(vector)\n",
    "        \n",
    "\n",
    "    dotp = [ np.dot(j,list_summary[0])/(np.linalg.norm(j) * np.linalg.norm(list_summary[0])) for  j in list_summary]\n",
    "    np.mean( dotp )\n",
    "\n",
    "    vec_mean = np.mean(list_summary,axis=0)\n",
    "    vec_std = np.std(list_summary,axis=0)\n",
    "\n",
    "    # sum(vec_std)\n",
    "\n",
    "    \n",
    "    _ = fig2.add_trace(go.Bar(\n",
    "        name=f'Cluster {i_c}',\n",
    "        x=list(res_labels), y=vec_mean,\n",
    "        error_y=dict(type='data', array=vec_std)\n",
    "    ))\n",
    "\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dotp = [ np.dot(j,list_summary[0])/(np.linalg.norm(j) * np.linalg.norm(list_summary[0])) for  j in list_summary]\n",
    "dotp\n",
    "np.mean( dotp )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paper2022",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ca5b395ee1d8a1cd2783c3fccc5aaaf2f1d95e614c8b133e284cded792af89cd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
