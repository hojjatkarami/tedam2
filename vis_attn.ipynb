{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activate line execution\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# general\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "# import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "import pickle\n",
    "\n",
    "# plotly\n",
    "import plotly.express as px  # (version 4.7.0 or higher)\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import custom libraries\n",
    "import sys\n",
    "# sys.path.append(\"C:\\\\DATA\\\\Tasks\\\\lib\\\\hk\")\n",
    "# import hk_utils\n",
    "\n",
    "# folder paths\n",
    "ADD_DATA = \"C:\\\\DATA\\\\data\\\\raw\\\\mimic4\\\\lookup\\\\\"\n",
    "ADD_DATA_proc = \"C:/DATA/data/processed/\"\n",
    "\n",
    "\n",
    "PATH_PAPER = \"C:\\\\DATA\\\\Tasks\\\\220704\\\\Alternate-Transactions-Articles-LaTeX-template\\\\images\\\\\"\n",
    "\n",
    "\n",
    "PATH_SYS=\"/mlodata1/hokarami/tedam/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries for THP\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import transformer.Constants as Constants\n",
    "import Utils\n",
    "\n",
    "# from preprocess.Dataset import get_dataloader, get_dataloader2\n",
    "# from transformer.Models import Transformer\n",
    "# from transformer.hk_transformer import Transformer\n",
    "from tqdm import tqdm\n",
    "\n",
    "# from torchinfo import summary\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "# torch.cuda.empty_cache()\n",
    "# torch.cuda.memory_allocated()\n",
    "# torch.cuda.memory_reserved()\n",
    "\n",
    "from sklearn import metrics\n",
    "# from hk_pytorch import save_checkpoint,load_checkpoint\n",
    "# import hk_pytorch\n",
    "\n",
    "\n",
    "# from custom2 import myparser\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Main\n",
    "import webbrowser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans,AgglomerativeClustering,DBSCAN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import integrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sudo conda install -c conda-forge dash --name paper2022\n",
    "# sudo conda install -c conda-forge jupyter-dash --name paper2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsnecuda import TSNE\n",
    "from MulticoreTSNE import MulticoreTSNE as TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install wandb -qqq\n",
    "import wandb\n",
    "# wandb.login()\n",
    "api = wandb.Api()\n",
    "import os\n",
    "\n",
    "os.environ[\"WANDB_API_KEY\"] = \"0f780ac8a470afe6cb7fc474ff3794772c660465\"\n",
    "\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"jup_res\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Project is specified by <entity/project-name>\n",
    "def dl_runs(all_runs, selected_tag=None):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    summary_list, config_list, name_list, path_list = [], [], [], []\n",
    "    for run in all_runs: \n",
    "\n",
    "        if (selected_tag not in run.tags) and (selected_tag is not None):\n",
    "            continue\n",
    "        # .summary contains the output keys/values for metrics like accuracy.\n",
    "        #  We call ._json_dict to omit large files \n",
    "        summary_list.append(run.summary._json_dict)\n",
    "\n",
    "        # .config contains the hyperparameters.\n",
    "        #  We remove special values that start with _.\n",
    "        \n",
    "\n",
    "        config_list.append(\n",
    "            {k: v for k,v in run.config.items()\n",
    "            if not k.startswith('_')})\n",
    "\n",
    "        # .name is the human-readable name of the run.\n",
    "        name_list.append(run.name)\n",
    "        path_list.append(run.path)\n",
    "\n",
    "    runs_df = pd.DataFrame({\n",
    "        \"summary\": summary_list,\n",
    "        \"config\": config_list,\n",
    "        \"name\": name_list,\n",
    "        \"path\": path_list\n",
    "\n",
    "        })\n",
    "\n",
    "    # runs_df.to_csv(\"project.csv\")\n",
    "    return runs_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import base64\n",
    "import pickle\n",
    "import gzip\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from jupyter_dash import JupyterDash\n",
    "from dash import dcc, html, Input, Output, no_update\n",
    "import dash_bootstrap_components as dbc\n",
    "# sudo conda install -c conda-forge dash-bootstrap-components jupyter-dash --name paper2022\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from PIL import ImageDraw, Image\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Helper functions\n",
    "def np_image_to_base64(im_matrix,scale=4):\n",
    "\n",
    "    im_matrix = np.repeat(np.repeat(im_matrix,scale,axis=0),scale,axis=1)\n",
    "    im = Image.fromarray(im_matrix)\n",
    "    buffer = io.BytesIO()\n",
    "    im.save(buffer, format=\"jpeg\")\n",
    "    encoded_image = base64.b64encode(buffer.getvalue()).decode()\n",
    "    im_url = \"data:image/jpeg;base64, \" + encoded_image\n",
    "    return im_url\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def binary_matrix_to_image(binary_matrix, grid_size=8, border_size=1):\n",
    "    # Calculate the size of the output image based on the size of the binary matrix\n",
    "    height, width = binary_matrix.shape[:2]\n",
    "    image_width = width * grid_size + (width + 1) * border_size\n",
    "    image_height = height * grid_size + (height + 1) * border_size\n",
    "    \n",
    "    # Create a new image and a draw object to draw the grid and borders\n",
    "    image = Image.new('RGB', (image_width, image_height), color='black')\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    \n",
    "    # Draw the white grids\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            if binary_matrix[i, j] == 1:\n",
    "                x1 = j * (grid_size + border_size) + border_size\n",
    "                y1 = i * (grid_size + border_size) + border_size\n",
    "                x2 = x1 + grid_size\n",
    "                y2 = y1 + grid_size\n",
    "                draw.rectangle((x1, y1, x2, y2), fill='white')\n",
    "                \n",
    "    \n",
    "    # Draw the black borders\n",
    "    for i in range(height + 1):\n",
    "        y = i * (grid_size + border_size)\n",
    "        draw.line((0, y, image_width, y), fill='white', width=border_size)\n",
    "        \n",
    "    for j in range(width + 1):\n",
    "        x = j * (grid_size + border_size)\n",
    "        draw.line((x, 0, x, image_height), fill='white', width=border_size)\n",
    "        \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_rgb(num, **rgb_params):\n",
    "    \n",
    "    \n",
    "    \n",
    "    if len(rgb_params)>0:\n",
    "\n",
    "        normalized = (num - rgb_params['offset'])/rgb_params['range']\n",
    "\n",
    "        \n",
    "        # Map to a color between blue, gray, and red\n",
    "        rgb_lower = rgb_params['rgb_lower']\n",
    "        rgb_middle = rgb_params['rgb_middle']\n",
    "        rgb_upper = rgb_params['rgb_upper']\n",
    "    else:\n",
    "    \n",
    "        # Normalize to the range of 0 to 1\n",
    "    \n",
    "    \n",
    "    \n",
    "        normalized = (num + 2) / 4\n",
    "        \n",
    "        # Map to a color between blue, gray, and red\n",
    "        rgb_lower = (0, 0, 255,1)\n",
    "        rgb_middle = (128, 128, 128,1)\n",
    "        rgb_upper = (255, 0, 0,1)\n",
    "    \n",
    "    if normalized < 0.5:\n",
    "        r = int((2 * normalized) * rgb_middle[0] + (1 - 2 * normalized) * rgb_lower[0])\n",
    "        g = int((2 * normalized) * rgb_middle[1] + (1 - 2 * normalized) * rgb_lower[1])\n",
    "        b = int((2 * normalized) * rgb_middle[2] + (1 - 2 * normalized) * rgb_lower[2])\n",
    "        a = int((2 * normalized) * rgb_middle[3] + (1 - 2 * normalized) * rgb_lower[3])\n",
    "    else:\n",
    "        r = int((2 * normalized - 1) * rgb_upper[0] + (2 - 2 * normalized) * rgb_middle[0])\n",
    "        g = int((2 * normalized - 1) * rgb_upper[1] + (2 - 2 * normalized) * rgb_middle[1])\n",
    "        b = int((2 * normalized - 1) * rgb_upper[2] + (2 - 2 * normalized) * rgb_middle[2])\n",
    "        a = int((2 * normalized - 1) * rgb_upper[3] + (2 - 2 * normalized) * rgb_middle[3])\n",
    "    \n",
    "    # if normalized>0.5:\n",
    "    #     print(normalized,a,rgb_upper[3])\n",
    "    #     term\n",
    "    return (r, g, b,a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import ImageDraw, Image, ImageFont\n",
    "\n",
    "def binary_matrix_to_image(binary_matrix, row_labels=None, font_path=None, grid_size=10, border_size=1, label_size=15, is_fill=True,**rgb_params):\n",
    "    # Add a dummy column to the binary matrix\n",
    "    ddd=2\n",
    "\n",
    "    height, width = binary_matrix.shape[:2]\n",
    "    binary_matrix = np.concatenate((np.zeros((height, ddd)), binary_matrix), axis=1)\n",
    "    width += ddd\n",
    "    \n",
    "    # Calculate the size of the output image based on the size of the binary matrix\n",
    "    image_width = (width + 1) * grid_size + (width + 2) * border_size\n",
    "    image_height = height * grid_size + (height + 1) * border_size\n",
    "    \n",
    "    # Create a new image and a draw object to draw the grid and borders\n",
    "    image = Image.new('RGBA', (image_width, image_height), color=(0,0,0,0))\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    \n",
    "    # Draw the white grids\n",
    "    for i in range(height):\n",
    "        for j in range(1, width):\n",
    "            # if binary_matrix[i, j] == 1:\n",
    "            #     x1 = j * (grid_size + border_size) + border_size\n",
    "            #     y1 = i * (grid_size + border_size) + border_size\n",
    "            #     x2 = x1 + grid_size\n",
    "            #     y2 = y1 + grid_size\n",
    "            #     draw.rectangle((x1, y1, x2, y2), fill='white')\n",
    "\n",
    "            if binary_matrix[i, j] != 0:\n",
    "                x1 = j * (grid_size + border_size) + border_size\n",
    "                y1 = i * (grid_size + border_size) + border_size\n",
    "                x2 = x1 + grid_size\n",
    "                y2 = y1 + grid_size\n",
    "\n",
    "                int_color = ( int(binary_matrix[i, j]*96),\n",
    "                             int(binary_matrix[i, j]*96),\n",
    "                             int(binary_matrix[i, j]*96))\n",
    "\n",
    "                \n",
    "                int_color = map_to_rgb(binary_matrix[i, j], **rgb_params)\n",
    "                if is_fill:\n",
    "                    draw.rectangle((x1, y1, x2, y2), fill= int_color)\n",
    "                else:\n",
    "                    draw.rectangle((x1, y1, x2, y2), outline=int_color,width=2, fill= None)\n",
    "\n",
    "\n",
    "    # Draw the borders\n",
    "    color_border = (0,0,0,16)\n",
    "    for i in range(height + 1):\n",
    "        y = i * (grid_size + border_size)\n",
    "        draw.line((grid_size, y, image_width, y), fill=color_border, width=border_size)\n",
    "        \n",
    "    for j in range(width + 1):\n",
    "        x = j * (grid_size + border_size)\n",
    "        draw.line((x, 0, x, image_height), fill=color_border, width=border_size)\n",
    "\n",
    "    \n",
    "    # Draw the row labels\n",
    "    if row_labels is not None:\n",
    "        font = ImageFont.truetype(PATH_SYS+'arial.ttf', size=label_size)\n",
    "        max_label_width = max([font.getsize(str(label))[0] for label in row_labels])\n",
    "        label_x = 0\n",
    "        label_y = border_size\n",
    "        for i, label in enumerate(row_labels):\n",
    "            draw.text((label_x, label_y), str(label), font=font, fill='black',align=\"right\")\n",
    "            label_y += grid_size + border_size\n",
    "            # if i == 0:\n",
    "            #     label_x += max_label_width + border_size + grid_size\n",
    "        \n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "def create_barplot_image(data, labels, filename):\n",
    "    \"\"\"\n",
    "    Creates a bar plot image of the input data and saves it as a PNG file with the given filename.\n",
    "\n",
    "    Args:\n",
    "        data (numpy.ndarray): A 1D array of data to plot.\n",
    "        labels (list): A list of labels for each data point.\n",
    "        filename (str): The name of the output PNG file.\n",
    "\n",
    "    Returns:\n",
    "        PIL.Image.Image: A PIL image object of the bar plot.\n",
    "    \"\"\"\n",
    "    # Create a figure and axis object\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Create a bar plot\n",
    "    _ = ax.bar(np.arange(len(data)), data)\n",
    "\n",
    "    # Set axis labels and title\n",
    "    _ = ax.set_xlabel('Index')\n",
    "    _ = ax.set_ylabel('Value')\n",
    "    _ = ax.set_title('Bar plot')\n",
    "\n",
    "    # Set x-tick labels\n",
    "    _ = ax.set_xticks(np.arange(len(data)))\n",
    "    _ = ax.set_xticklabels(labels, rotation=45)\n",
    "\n",
    "    # Save the plot as a PNG file\n",
    "    _ = fig.savefig(filename)\n",
    "    plt.close(fig)\n",
    "    # Load the PNG image and return as a PIL image object\n",
    "    return Image.open(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def event2mat(event_type, event_time,P):\n",
    "\n",
    "    m = event_type.sum(1)>0 # False are masked\n",
    "    e=event_type[m,:]\n",
    "    t=event_time[m]\n",
    "    # print(t)\n",
    "\n",
    "    indices = e.nonzero()\n",
    "    indices[:,0] = t[indices[:,0]].int()\n",
    "    # print(t[indices[:,0]])\n",
    "    # print(indices[:,0])\n",
    "\n",
    "    M = torch.zeros((P, e.shape[-1]))\n",
    "    M[indices[:,0],indices[:,1]]=1\n",
    "\n",
    "    return M.detach().cpu().numpy().transpose() # [M,P]\n",
    "\n",
    "def att_event2mat(event_type, event_time,P, tee_att):\n",
    "    # tee_att [h,L]\n",
    "    h = tee_att.shape[0]\n",
    "\n",
    "    m = event_type.sum(1)>0 # False are masked\n",
    "    e=event_type[m,:]\n",
    "    t=event_time[m]\n",
    "    tee_att = tee_att[:,m]\n",
    "\n",
    "    # indices = e.nonzero()\n",
    "    # indices[:,0] = t[indices[:,0]].int()\n",
    "\n",
    "    # M = torch.zeros(h, len(t))\n",
    "    M = torch.zeros(( h , P))\n",
    "\n",
    "    M[:,t.long()]=tee_att\n",
    "\n",
    "    return M.detach().cpu().numpy() # [h,L]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state2mat(time, mod,M):\n",
    "    P = time.int().max().item() + 1\n",
    "\n",
    "    M = torch.zeros(P, M)\n",
    "    M[time[mod!=0].long(), mod[mod!=0]-1] = 1\n",
    "\n",
    "\n",
    "    return M.cpu().numpy().transpose() # [M,P]\n",
    "\n",
    "def att_state2mat(time, mod,M, dam_att):\n",
    "    # dam_att [P,h]\n",
    "    # h = dam_att.shape[-1]\n",
    "\n",
    "    # dam_att = dam_att[:,0] # [P]\n",
    "    P = time.int().max().item() + 1\n",
    "\n",
    "    M = torch.zeros(P, M)\n",
    "    \n",
    "    M[time[mod!=0].long(),  mod[mod!=0]-1] = dam_att[mod!=0]\n",
    "\n",
    "\n",
    "    return M.cpu().numpy().transpose() # [M,P]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cool_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cool_image(out,i_b,i,opt,CROP=0):\n",
    "\n",
    "    att_mat_img=None\n",
    "    img_ev=None\n",
    "\n",
    "    label_size = 12\n",
    "    rgb_params_values = {\n",
    "    'rgb_lower':(0, 0, 255,255),\n",
    "    'rgb_middle':(128, 128, 128,255),\n",
    "    'rgb_upper':(255, 0, 0,255),\n",
    "    'offset':-2,\n",
    "    'range':4\n",
    "\n",
    "    }\n",
    "    rgb_params_events = {\n",
    "    'rgb_lower':(255, 255, 255,255),\n",
    "    'rgb_middle':(196, 196, 196,255),\n",
    "    'rgb_upper':(128, 128, 128,255),\n",
    "    'offset':0,\n",
    "    'range':1\n",
    "\n",
    "    }\n",
    "    rgb_params_events_pred = {\n",
    "    'rgb_lower':(255, 255, 255,255),\n",
    "    'rgb_middle':(128, 255, 128,255),\n",
    "    'rgb_upper':(0, 255, 0,255),\n",
    "    'offset':0,\n",
    "    'range':1\n",
    "\n",
    "    }\n",
    "    # rgb_params_att = {\n",
    "    #     'rgb_lower':(64, 64, 64,0),\n",
    "    #     'rgb_middle':(164, 164, 32,32),\n",
    "    #     'rgb_upper':(255, 255, 0,255),\n",
    "    #     'offset':0,\n",
    "    #     'range':0.1\n",
    "\n",
    "    # }\n",
    "\n",
    "\n",
    "    rgb_params_att = {\n",
    "        'rgb_lower':(128, 128, 128,32),\n",
    "        # 'rgb_middle':(8, 164, 32,196),\n",
    "        'rgb_upper':(0, 255, 0,255),\n",
    "        'offset':0,\n",
    "        'range':0.2\n",
    "\n",
    "    }\n",
    "\n",
    "\n",
    "    rgb_params_att['rgb_middle'] = tuple([(int(i+j)/2) for i,j in zip(rgb_params_att['rgb_lower'],rgb_params_att['rgb_upper'])])\n",
    "    rgb_params_att['rgb_middle']\n",
    "    if hasattr(opt,'dict_map_states' ):\n",
    "        state_labels = list(opt.dict_map_states.keys())[CROP:]\n",
    "        # state_labels = [str(i) for i in range(len(opt.dict_map_states))]\n",
    "\n",
    "    if hasattr(opt,'dict_map_events' ):\n",
    "        offset=len(opt.dict_map_states.keys())-len(opt.dict_map_events.keys())\n",
    "        event_labels = list(opt.dict_map_events.keys())\n",
    "        # event_labels = [str(i+offset) for i in range(len(opt.dict_map_events))]\n",
    "\n",
    "\n",
    "    # event_labels = opt.dict_map_events.keys()\n",
    "    \n",
    "\n",
    "    # if len(out['event_type_list']) > 0:\n",
    "    \n",
    "\n",
    "    if len(out['state_time_list']) > 0:\n",
    "        st=out['state_time_list'][i_b][i]\n",
    "        sm=out['state_mod_list'][i_b][i]\n",
    "        sv=( out['state_value_list'][i_b][i] )\n",
    "\n",
    "        dam_att = out['list_DAM_att'][i_b][i] # [P,h]\n",
    "\n",
    "        n_state_mods = len(opt.dict_map_states.keys())\n",
    "\n",
    "        # ev.shape, t.shape\n",
    "        P = st.int().max().item() + 1\n",
    "\n",
    "        \n",
    "        # list_img_att = []\n",
    "        # for i_head in range(dam_att.shape[-1]):\n",
    "        #     binary_matrix = att_state2mat(st, sm, n_state_mods, dam_att[:,i_head])\n",
    "        #     img_att = binary_matrix_to_image(binary_matrix, row_labels=state_labels, font_path=None, grid_size=10, border_size=1, label_size=label_size,is_fill=False,**rgb_params_att)\n",
    "        #     list_img_att.append(img_att.convert(\"RGB\"))\n",
    "\n",
    "        binary_matrix = att_state2mat(st, sm, n_state_mods, dam_att.sum(1))[CROP:,:]\n",
    "        # print(f'binary_matrix.shape={binary_matrix.shape}')\n",
    "        \n",
    "        img_att = binary_matrix_to_image(binary_matrix, row_labels=state_labels, font_path=None, grid_size=10, border_size=2, label_size=label_size,is_fill=False,**rgb_params_att)\n",
    "\n",
    "\n",
    "        binary_matrix = att_state2mat(st, sm, n_state_mods, sv)[CROP:,:]\n",
    "        img_val = binary_matrix_to_image(binary_matrix, row_labels=state_labels, font_path=None, grid_size=10, border_size=2, label_size=label_size,is_fill=True,**rgb_params_values)\n",
    "\n",
    "        merged_img = Image.new('RGBA', img_val.size)\n",
    "        merged_img = Image.alpha_composite(merged_img, img_val)\n",
    "        tempp=state_labels\n",
    "        merged_img = Image.alpha_composite(merged_img, img_att)#.convert(\"RGB\")\n",
    "\n",
    "        if opt.event_enc:\n",
    "            ev = out['event_type_list'][i_b][i]\n",
    "            t = out['event_time_list'][i_b][i]\n",
    "            \n",
    "            ev_pred = out['next_event_type_list'][i_b][i]\n",
    "\n",
    "\n",
    "            m = (ev.sum(1)>0).sum() # False are masked\n",
    "            ev=ev[:m]\n",
    "            ev_pred=ev_pred[:m-1] # for 2 to L-1\n",
    "            ev_pred = nn.functional.pad(ev_pred,(0,0,1,0))\n",
    "            t=t[:m]\n",
    "\n",
    "\n",
    "            # print(f'm={m}')\n",
    "\n",
    "            # print(f'ev.shape={ev.shape}')\n",
    "            # print(f'ev_pred.shape={ev_pred.shape}')\n",
    "\n",
    "                                # plot attention of last event\n",
    "            tee_att = out['list_TE_att'][i_b][i,:,m-1,:m] # [h,L]\n",
    "            # print(f'tee_att.shape={tee_att.shape}')\n",
    "            # # print(tee_att)\n",
    "            \n",
    "\n",
    "                                \n",
    "            # att_names = [f'h{i}' for i in range(tee_att.shape[0])]\n",
    "            # rgb_params_att['range']=tee_att.max()\n",
    "            # binary_matrix = att_event2mat(ev, t,P, tee_att)\n",
    "\n",
    "            # img_att_ev = binary_matrix_to_image(binary_matrix, row_labels=att_names, font_path=None, grid_size=10, border_size=1, label_size=label_size,is_fill=False,**rgb_params_att)\n",
    "            \n",
    "            # merged_img2 = Image.new('RGBA', (merged_img.size[0],merged_img.size[1]+img_att_ev.size[1]))\n",
    "            # merged_img2.paste(merged_img, (0,0))\n",
    "            # merged_img2.paste(img_att_ev, (0,merged_img.size[1]))\n",
    "            # merged_img = merged_img2\n",
    "\n",
    "\n",
    "\n",
    "                                # plot attention matrix\n",
    "            m = (ev.sum(1)>0).sum() # False are masked\n",
    "            tee_att_mat = out['list_TE_att'][i_b][i,:,:m,:m].mean(0) # [L,L]\\\n",
    "            # tee = out['list_TE_att'][i_b][i][:1,:m,:m].mean(0)#.cpu().numpy() \n",
    "            print('A1',tee_att_mat)\n",
    "            # tee_att_mat[tee_att_mat<0.02]=0\n",
    "            # print(f'tee_att_mat.shape={tee_att_mat.shape}')\n",
    "            print('aaaa',tee_att_mat)\n",
    "\n",
    "            # # print(tee_att_mat.sum(1))\n",
    "            scaler=torch.arange(1,m+1)[:,None]\n",
    "            print(scaler)\n",
    "            # scaler= (1/tee_att_mat.max(1)[0])[:,None]\n",
    "            tee_att_mat *= scaler\n",
    "            print('A2',tee_att_mat)\n",
    "\n",
    "            tee_att_mat[tee_att_mat<0.02]=0\n",
    "\n",
    "            print(type(tee_att_mat))\n",
    "            rgb_params_att['range'] = tee_att_mat.max()\n",
    "            # # print(tee_att_mat.max(1))\n",
    "            print('dafas',tee_att_mat)\n",
    "            # # print(tee_att_mat[1])\n",
    "\n",
    "            tee_att_mat_spaced = att_event2mat(ev, t,P, tee_att_mat)\n",
    "            # print(f'tee_att_mat_spaced.shape={tee_att_mat_spaced.shape}')\n",
    "\n",
    "            binary_matrix = tee_att_mat_spaced\n",
    "            img_val = binary_matrix_to_image(binary_matrix, row_labels=None, font_path=None, grid_size=10, border_size=1, label_size=label_size,is_fill=True,**rgb_params_att)\n",
    "\n",
    "            att_mat_img = Image.new('RGBA', img_val.size)\n",
    "            att_mat_img = Image.alpha_composite(att_mat_img, img_val)\n",
    "\n",
    "\n",
    "            # t=torch.arange(m)\n",
    "            # PP = t.int().max().item() + 1\n",
    "\n",
    "            # print(t[:m])\n",
    "            ev_matrix = event2mat(ev,t,P)\n",
    "            # print(f'ev_matrix.shape={ev_matrix.shape}')\n",
    "            # print(P)\n",
    "            img_ev = binary_matrix_to_image(ev_matrix, row_labels=event_labels, font_path=None, grid_size=10, border_size=1, label_size=label_size,**rgb_params_events)\n",
    "\n",
    "\n",
    "            ev_pred_matrix = event2mat(ev_pred,t,P)\n",
    "            # print(f'ev_pred_matrix.shape={ev_pred_matrix.shape}')\n",
    "\n",
    "            img_ev_pred = binary_matrix_to_image(ev_pred_matrix, row_labels=None, font_path=None, grid_size=10, border_size=1,is_fill=False, label_size=label_size,**rgb_params_events_pred)\n",
    "            \n",
    "            merged_img3 = Image.new('RGBA', (att_mat_img.size[0],att_mat_img.size[1]+img_ev.size[1]))\n",
    "            merged_img3.paste(att_mat_img, (0,0))\n",
    "            merged_img3.paste(img_ev, (0,att_mat_img.size[1]))\n",
    "            merged_img3.paste(img_ev_pred, (0,att_mat_img.size[1]))\n",
    "\n",
    "            temp_img = Image.new('RGBA', img_ev.size)\n",
    "            temp_img = Image.alpha_composite(temp_img, img_ev)\n",
    "            temp_img = Image.alpha_composite(temp_img, img_ev_pred)#.convert(\"RGB\")\n",
    "\n",
    "            merged_img3.paste(temp_img, (0,att_mat_img.size[1]))\n",
    "\n",
    "            att_mat_img = merged_img3\n",
    "\n",
    "\n",
    "\n",
    "    else:\n",
    "        \n",
    "        ev = out['event_type_list'][i_b][i]\n",
    "        t = out['event_time_list'][i_b][i]\n",
    "        P = t.int().max().item() + 1\n",
    "        m = (ev.sum(1)>0).sum() # False are masked\n",
    "\n",
    "        tee_att = out['list_TE_att'][i_b][i,:,m-2,:m] # [h,L]\n",
    "        att_names = [f'h{i}' for i in range(tee_att.shape[0])]\n",
    "        rgb_params_att['range']=tee_att.max()\n",
    "\n",
    "        binary_matrix = event2mat(ev,t,P)\n",
    "        img_ev = binary_matrix_to_image(binary_matrix, row_labels=event_labels, font_path=None, grid_size=10, border_size=1, label_size=label_size,**rgb_params_events)\n",
    "\n",
    "        binary_matrix = att_event2mat(ev, t,P, tee_att)\n",
    "        img_att_ev = binary_matrix_to_image(binary_matrix, row_labels=None, font_path=None, grid_size=10, border_size=1, label_size=label_size,is_fill=False,**rgb_params_att)\n",
    "            \n",
    "        # print(binary_matrix.sum())\n",
    "        merged_img = Image.new('RGB', (img_ev.size[0],img_ev.size[1]+img_att_ev.size[1]))\n",
    "        merged_img.paste(img_ev, (0,0))\n",
    "        merged_img.paste(img_att_ev, (0,img_ev.size[1]))\n",
    "\n",
    "\n",
    "\n",
    "        # plot attention matrix\n",
    "        m = (ev.sum(1)>0).sum() # False are masked\n",
    "        tee_att_mat = out['list_TE_att'][i_b][i,:,:m,:m].mean(0) # [L,L]\n",
    "\n",
    "        binary_matrix = tee_att_mat\n",
    "        img_val = binary_matrix_to_image(binary_matrix, row_labels=None, font_path=None, grid_size=10, border_size=1, label_size=label_size,is_fill=True,**rgb_params_att)\n",
    "        \n",
    "        att_mat_img = Image.new('RGBA', img_val.size)\n",
    "        att_mat_img = Image.alpha_composite(att_mat_img, img_val)\n",
    "\n",
    "\n",
    "    return merged_img,(att_mat_img,img_ev)#(img_att.convert(\"RGB\"), img_val.convert(\"RGB\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_summary(df,out, point_ids,res_labels, fig=None):\n",
    "\n",
    "    if fig is None:\n",
    "        fig = go.Figure()\n",
    "\n",
    "\n",
    "\n",
    "    list_summary = []\n",
    "    for pid in point_ids:\n",
    "\n",
    "        i_b = int(df.iloc[pid]['i_b'])\n",
    "        i = int(df.iloc[pid]['i'])\n",
    "\n",
    "        ev = out['event_type_list'][i_b][i]\n",
    "        t = out['event_time_list'][i_b][i]\n",
    "        \n",
    "\n",
    "        P = t.int().max().item() + 1\n",
    "\n",
    "        M = event2mat(ev,t,P)\n",
    "\n",
    "\n",
    "        vector = M.sum(1)/M.shape[1]*24\n",
    "        list_summary.append(vector)\n",
    "\n",
    "    vec_mean = np.mean(list_summary,axis=0)\n",
    "    vec_std = np.std(list_summary,axis=0)\n",
    "\n",
    "    sum(vec_std)\n",
    "\n",
    "    \n",
    "    _ = fig.add_trace(go.Bar(\n",
    "        name=f'Summary',\n",
    "        x=list(res_labels), y=vec_mean,\n",
    "        error_y=dict(type='data', array=vec_std)\n",
    "    ))\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_from_wandb(run_path, consider_sample_labels = False):\n",
    "\n",
    "    run = api.run(run_path)\n",
    "    \n",
    "    # for file in run.files():\n",
    "    #     file.download(replace=True,root=f'./local/{run_path}/')\n",
    "    for file in run.files():\n",
    "        if 'best_model' in file.name or 'opt.pkl' in file.name:\n",
    "\n",
    "            try:\n",
    "                file.download(replace=True, root=f'.local/{run_path}')\n",
    "\n",
    "            except:\n",
    "                print('ERROR')\n",
    "                pass\n",
    "    opt = pickle.load(open(f'.local/{run_path}/opt.pkl','rb'))\n",
    "    \n",
    "    if consider_sample_labels:\n",
    "        opt.sample_label=True\n",
    "\n",
    "\n",
    "    opt = Main.config(opt, justLoad=True)\n",
    "    if not hasattr(opt,'diag_offset'):\n",
    "        opt.diag_offset=1\n",
    "        print('ATTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTT')\n",
    "    checkpoint = torch.load(f'.local/{run_path}/best_model.pkl')\n",
    "\n",
    "    model = Main.ATHP(\n",
    "       n_marks=opt.num_marks,\n",
    "        TE_config = opt.TE_config,\n",
    "        DAM_config = opt.DAM_config,\n",
    "        NOISE_config = opt.NOISE_config,\n",
    "\n",
    "        CIF_config = opt.CIF_config,\n",
    "        next_time_config = opt.next_time_config,\n",
    "        next_type_config = opt.next_type_config,\n",
    "        label_config = opt.label_config,\n",
    "\n",
    "        demo_config = opt.demo_config,\n",
    "\n",
    "        device=opt.device,\n",
    "        diag_offset=opt.diag_offset\n",
    "    )\n",
    "\n",
    "    _ = model.to(opt.device)\n",
    "    _ = model.load_state_dict(checkpoint['model_state_dict'], strict=False)\n",
    "    _ = model.eval()\n",
    "\n",
    "    return model, opt, run"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_knn_pids (X, id_origin, n_knn=10):\n",
    "\n",
    "    # X [N,d] np.array\n",
    "    r = np.sqrt(   ((X-X[id_origin])**2).sum(-1)   )\n",
    "    knn_pids = list(np.argpartition(r,n_knn)[:n_knn])\n",
    "\n",
    "    if id_origin not in knn_pids:\n",
    "        print('bad')\n",
    "    else:\n",
    "        knn_pids.remove(id_origin)\n",
    "\n",
    "    # print(X.shape)\n",
    "    # term\n",
    "\n",
    "    \n",
    "    # x0 = df.iloc[id_origin]['x']\n",
    "    # y0 = df.iloc[id_origin]['y']\n",
    "\n",
    "    # df['r'] = df.apply(lambda row: ( (row['x']-x0)**2 + (row['y']-y0)**2  ), axis=1)\n",
    "\n",
    "    # knn_pids = list(df.nsmallest(n_knn,'r').index)\n",
    "\n",
    "\n",
    "    return knn_pids\n",
    "\n",
    "def cal_similarity(df, out, pid, knn_pids):\n",
    "\n",
    "    list_summary = []\n",
    "    for pid in knn_pids:\n",
    "        \n",
    "\n",
    "        i_b = df.iloc[pid]['i_b']\n",
    "        i = df.iloc[pid]['i']\n",
    "\n",
    "        ev = out['event_type_list'][i_b][i]\n",
    "        t = out['event_time_list'][i_b][i]\n",
    "        st=out['state_time_list'][i_b][i]\n",
    "        \n",
    "        P = st.int().max().item() + 1\n",
    "\n",
    "        M = event2mat(ev,t,P)\n",
    "\n",
    "        \n",
    "\n",
    "        vector = M.sum(1)/M.shape[1]*24\n",
    "\n",
    "        \n",
    "        list_summary.append(vector)\n",
    "        \n",
    "\n",
    "    dotp = [ np.dot(j,list_summary[0])/(np.linalg.norm(j) * np.linalg.norm(list_summary[0])) for  j in list_summary]\n",
    "    sim_score = np.mean( dotp )\n",
    "\n",
    "\n",
    "    return sim_score, list_summary\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cif(out,i_b,i, fig=None):\n",
    "\n",
    "    ev = out['event_type_list'][i_b][i]\n",
    "    t = out['event_time_list'][i_b][i]\n",
    "\n",
    "\n",
    "    tee_att = out['list_TE_att'][i_b][i,:,-4,:] # [h,L]\n",
    "    cifs = out['list_intens_at_samples'][i_b][i]\n",
    "    taus = out['list_taus'][i_b][i]\n",
    "\n",
    "    y_cifs = out['list_true_intens_at_evs'][i_b][i] # [L-1] 2 to L\n",
    "\n",
    "    P = t.int().max().item() + 1\n",
    "\n",
    "    m = ev.sum(1)>0 # False are masked\n",
    "    m = m.sum().item()\n",
    "\n",
    "    \n",
    "    taus = taus[:m-1,:,:] + t[:m-1,None,None]\n",
    "    cifs = cifs[:m-1,:,:]\n",
    "    y_cifs = y_cifs[:m-1,:]  # 1 to L-1\n",
    "\n",
    "\n",
    "    n_cifs=cifs.shape[1]\n",
    "    # print(n_cifs,taus.shape, cifs.shape)\n",
    "\n",
    "    cifs = cifs.reshape(n_cifs,-1)[0] # [0] is the first cif\n",
    "    taus = taus.reshape(1,-1)[0]\n",
    "    y_cifs = y_cifs.reshape(n_cifs,-1)[0]\n",
    "\n",
    "    print(taus)\n",
    "    print(cifs)\n",
    "    # print(n_cifs,taus.shape, cifs.shape)\n",
    "    temp = torch.argsort(taus)\n",
    "\n",
    "    taus = taus[temp]\n",
    "    cifs = cifs[temp]\n",
    "\n",
    "\n",
    "    if fig==None:\n",
    "        fig=go.Figure()\n",
    "\n",
    "    _ = fig.add_trace(go.Scatter(x=taus,y=cifs))\n",
    "\n",
    "    # _ = fig.add_trace(go.Scatter(x=t[1:m],y=y_cifs*0+1,mode='markers'))\n",
    "    # _ = fig.add_trace(go.Scatter(x=t[1:m],y=t[1:m],mode='markers'))\n",
    "\n",
    "    # print(m)\n",
    "    # print(t[1:5])\n",
    "    # print(y_cifs[:4])\n",
    "\n",
    "    _ = fig.add_trace(go.Scatter(x=t[:m],y=t[:m]*0,mode='markers'))\n",
    "\n",
    "    _ = fig.add_trace(go.Scatter(x=t[1:m],y=y_cifs,mode='markers'))\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cif_cum(out,i_b,i, fig=None):\n",
    "\n",
    "    ev = out['event_type_list'][i_b][i]\n",
    "    t = out['event_time_list'][i_b][i]\n",
    "\n",
    "\n",
    "    tee_att = out['list_TE_att'][i_b][i,:,-4,:] # [h,L]\n",
    "    cifs = out['list_intens_at_samples'][i_b][i]\n",
    "    taus = out['list_taus'][i_b][i]\n",
    "\n",
    "    y_cifs = out['list_true_intens_at_evs'][i_b][i] # [L-1] 2 to L\n",
    "\n",
    "    P = t.int().max().item() + 1\n",
    "\n",
    "    m = ev.sum(1)>0 # False are masked\n",
    "    m = m.sum().item()\n",
    "\n",
    "    taus = taus[:m-1,:,:] + t[:m-1,None,None]\n",
    "    cifs = cifs[:m-1,:,:]\n",
    "    y_cifs = y_cifs[:m-1,:]  # 1 to L-1\n",
    "\n",
    "\n",
    "    n_cifs=cifs.shape[1]\n",
    "\n",
    "    cifs = cifs.reshape(n_cifs,-1)[0]\n",
    "    taus = taus.reshape(n_cifs,-1)[0]\n",
    "    y_cifs = y_cifs.reshape(n_cifs,-1)[0]\n",
    "\n",
    "    temp = torch.argsort(taus)\n",
    "\n",
    "    taus = taus[temp]\n",
    "    cifs = cifs[temp]\n",
    "\n",
    "    cifs_int = integrate.cumulative_trapezoid(cifs, taus, initial=0)/(taus)\n",
    "\n",
    "    if fig==None:\n",
    "        fig=go.Figure()\n",
    "\n",
    "    _ = fig.add_trace(go.Scatter(x=taus,y=cifs_int))\n",
    "\n",
    "    # _ = fig.add_trace(go.Scatter(x=t[1:m],y=y_cifs*0+1,mode='markers'))\n",
    "    # _ = fig.add_trace(go.Scatter(x=t[1:m],y=t[1:m],mode='markers'))\n",
    "\n",
    "    # print(m)\n",
    "    # print(t[1:5])\n",
    "    # print(y_cifs[:4])\n",
    "\n",
    "    _ = fig.add_trace(go.Scatter(x=t[:m],y=t[:m]*0,mode='markers'))\n",
    "\n",
    "    # _ = fig.add_trace(go.Scatter(x=t[1:m],y=y_cifs,mode='markers'))\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cif_cum(out,i_b,i, fig=None):\n",
    "\n",
    "    ev = out['event_type_list'][i_b][i]\n",
    "    t = out['event_time_list'][i_b][i]\n",
    "\n",
    "\n",
    "    tee_att = out['list_TE_att'][i_b][i,:,-4,:] # [h,L]\n",
    "    cifs = out['list_intens_at_samples'][i_b][i]\n",
    "    taus = out['list_taus'][i_b][i]\n",
    "\n",
    "    y_cifs = out['list_true_intens_at_evs'][i_b][i] # [L-1] 2 to L\n",
    "\n",
    "    P = t.int().max().item() + 1\n",
    "\n",
    "    m = ev.sum(1)>0 # False are masked\n",
    "    m = m.sum().item()\n",
    "\n",
    "    taus = taus[:m-1,:,:] + t[:m-1,None,None]\n",
    "    cifs = cifs[:m-1,:,:]\n",
    "    y_cifs = y_cifs[:m-1,:]  # 1 to L-1\n",
    "\n",
    "\n",
    "    n_cifs=cifs.shape[1]\n",
    "\n",
    "    cifs = cifs.reshape(n_cifs,-1)[0]\n",
    "    taus = taus.reshape(n_cifs,-1)[0]\n",
    "    y_cifs = y_cifs.reshape(n_cifs,-1)[0]\n",
    "\n",
    "    temp = torch.argsort(taus)\n",
    "\n",
    "    taus = taus[temp]\n",
    "    cifs = cifs[temp]\n",
    "\n",
    "    cifs_int = integrate.cumulative_trapezoid(cifs, taus, initial=0)/(taus)\n",
    "\n",
    "    if fig==None:\n",
    "        fig=go.Figure()\n",
    "\n",
    "    _ = fig.add_trace(go.Scatter(x=taus,y=cifs_int))\n",
    "\n",
    "    # _ = fig.add_trace(go.Scatter(x=t[1:m],y=y_cifs*0+1,mode='markers'))\n",
    "    # _ = fig.add_trace(go.Scatter(x=t[1:m],y=t[1:m],mode='markers'))\n",
    "\n",
    "    # print(m)\n",
    "    # print(t[1:5])\n",
    "    # print(y_cifs[:4])\n",
    "\n",
    "    _ = fig.add_trace(go.Scatter(x=t[:m],y=t[:m]*0,mode='markers'))\n",
    "\n",
    "    # _ = fig.add_trace(go.Scatter(x=t[1:m],y=y_cifs,mode='markers'))\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    return taus,cifs_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2],\n",
       "       [3, 4, 5]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 0]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=np.arange(6).reshape(2,3)\n",
    "a\n",
    "\n",
    "np.roll(a,-1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## att agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(row1, row2):\n",
    "    intersection = np.logical_and(row1, row2).sum()\n",
    "    union = np.logical_or(row1, row2).sum()\n",
    "    return intersection / union\n",
    "\n",
    "def compute_jaccard_similarity(A,B):\n",
    "\n",
    "    L, M = A.shape\n",
    "    M, C = B.shape\n",
    "    res = np.zeros((L, C))\n",
    "    for i in range(L):\n",
    "        for j in range(C):\n",
    "            res[i, j] = jaccard_similarity(A[i], B[:, j])\n",
    "    return res\n",
    "\n",
    "\n",
    "def att_map(out,i_b,i,common_patterns):\n",
    "\n",
    "    # common_patterns is of shape [C,M]\n",
    "\n",
    "    tee_mapped = np.zeros((common_patterns.shape[0], common_patterns.shape[0])) # [C,C]\n",
    "    norm = np.zeros((common_patterns.shape[0], common_patterns.shape[0])) # [C,C]\n",
    "\n",
    "    N_CLUSTERS = common_patterns.shape[0]\n",
    "    ev = out['event_type_list'][i_b][i].cpu().numpy()   # [L,M]\n",
    "    \n",
    "    \n",
    "    if len(ev.shape)==1:    # if multi-class\n",
    "        identity = np.eye(common_patterns.shape[1]+1,dtype=np.int8)\n",
    "        ev = identity.take(ev, axis=0)[:,1:] #  [B,LLLL] -> [B,LLLLLL,K]\n",
    "    \n",
    "    m=(ev.sum(1)>0).sum()\n",
    "    m\n",
    "    if m==0:\n",
    "        # print(out['event_time_list'][i_b][i])\n",
    "        print(\"NO EVENTS!\")\n",
    "        return tee_mapped, norm\n",
    "    ev=ev[:m]\n",
    "    tee = out['list_TE_att'][i_b][i][:1,:m,:m].mean(0).cpu().numpy() \n",
    "    print('A1',tee)\n",
    "\n",
    "    # tee(i,j): influence of j-th event on (i+1)-th event    \n",
    "    tee[-1,:] = 0\n",
    "    scaler=np.arange(1,m+1)[:,None]\n",
    "    # scaler= (1/tee_att_mat.max(1)[0])[:,None]\n",
    "    tee *= scaler\n",
    "    print('A2',tee)\n",
    "\n",
    "    print(tee[:6,:6])\n",
    "\n",
    "    q=(tee>0.02).astype(np.int8)\n",
    "\n",
    "    # print(tee[-12:,-12:])\n",
    "    TH=3\n",
    "    tee[tee<TH]=0\n",
    "    tee[tee>=TH]=1\n",
    "\n",
    "    \n",
    "    # print(tee[-12:,-12:].astype(int))\n",
    "    # print(q[-12:,-12:])\n",
    "    # print(tee.sum(), q.sum())\n",
    "\n",
    "    \n",
    "    tee.shape\n",
    "\n",
    "\n",
    "    temp = compute_jaccard_similarity(ev,common_patterns.T) # [L,M],[M,C]->[L,C]\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    temp=np.argmax(temp,axis=1) # [L]\n",
    "    temp.shape\n",
    "    temp\n",
    "\n",
    "    vec_map = temp\n",
    "\n",
    "    mat_map_1h = np.zeros((m,N_CLUSTERS),dtype= np.int8) # [L,C]\n",
    "    mat_map_1h[np.arange(m),vec_map]=1\n",
    "    # print(mat_map_1h.shape)    # [L,N_clusters]\n",
    "\n",
    "    # IMPORTANT\n",
    "    mat_iplus1 = np.roll(mat_map_1h.T,-1) # [C,L]\n",
    "    mat_iplus1[:,-1]=0\n",
    "\n",
    "    # mat_iplus1 = mat_map_1h.T\n",
    "\n",
    "    tee_mapped = mat_iplus1 @ tee @ mat_map_1h  # tee_mapped(i,j): influence of j-th pattern on i-th pattern\n",
    "    tee_mapped.shape\n",
    "\n",
    "    tee_mapped\n",
    "\n",
    "    # NEW method\n",
    "    a=np.einsum('ab,cd->adbc',mat_iplus1,mat_map_1h) # [C,L] [L,C]-> [C,C,L,L]\n",
    "    # q=np.tril(np.ones((m,m),dtype=np.int8)) # [L,L]\n",
    "    # q=(tee>0).astype(np.int8)\n",
    "    norm=np.sum(  np.einsum('ij,adij->adij',q,a)   ,(-1,-2)) # [C,C]\n",
    "    # norm=np.einsum('ij,adij->ad',q,a)    # [C,C]\n",
    "\n",
    "    # OLD method\n",
    "    sum1=mat_iplus1.sum(1)  # shape [N_CLUSTER]\n",
    "    sum2=mat_map_1h.sum(0)  # shape [N_CLUSTER]\n",
    "    # norm = np.outer(sum1,sum2)\n",
    "    # print(sum1,sum2)\n",
    "    # print(norm.shape, norm)\n",
    "\n",
    "    \n",
    "    # print(((tee_mapped[:6,:6]-norm[:6,:6])>0).sum())\n",
    "    \n",
    "    \n",
    "    \n",
    "    if (((tee_mapped[:6,:6]-norm[:6,:6])>0).sum()):\n",
    "        print(tee_mapped[:6,:6])\n",
    "        print(norm[:6,:6])\n",
    "        print(i_b,i)\n",
    "        term\n",
    "    \n",
    "    return tee_mapped, norm\n",
    "\n",
    "def plot_heatmap_att_agg(df,out,point_ids,fig=None, event_labels=None):\n",
    "\n",
    "    # common_patterns,_ = compute_common_patterns(out1,opt1,N_CLUSTERS=10)\n",
    "\n",
    "    NORM_TH = 0.1\n",
    "\n",
    "    if fig is None:\n",
    "        fig=go.Figure()\n",
    "\n",
    "    att_maps=[]\n",
    "    att_norms=[]\n",
    "    for pid in point_ids:\n",
    "\n",
    "        i_b = int(df.iloc[pid]['i_b'])\n",
    "        i = int(df.iloc[pid]['i'])\n",
    "\n",
    "        tee_mapped, norm = att_map(out,i_b,i,common_patterns)\n",
    "        att_maps.append(tee_mapped  )\n",
    "        att_norms.append(norm  )\n",
    "\n",
    "    norms_matrix = sum(att_norms)\n",
    "    \n",
    "    id_unwanted = (norms_matrix/len(point_ids)<NORM_TH)\n",
    "    # norms_matrix[norms_matrix<0.5]=1.0001\n",
    "    agg_matrix = sum(att_maps)/norms_matrix\n",
    "  \n",
    "    norms_matrix = norms_matrix/len(point_ids)\n",
    "\n",
    "    agg_matrix[id_unwanted]=0\n",
    "    agg_matrix[agg_matrix<0.1]=0\n",
    "\n",
    "\n",
    "\n",
    "    # agg_matrix[agg_matrix<0.5]=0\n",
    "\n",
    "    if len(out['event_type_list'][0].shape)==2: # if multi_class\n",
    "        patt_str = [f'P {i+1}' for i in range(common_patterns.shape[0])]\n",
    "    else:\n",
    "        patt_str = [''.join(str(cell) for cell in row) for row in common_patterns]\n",
    "\n",
    "    patt_str = [f'P{i+1}' for i in range(common_patterns.shape[0])]\n",
    "\n",
    "    fig_agg_mat = px.imshow(agg_matrix, x=patt_str, y=patt_str,\n",
    "    \n",
    "        color_continuous_scale=[\n",
    "        (0, \"#f0f1fc\"),\n",
    "        (0.1, \"#f0f1fc\"),\n",
    "\n",
    "        # (0.001/np.max(agg_matrix), \"#FFFFFF\"),\n",
    "        # (0.001/np.max(agg_matrix), \"#A9D3FF\"),\n",
    "        (0.5, \"#a7b1fa\"),\n",
    "\n",
    "        (1, \"#021ff7\")] )\n",
    "\n",
    "    # fig_agg_mat = go.Figure(\n",
    "    #                 data=go.Heatmap(\n",
    "    #                 z=agg_matrix,#x=patt_str, y=patt_str,\n",
    "    #                 line=dict(width=1, color='white')\n",
    "    #                     )\n",
    "    #             )\n",
    "\n",
    "    perc_pos = (df.iloc[point_ids]['color_true']=='Positive Samples').sum()/len(point_ids)*100\n",
    "    fig_agg_mat.update_layout(\n",
    "        title=f\"per: {perc_pos}\",\n",
    "        # title=\"Plot Title\",\n",
    "        # xaxis_title=\"X Axis Title\",\n",
    "        # yaxis_title=\"Y Axis Title\",\n",
    "        # legend_title=\"Legend Title\",\n",
    "        font=dict(\n",
    "            # family=\"Courier New, monospace\",\n",
    "            size=10,\n",
    "            # color=\"RebeccaPurple\"\n",
    "        )\n",
    "    )\n",
    "    fig_agg_mat.update_xaxes(tickangle=-45)\n",
    "\n",
    "    \n",
    "\n",
    "    # norms_matrix = norms_matrix.astype(int)\n",
    "    # norms_matrix[norms_matrix<1] = 0 \n",
    "    fig_freqs = px.imshow((norms_matrix), x=patt_str, y=patt_str,\n",
    "                          \n",
    "     color_continuous_scale=[(0, \"#FFFFFF\"),\n",
    "    #  (1, \"#FFFFFF\"),     \n",
    "    #  (NORM_TH/np.max(norms_matrix), \"#A9C8FF\"),\n",
    "    #  (0.75, \"#176BFF\"),\n",
    "    # (np.median(norms_matrix)/np.max(norms_matrix), \"#a7b1fa\"),\n",
    "    (0.9, \"#f25252\"), # \n",
    "\n",
    "     (1, \"#FF3D17\")]) # \n",
    "    fig_freqs.update_xaxes(tickangle=-45)\n",
    "    fig_freqs.update_layout(\n",
    "        # title=\"Plot Title\",\n",
    "        # xaxis_title=\"X Axis Title\",\n",
    "        # yaxis_title=\"Y Axis Title\",\n",
    "        # legend_title=\"Legend Title\",\n",
    "        font=dict(\n",
    "            # family=\"Courier New, monospace\",\n",
    "            size=10,\n",
    "            # color=\"RebeccaPurple\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    fig_patterns = px.imshow(common_patterns, x=event_labels, y=patt_str,\n",
    "                             width=600,height=600,\n",
    "     color_continuous_scale=px.colors.sequential.Blues)\n",
    "    fig_patterns.update_xaxes(tickangle=-45)\n",
    "    fig_patterns.update_layout(\n",
    "        # title=\"Plot Title\",\n",
    "        xaxis_title=\"X Axis Title\",\n",
    "        # yaxis_title=\"Y Axis Title\",\n",
    "        # legend_title=\"Legend Title\",\n",
    "        font=dict(\n",
    "            # family=\"Courier New, monospace\",\n",
    "            size=10,\n",
    "            # color=\"RebeccaPurple\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "    fig_agg_mat.write_image(\"local/images/fig_agg_mat.svg\")\n",
    "    fig_freqs.write_image(\"local/images/fig_freqs.svg\")\n",
    "    fig_patterns.write_image(\"local/images/fig_patterns.svg\")\n",
    "\n",
    "    return fig_agg_mat, fig_freqs, fig_patterns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## common patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_common_patterns(out,opt,N_CLUSTERS=20):\n",
    "\n",
    "\n",
    "    \n",
    "    if opt.data_label=='multiclass':\n",
    "        common_patterns=np.eye(opt.num_marks,dtype=np.int8)\n",
    "        fig_clustering = None\n",
    "    else:\n",
    "\n",
    "\n",
    "        all_events=np.concatenate(out['event_type_list'],axis=1) # [B,LLLLLL,K] or [B,LLLL]\n",
    "        masks=all_events.sum(-1)>0\n",
    "\n",
    "\n",
    "\n",
    "        TSNE_LIMIT=16000\n",
    "        X = all_events[masks][:TSNE_LIMIT]\n",
    "\n",
    "        X_str = [''.join(str(cell) for cell in row) for row in X]\n",
    "\n",
    "        df=pd.DataFrame()\n",
    "        df['val']=list(X)\n",
    "        df['str']=X_str\n",
    "\n",
    "        df_temp = df.groupby('str').size().sort_values(ascending=False).head(N_CLUSTERS).reset_index(name='count')\n",
    "        \n",
    "        df_temp = df_temp.merge(df.drop_duplicates(subset='str'),how='inner',on='str')\n",
    "        common_patterns = np.stack(df_temp['val'].values)\n",
    "    #     # kmeans clustering\n",
    "    #     # Generate sample binary data\n",
    "    #     data = X\n",
    "\n",
    "    #     # Initialize KMeans object with 2 clusters\n",
    "    #     kmeans = KMeans(n_clusters=N_CLUSTERS)\n",
    "\n",
    "    #     # Fit the data to the KMeans object\n",
    "    #     _ = kmeans.fit(data)\n",
    "\n",
    "    #     # Get the labels and cluster centers\n",
    "    #     labels = kmeans.labels_\n",
    "    #     centers = kmeans.cluster_centers_\n",
    "\n",
    "    #     labels\n",
    "\n",
    "\n",
    "\n",
    "    #     df['cluster_kmeans']=labels\n",
    "\n",
    "    #     # # TSNE\n",
    "    #     # tsne = TSNE(n_components=2, perplexity=60, learning_rate=10,n_jobs=4)\n",
    "    #     # X_tsne = tsne.fit_transform(X[:TSNE_LIMIT,:])\n",
    "    #     # df['x']=X_tsne[:,0]\n",
    "    #     # df['y']=X_tsne[:,1]\n",
    "\n",
    "    #     # fig_clustering=px.scatter(df,x='x',y='y',color='cluster_kmeans',hover_data=[\"str\"])\n",
    "    #     fig_clustering=None\n",
    "\n",
    "\n",
    "    #     # finding common patterns\n",
    "    #     METHOD = 'cluster_kmeans'\n",
    "    #     common_patterns = []\n",
    "\n",
    "    #     for i in range(N_CLUSTERS):\n",
    "    #         temp = df[df[METHOD]==i]['val'].values\n",
    "    #         temp = (temp.sum()/temp.shape[0]*100).astype(int)\n",
    "\n",
    "    #         temp[temp<30]=0\n",
    "    #         temp[temp>=30]=1\n",
    "    #         print(temp,'\\n')\n",
    "    #         common_patterns.append(temp)\n",
    "\n",
    "    #     common_patterns = np.array(common_patterns)\n",
    "    # common_patterns.shape\n",
    "\n",
    "\n",
    "\n",
    "    fig_clustering = None\n",
    "    return common_patterns, fig_clustering\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hokarami/TEEDAM_supervised/56ecgyrq'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs_path=[\n",
    "# \"hokarami/TEEDAM_supervised/5uzxzoxd\",\n",
    "\"hokarami/TEEDAM_supervised/sb9zf1mm\",\n",
    "\"hokarami/TEEDAM_supervised/hue1qxw4\",  # seft [Q10-TE__nextmark-concat]1566371 with label\n",
    "\n",
    "# \"hokarami/TEEDAM_supervised/t43m0t0u\", # [Q10-DA__base-concat]1563864\n",
    "\n",
    "\"hokarami/TEEDAM_supervised/9gxq3dgy\", # [Q10-TEDA__nextmark-concat]1577576 with label\n",
    "\n",
    "\"hokarami/TEEDAM_supervised/56ecgyrq\", # [Q20-TEDA__nextmark-concat]1588433\n",
    "# \"hokarami/TEEDAM_supervised/g4x0ibmk\", # [Q20-TE__nextmark-concat]1585936 with label\n",
    "\n",
    "# \"hokarami/TEEDAM_supervised/lzvf7erg\", # [Q20-DA__base-concat]1586915\n",
    "\n",
    "]\n",
    "\n",
    "run_path = runs_path[-1]\n",
    "run_path\n",
    "\n",
    "\n",
    "# run = api.run(run_path)\n",
    "# for file in run.files():\n",
    "#     file.download(replace=True,root='./local/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ATT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out.keys()\n",
    "# bs = opt.batch_size\n",
    "\n",
    "\n",
    "# out['event_type_list'][0].shape\n",
    "# out['event_time_list'][0].shape\n",
    "# out['non_pad_mask_list'][0].shape\n",
    "# out['list_TE_att'][0].shape\n",
    "\n",
    "# out['state_mod_list'][0].shape\n",
    "# out['list_DAM_att'][0].shape\n",
    "\n",
    "# out['y_state_true'].shape\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary_matrix = state2mat(st, sm,n_state_mods)\n",
    "\n",
    "# # binary_matrix_to_image(binary_matrix, row_labels=state_labels, font_path=None, grid_size=10, border_size=1, label_size=8)\n",
    "\n",
    "\n",
    "# M = [state2mat(st, sm,n_state_mods) +  att_state2mat(st, sm, n_state_mods, dam_att.sum(1))*0,\n",
    "     \n",
    "#      att_event2mat(ev, t,P, tee_att)*12\n",
    "     \n",
    "#      ]\n",
    "\n",
    "# all_labels = [*state_labels,\n",
    "#               *[f\"Head_{i}\" for i in range(tee_att.shape[0])]\n",
    "#               ]\n",
    "# binary_matrix = np.concatenate(M, axis=0)\n",
    "\n",
    "# # binary_matrix_to_image(binary_matrix, row_labels=all_labels, font_path=None, grid_size=10, border_size=1, label_size=8)\n",
    "\n",
    "\n",
    "# # binary_matrix = event2mat(ev,t,P)\n",
    "# # event_labels = opt.dict_map_events.keys()\n",
    "\n",
    "# # binary_matrix_to_image(binary_matrix, row_labels=None, font_path=None, grid_size=10, border_size=1, label_size=8)\n",
    "\n",
    "\n",
    "# binary_matrix = att_state2mat(st, sm, n_state_mods, dam_att.sum(1))\n",
    "# img_att = binary_matrix_to_image(binary_matrix, row_labels=state_labels, font_path=None, grid_size=10, border_size=1, label_size=8,is_fill=False,**rgb_params_att)\n",
    "\n",
    "\n",
    "# binary_matrix = att_state2mat(st, sm, n_state_mods, sv)\n",
    "# img_val = binary_matrix_to_image(binary_matrix, row_labels=state_labels, font_path=None, grid_size=10, border_size=1, label_size=8,is_fill=True,**rgb_params_values)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # binary_matrix[binary_matrix!=0].shape\n",
    "# # binary_matrix.shape\n",
    "# # binary_matrix.min()\n",
    "# # binary_matrix.max()\n",
    "\n",
    "# i_b=3\n",
    "# i=18\n",
    "\n",
    "# merged_img,temp = cool_image(out,i_b,i,opt)\n",
    "\n",
    "# temp[2][0]\n",
    "# temp[2][1]\n",
    "# temp[0]\n",
    "# merged_img\n",
    "\n",
    "# map_to_rgb(-0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if 'y_state_true' in out:\n",
    "\n",
    "#     y_state_pred = out['y_state_pred']\n",
    "#     y_state_true = out['y_state_true']\n",
    "#     y_state_score = out['y_state_score']\n",
    "# else:\n",
    "#     y_state_pred = None\n",
    "#     y_state_true = None\n",
    "#     y_state_score = None\n",
    "\n",
    "# y_pred = out['y_pred']\n",
    "# y_true = out['y_true']\n",
    "# y_score = out['y_score']\n",
    "\n",
    "\n",
    "# res=list()\n",
    "\n",
    "\n",
    "# if len(out['state_mod_list'])>0 and 0:\n",
    "\n",
    "#     res_labels = opt.dict_map_states.keys()\n",
    "\n",
    "#     n_cols = len(opt.dict_map_states.keys())\n",
    "\n",
    "#     state_mod_list = out['state_mod_list']\n",
    "#     state_time_list = out['state_time_list']\n",
    "#     len(state_mod_list)\n",
    "#     state_mod_list[0].shape\n",
    "\n",
    "#     for state_mod,state_time in zip(state_mod_list,state_time_list):\n",
    "#         xs = torch.unbind(state_time,0)\n",
    "#         ys = torch.unbind(state_mod,0)\n",
    "\n",
    "#         for x,y in zip(xs,ys):\n",
    "#             # y = y[y~=0]\n",
    "#             n_rows = x.int().max().item() + 1\n",
    "#             matrix = torch.zeros(n_rows, n_cols)\n",
    "#             matrix[x[y!=0].long(), y[y!=0]-1] = 1\n",
    "#             res.append(matrix.cpu().numpy().transpose()) # [n_marks * times]\n",
    "\n",
    "\n",
    "# else:\n",
    "#     non_pad_mask_list = out['non_pad_mask_list']\n",
    "#     event_type_list = out['event_type_list']\n",
    "#     event_time_list = out['event_time_list']\n",
    "\n",
    "#     event_type_list[0].shape\n",
    "#     non_pad_mask_list[0].shape\n",
    "\n",
    "#     num_marks = event_type_list[0].shape[-1]\n",
    "#     res_labels = opt.dict_map_events.keys()\n",
    "\n",
    "\n",
    "\n",
    "#     for event_type, event_time, non_pad_mask in zip(event_type_list,event_time_list,non_pad_mask_list):\n",
    "\n",
    "#         B = event_type.shape[0]\n",
    "#         for i in range(B):\n",
    "#             m = non_pad_mask[i]\n",
    "#             e=event_type[i,:m.sum().int(),:]\n",
    "#             t=event_time[i,:m.sum().int()]\n",
    "            \n",
    "#             indices = e.nonzero()\n",
    "#             indices[:,0] = t[indices[:,0]]\n",
    "\n",
    "#             M = torch.zeros((indices[:,0].max()+1, e.shape[-1]))\n",
    "#             M[indices[:,0],indices[:,1]]=1\n",
    "\n",
    "\n",
    "#             res.append( M.cpu().numpy().astype(np.uint8).transpose() )\n",
    "\n",
    "\n",
    "#         # temp = torch.unbind(event_type,0)\n",
    "#         # lens = non_pad_mask.sum(1).long()\n",
    "#         # term\n",
    "#         # for i,x in enumerate(temp):\n",
    "#         #     res.append( x[:lens[i],:].cpu().numpy().astype(np.uint8).transpose() )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# res[1].shape\n",
    "\n",
    "# len(res_labels)\n",
    "# res_labels\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # for i,pattern in enumerate(res):\n",
    "# #     image = Image.fromarray(pattern)\n",
    "\n",
    "\n",
    "# #     # row_labels = opt.dict_map_states.keys()\n",
    "# #     # image = binary_matrix_to_image(pattern, row_labels=row_labels, grid_size=50, border_size=2, label_size=20)\n",
    "# #     # image.save(f'./local/images/img{i}.jpeg')\n",
    "# all_images = [f'./local/images/img{i}.jpeg' for i in range(len(res))]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSNE of Learned Rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TSNE_LIMIT = 6000\n",
    "\n",
    "def compute_tsne(r_enc_list, model, TSNE_LIMIT=6000):\n",
    "    X_tsne = dict()\n",
    "    tsne = TSNE(n_components=2, perplexity=30, learning_rate=10,n_jobs=4)\n",
    "\n",
    "    # r_enc_list = out['r_enc_list']\n",
    "\n",
    "    X = np.concatenate(r_enc_list,axis=0)[:,:]\n",
    "    X_tsne_full = tsne.fit_transform(X[:TSNE_LIMIT,:])\n",
    "    X_tsne.update({'full': X_tsne_full})\n",
    "    X_tsne_split=dict()\n",
    "    if model.d_out_te>0:\n",
    "        X_te = np.concatenate(r_enc_list,axis=0)[:,:model.d_out_te]\n",
    "        X_te_tsne = tsne.fit_transform(X_te[:TSNE_LIMIT,:])\n",
    "        X_tsne_split['tee']=X_te_tsne\n",
    "        X_tsne.update({'tee': X_te_tsne})\n",
    "\n",
    "    if model.d_out_dam>0:    \n",
    "        X_dam = np.concatenate(r_enc_list,axis=0)[:,model.d_out_te:]\n",
    "        X_dam_tsne = tsne.fit_transform(X_dam[:TSNE_LIMIT,:])\n",
    "        X_tsne_split['dam']=X_dam_tsne\n",
    "        X_tsne.update({'dam': X_dam_tsne})\n",
    "\n",
    "    return X_tsne"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_df(out,opt, X_tsne=None, TSNE_LIMIT=5000):\n",
    "    if 'y_state_true' in out:\n",
    "\n",
    "        y_state_pred = out['y_state_pred']\n",
    "        y_state_true = out['y_state_true']\n",
    "        y_state_score = out['y_state_score']\n",
    "    else:\n",
    "        y_state_pred = None\n",
    "        y_state_true = None\n",
    "        y_state_score = None\n",
    "\n",
    "    y_pred = out['y_pred']\n",
    "    y_true = out['y_true']\n",
    "    y_score = out['y_score']\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    if X_tsne is not None:\n",
    "        df['x']=X_tsne[:,0]\n",
    "        df['y']=X_tsne[:,1]\n",
    "    else:\n",
    "        df['x'] = y_state_true\n",
    "        TSNE_LIMIT=100000000\n",
    "\n",
    "    # df['x']=X_te_tsne[:,0]\n",
    "    # df['y']=X_te_tsne[:,1]\n",
    "\n",
    "    # df['x']=X_dam_tsne[:,0]\n",
    "    # df['y']=X_dam_tsne[:,1]\n",
    "\n",
    "    df['color']=0\n",
    "    df['id']=np.arange(len(df))\n",
    "\n",
    "\n",
    "    if y_state_true is not None:\n",
    "\n",
    "        TP = (y_state_true[:TSNE_LIMIT]*y_state_pred[:TSNE_LIMIT])==1\n",
    "        FN = (y_state_true[:TSNE_LIMIT]-y_state_pred[:TSNE_LIMIT])==1\n",
    "        FP = (y_state_true[:TSNE_LIMIT]-y_state_pred[:TSNE_LIMIT])==-1\n",
    "\n",
    "        TN = (y_state_true[:TSNE_LIMIT]+y_state_pred[:TSNE_LIMIT])==0\n",
    "\n",
    "        FP_FN = (y_state_true[:TSNE_LIMIT]+y_state_pred[:TSNE_LIMIT])==1\n",
    "        TP_TN = (y_state_true[:TSNE_LIMIT]-y_state_pred[:TSNE_LIMIT])==0\n",
    "\n",
    "\n",
    "        # df.loc[TN, 'color']='True Negatives'\n",
    "        df.loc[TP, 'color']='True Positives'\n",
    "        df.loc[FN, 'color']='False Negatives'\n",
    "        df.loc[FP, 'color']='False Positives'\n",
    "        df.loc[TN, 'color']='True Negatives'\n",
    "\n",
    "        df.loc[TP_TN, 'color_true_pred']='True Predicted'\n",
    "        df.loc[FP_FN, 'color_true_pred']='False Predicted'\n",
    "\n",
    "\n",
    "        df.loc[y_state_true[:TSNE_LIMIT].astype(bool).flatten(), 'color_true']='Positive Samples'\n",
    "        df.loc[~y_state_true[:TSNE_LIMIT].astype(bool).flatten(), 'color_true']='Negative Samples'\n",
    "\n",
    "\n",
    "        df.loc[y_state_pred[:TSNE_LIMIT].astype(bool).flatten(), 'color_pred']='Positive Predicted'\n",
    "        df.loc[~y_state_pred[:TSNE_LIMIT].astype(bool).flatten(), 'color_pred']='Negative Predicted'\n",
    "\n",
    "        # df.loc[y_state_pred[:TSNE_LIMIT].astype(bool).flatten(), 'color_true_pred']='Positive Predicted'\n",
    "        # df.loc[~y_state_pred[:TSNE_LIMIT].astype(bool).flatten(), 'color_true_pred']='Negative Predicted'\n",
    "\n",
    "\n",
    "    df['i_b'] = df['id'].apply(lambda x:int(x / opt.batch_size) )\n",
    "    df['i'] = df['id'].apply(lambda x:x % opt.batch_size)\n",
    "\n",
    "    t_max = np.concatenate( [t.max(1)[0] for t in out['event_time_list']] )\n",
    "\n",
    "    df['color_t_max'] = t_max\n",
    "    if len(out['list_log_sum'])>0:\n",
    "        df['color_log_sum'] = np.concatenate(out['list_log_sum'],axis=0) / t_max\n",
    "        df['color_integral_'] = np.concatenate(out['list_integral_'],axis=0) / t_max\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_map = {\n",
    "    'Positive Samples': \"#E52B50\",\n",
    "    'Negative Samples': \"#3B7A57\",\n",
    "    'True Predicted': \"#E52B50\",\n",
    "    'False Predicted': \"#3B7A57\",\n",
    "\n",
    "    \n",
    "    0: \"#3B7A57\",\n",
    "    # 'Positive Predicted': \"#3DDC84\",\n",
    "    # 'Negative Predicted': \"#FFBF00\",\n",
    "\n",
    "    'Positive Predicted': \"#E52B50\",\n",
    "    'Negative Predicted': \"#3B7A57\",\n",
    "\n",
    "    5: \"#915C83\",\n",
    "    'True Positives': \"#008000\",\n",
    "    'False Negatives': \"#7FFFD4\",\n",
    "    'False Positives': \"#E9D66B\",\n",
    "    'True Negatives': \"#007FFF\",\n",
    "}\n",
    "\n",
    "def plot_tsne(df, title=\"\"):\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    if 'color_true' in df:\n",
    "        labels = df['color_true'].values\n",
    "        colors = [color_map[label] for i,label in enumerate(labels)]\n",
    "\n",
    "        _ = fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=df['x'],\n",
    "                y=df['y'],\n",
    "                # z=tsne[:, 2],\n",
    "                mode='markers',\n",
    "                marker=dict(\n",
    "                    # size=2,\n",
    "                    color=colors,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        )\n",
    "    else:\n",
    "        labels = df['color'].values\n",
    "        colors = [color_map[label] for i,label in enumerate(labels)]\n",
    "\n",
    "        _ = fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=df['x'],\n",
    "                y=df['y'],\n",
    "                # z=tsne[:, 2],\n",
    "                mode='markers',\n",
    "                marker=dict(\n",
    "                    # size=2,\n",
    "                    color=colors,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        )\n",
    "\n",
    "    if 'color_pred' in df:\n",
    "        labels = df['color_pred'].values\n",
    "        colors = [color_map[label] for i,label in enumerate(labels)]\n",
    "        _ = fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=df['x'],\n",
    "                y=df['y'],\n",
    "                # z=tsne[:, 2],\n",
    "                mode='markers',\n",
    "                marker=dict(\n",
    "                    symbol='circle-open',\n",
    "                    # size=10,\n",
    "                    color=colors,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        )\n",
    "\n",
    "        \n",
    "    if 'color_integral_' in df:\n",
    "        colors = df['color_integral_'].values\n",
    "\n",
    "        _ = fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=df['x'],\n",
    "                y=df['y'],\n",
    "                # z=tsne[:, 2],\n",
    "                mode='markers',\n",
    "                marker=dict(\n",
    "                    # size=8,\n",
    "                    color=colors,\n",
    "                    colorbar=dict(\n",
    "                        title=\"cif_integral\"\n",
    "                    ),\n",
    "                    colorscale=\"RdBu\",\n",
    "                )\n",
    "            )\n",
    "\n",
    "        )\n",
    "\n",
    "    if 'color_t_max' in df:\n",
    "        colors = df['color_t_max'].values\n",
    "\n",
    "        _ = fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=df['x'],\n",
    "                y=df['y'],\n",
    "                # z=tsne[:, 2],\n",
    "                mode='markers',\n",
    "                marker=dict(\n",
    "                    # size=8,\n",
    "                    color=colors,\n",
    "                    colorbar=dict(\n",
    "                        title=\"t_max\"\n",
    "                    ),\n",
    "                    colorscale=\"RdBu\",\n",
    "                )\n",
    "            )\n",
    "\n",
    "        )\n",
    "\n",
    "    _=fig.update_layout(\n",
    "        # autosize=False,\n",
    "        title=title,\n",
    "        width=600,\n",
    "        height=600,\n",
    "        showlegend=True,\n",
    "\n",
    "    )\n",
    "    _=fig.update_traces(\n",
    "        hoverinfo=\"none\",\n",
    "        hovertemplate=None,\n",
    "    )\n",
    "    # _=fig.update_layout(\n",
    "    #     scene=dict(\n",
    "    #         xaxis=dict(range=[-10,10]),\n",
    "    #         yaxis=dict(range=[-10,10]),\n",
    "    #         # zaxis=dict(range=[-10,10]),   \n",
    "    #     )\n",
    "    # )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # save to run\n",
    "    # fig.write_html(f\"local/{run.name}.html\")\n",
    "    # run.upload_file(f\"local/{run.name}.html\")\n",
    "\n",
    "\n",
    "    # tsne of TE_nextmark[label]\n",
    "        # https://storage.googleapis.com/wandb-production.appspot.com/hokarami/TEEDAM_supervised/hue1qxw4/local/temp.html?Expires=1676986614&GoogleAccessId=wandb-production%40appspot.gserviceaccount.com&Signature=xLOuNCu8qoWVwFRPCspoPKTFbpF5aOSJMAFICqsDRYxf2wfudxEiFFEIlXBIq9YyYZcPtpSKSzYb6nUr0lloLZ6GHg1w4AOBZyieBKBsuKmIDGqhRY4ojK0FPHZHD%2BeoKERgjD42F19vP8E5Qf%2BA7PlgB2E%2BWutwJxx1sc2TtCgjUdkEK%2BEwaTzfQBQ0hXGIWC9MeirU7hRSmn4%2BXzIRaRcUFjF0vOtxCHBjsEhldGSwaUFv21kt4qvr2hSeR5Ku5gS7webtvzVi6fw55Muq78%2FB90r3EqWqy9Sn68T%2FDKx%2F%2FzHVfge4TsxlIjRE%2F9HBCo7qZeNeeHnlHjVZXdvTKg%3D%3D\n",
    "\n",
    "    # tsne of DA[label]\n",
    "        # https://storage.googleapis.com/wandb-production.appspot.com/hokarami/TEEDAM_supervised/t43m0t0u/local/temp.html?Expires=1676987035&GoogleAccessId=wandb-production%40appspot.gserviceaccount.com&Signature=jX44t4Nblmtzd0CCZC2Gn0cw43iZZbZtuofN%2BrlmzgennSxNz36YE4BwYU%2Ft21iuFdSwmqPLnnI%2B2saLWT9kZsBHNo0e2Nsti0vhf7216iT1wsnnFukn%2B8CswPFeQUQBmSyvEO0IJRTE%2BLmjORdY5NFMdgeXchVwLlf8LBIJFoxAfyiaYLmCNcjWwSmbkvVf1DwOxL2sjneA8TtkgQiSCZiC3GgMJBfh8wg1bf6wS%2Bxa95APq%2BPo6J7%2Ffq0sqmqCiAp28E309PlM29C0C89y63dvzqkRhBhvdffx3O%2FFUAmK%2FjRF82ohd7JSgxMva9oWz%2By7aHESGKr0b49KrUxM2Q%3D%3D\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_dash_app(fig_tsne,out,opt, df,port=None):\n",
    "    if port is None:\n",
    "        port = np.random.randint(2000,5000)\n",
    "\n",
    "    app = JupyterDash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])\n",
    "\n",
    "    app.layout = dbc.Container([\n",
    "        # className=\"container\",\n",
    "        # children=[\n",
    "\n",
    "            dbc.Row([\n",
    "                    html.Div(id=\"dummy2\"),\n",
    "                    html.Div(id=\"dummy\"),\n",
    "                ]),\n",
    "\n",
    "            dbc.Row([\n",
    "                \n",
    "                dbc.Col(\n",
    "                    dcc.Graph(id=\"graph-5\", figure=fig_tsne, clear_on_unhover=True,),\n",
    "\n",
    "                    \n",
    "                    width=6),  # first column with graph\n",
    "\n",
    "\n",
    "\n",
    "                dbc.Col([\n",
    "                    html.Img(id='image_merge',src='./local/images/C0-1296.jpeg',style={\"hieght\": \"500px\", 'display': 'block', 'margin': '0 auto'},),\n",
    "\n",
    "                    html.Img(id='image_att',src='./local/images/C0-1296.jpeg',style={\"hieght\": \"500px\", 'display': 'block', 'margin': '0 auto'},),\n",
    "\n",
    "                ], width=6),  # second column with image\n",
    "            ]),\n",
    "\n",
    "            # dbc.Row([\n",
    "            #     dcc.Graph(id=\"graph-cif\", figure=go.Figure(), clear_on_unhover=True,),\n",
    "\n",
    "        \n",
    "            # ]),\n",
    "\n",
    "             dbc.Row([\n",
    "\n",
    "                # fig_agg_mat, fig_freqs, fig_patterns\n",
    "                \n",
    "                dbc.Col(\n",
    "                    dcc.Graph(id=\"fig_agg_mat\", figure=go.Figure(), clear_on_unhover=True,),\n",
    "\n",
    "                    \n",
    "                    width=4),  # first column with graph\n",
    "                dbc.Col(\n",
    "                    dcc.Graph(id=\"fig_freqs\", figure=go.Figure(), clear_on_unhover=True,),\n",
    "\n",
    "                    \n",
    "                    width=4),  # first column with graph\n",
    "                dbc.Col(\n",
    "                    dcc.Graph(id=\"fig_patterns\", figure=go.Figure(), clear_on_unhover=True,),\n",
    "\n",
    "                    \n",
    "                    width=4),  # first column with graph\n",
    "\n",
    "             ]),\n",
    "\n",
    "\n",
    "            dbc.Row([\n",
    "                dcc.Graph(id=\"graph-cif\", figure=go.Figure(), clear_on_unhover=True,),\n",
    "\n",
    "        \n",
    "            ]),\n",
    "\n",
    "            dbc.Row([\n",
    "                \n",
    "               \n",
    "\n",
    "                dbc.Col(\n",
    "                    dcc.Graph(id=\"graph-summary\", figure=go.Figure(), clear_on_unhover=True,),\n",
    "\n",
    "                    \n",
    "                    width=6),  # first column with graph\n",
    "\n",
    "                # dbc.Col(\n",
    "                #     html.Img(id='image',src='./local/images/C0-1296.jpeg',style={\"height\": \"400px\", 'display': 'block', 'margin': '0 auto'},),\n",
    "                \n",
    "                \n",
    "                # width=6),  # second column with image\n",
    "            ]),\n",
    "\n",
    "            dcc.Tooltip(id=\"graph-tooltip-5\", direction='bottom'),\n",
    "\n",
    "\n",
    "        \n",
    "        ])\n",
    "\n",
    "    @app.callback(\n",
    "        # Output(\"graph-tooltip-5\", \"show\"),\n",
    "        # Output(\"graph-tooltip-5\", \"bbox\"),\n",
    "        # Output(\"graph-tooltip-5\", \"children\"),\n",
    "        Output('image_merge', 'src'),\n",
    "        Output('image_att', 'src'),\n",
    "        Output(\"dummy2\", \"children\"),\n",
    "        Output(\"graph-cif\", \"figure\"),\n",
    "        Input(\"graph-5\", \"hoverData\"),\n",
    "    )\n",
    "    def display_hover(hoverData):\n",
    "        if hoverData is None:\n",
    "            # return False, no_update, no_update, no_update, no_update\n",
    "            return no_update,no_update, no_update, no_update\n",
    "\n",
    "        num = 111111\n",
    "        # demo only shows the first point, but other points may also be available\n",
    "        hover_data = hoverData[\"points\"][0]\n",
    "        bbox = hover_data[\"bbox\"]\n",
    "        num = hover_data[\"pointNumber\"]\n",
    "\n",
    "        print(f'NUM:{num}')\n",
    "\n",
    "        # im_matrix = res[num].astype(int)\n",
    "        # # im_url = np_image_to_base64(im_matrix)\n",
    "        # # im_url = binary_matrix_to_image(im_matrix)\n",
    "        # im_url = binary_matrix_to_image(im_matrix, row_labels=res_labels, grid_size=50, border_size=2, label_size=20)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        # # bar plot\n",
    "        # vector = im_matrix.sum(1)/im_matrix.shape[1]*24\n",
    "        # # im_url = plot_bar_chart(vector, labels=res_labels)\n",
    "        # im_url = create_barplot_image(vector, res_labels, './local/images/temp.png')\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "        # NEW\n",
    "        i_b = int(df.iloc[num]['i_b'])\n",
    "        i = int(df.iloc[num]['i'])\n",
    "        im_url, temp = cool_image(out,i_b,i,opt)\n",
    "\n",
    "        \n",
    "        output_str = f\"{num} - {df.iloc[num]['color']} - i_b {i_b} - i {i}\"\n",
    "        \n",
    "        im_url.save(\"./local/images/hover_img.png\")\n",
    "        if temp[0] is not None:\n",
    "            im_url.save(\"./local/images/att.png\")\n",
    "\n",
    "        im_url_path = './local/images/C2-203.jpeg'\n",
    "        \n",
    "        \n",
    "        \n",
    "        children = [\n",
    "            html.Div([\n",
    "                html.Img(\n",
    "                    src=im_url,\n",
    "                    style={\"height\": \"400px\", 'display': 'block', 'margin': '0 auto'},\n",
    "                ),\n",
    "                # html.P(\"MNIST Digit \" + str(labels[num]), style={'font-weight': 'bold'})\n",
    "                html.P(f\"Patterns-id={num} - i_b {i_b} - i {i}\" , style={'font-weight': 'bold'})\n",
    "\n",
    "            ])\n",
    "            \n",
    "        ]\n",
    "\n",
    "        # fig_cif = plot_cif(out,i_b,i)\n",
    "        fig_cif = go.Figure()\n",
    "        # fig_cif = plot_cif_cum(out,i_b,i)\n",
    "\n",
    "\n",
    "        # return True, bbox, children,im_url, output_str\n",
    "        return im_url,temp[0], output_str,fig_cif        # temp[0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Define a callback function to print the selected point IDs\n",
    "    # fig_agg_mat, fig_freqs, fig_patterns\n",
    "    @app.callback(\n",
    "        Output(\"dummy\", \"children\"),\n",
    "        Output(\"graph-summary\", \"figure\"), \n",
    "        Output(\"fig_agg_mat\", \"figure\"), \n",
    "        Output(\"fig_freqs\", \"figure\"), \n",
    "        Output(\"fig_patterns\", \"figure\"), \n",
    "\n",
    "        [Input(\"graph-5\", \"selectedData\"), Input(\"graph-summary\", \"figure\")])\n",
    "    def display_selected_data(selected_data, fig_prev):\n",
    "        if selected_data is None:\n",
    "            return \"No points selected.\",no_update,no_update,no_update,no_update\n",
    "        else:\n",
    "\n",
    "\n",
    "            new_fig = go.Figure(data=fig_prev['data'],layout=fig_prev['layout'])\n",
    "            fig_att_agg = go.Figure(data=fig_prev['data'],layout=fig_prev['layout'])\n",
    "\n",
    "\n",
    "            point_ids = [point[\"pointIndex\"] for point in selected_data[\"points\"]]\n",
    "\n",
    "            # new_fig = bar_summary(df,out, point_ids,res_labels, fig=new_fig)\n",
    "            \n",
    "            print(\"point_ids:\\n\",point_ids)\n",
    "            fig_agg_mat, fig_freqs, fig_patterns = plot_heatmap_att_agg(df,out,point_ids,event_labels=list(opt.dict_map_events.keys()))\n",
    "\n",
    "            # # save selected to local\n",
    "            # for pid in point_ids:\n",
    "            #     # NEW\n",
    "            #     i_b = df.iloc[pid]['i_b']\n",
    "            #     i = df.iloc[pid]['i']\n",
    "            #     im_url, temp = cool_image(out,i_b,i,opt)\n",
    "            #     im_url.save(f\"./local/images/selected{pid}.png\")\n",
    "\n",
    "            # print(f\"{point_ids},\\n\")\n",
    "            return f\"{point_ids},\\n\",new_fig,fig_agg_mat, fig_freqs, fig_patterns\n",
    "\n",
    "    if __name__ == \"__main__\":\n",
    "        # app.run_server(mode='inline', debug=True)\n",
    "        app.run_server(mode='external',port=port)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEDAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT TEDAM --> single-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p12-raindrop/split3/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_unsupervised', wandb_tag='RD74-single3', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='', tl_tag='None', freeze='', ES_pat=100, setting='raindrop', test_center='', split='3', log='log.txt', user_prefix='[RD74-R3-TEE_C1-TEDA__pp_single_mark-concat-d0]', pos_alpha=1.0, epoch=50, batch_size=128, lr=0.01, smooth=0.0, weight_decay=0.1, diag_offset=0, event_enc=1, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, dam_output_activation='relu', dam_output_dims=16, dam_n_phi_layers=3, dam_phi_width=128, dam_phi_dropout=0.2, dam_n_psi_layers=2, dam_psi_width=64, dam_psi_latent_width=128, dam_dot_prod_dim=64, dam_n_heads=4, dam_attn_dropout=0.1, dam_latent_width=64, dam_n_rho_layers=2, dam_rho_width=128, dam_rho_dropout=0.1, dam_max_timescale=1000, dam_n_positional_dims=16, dam_online=False, state=True, demo=True, num_states=1, noise=False, mod='single', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=0, w_time=1.0, sample_label=True, w_pos_label=1.0, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p12/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_unsupervised', 'wandb_tag': 'RD74-single3', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'tl_tag': 'None', 'freeze': '', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '3', 'log': 'log.txt', 'user_prefix': '[RD74-R3-TEE_C1-TEDA__pp_single_mark-concat-d0]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 128, 'lr': 0.01, 'smooth': 0.0, 'weight_decay': 0.1, 'diag_offset': 0, 'event_enc': 1, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'dam_output_activation': 'relu', 'dam_output_dims': 16, 'dam_n_phi_layers': 3, 'dam_phi_width': 128, 'dam_phi_dropout': 0.2, 'dam_n_psi_layers': 2, 'dam_psi_width': 64, 'dam_psi_latent_width': 128, 'dam_dot_prod_dim': 64, 'dam_n_heads': 4, 'dam_attn_dropout': 0.1, 'dam_latent_width': 64, 'dam_n_rho_layers': 2, 'dam_rho_width': 128, 'dam_rho_dropout': 0.1, 'dam_max_timescale': 1000, 'dam_n_positional_dims': 16, 'dam_online': False, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'single', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 0, 'w_time': 1.0, 'sample_label': 2, 'w_pos_label': 1.0, 'w_sample_label': 100.0}, date='13-06-23--17-44-09', run_id='2697244', dataset='P12', str_config='-raindrop/split3', run_name='[RD74-R3-TEE_C1-TEDA__pp_single_mark-concat-d0]2697244', run_path='/mlodata1/hokarami/tedam/p12-raindrop/split3/[RD74-R3-TEE_C1-TEDA__pp_single_mark-concat-d0]2697244/', device=device(type='cuda'), INPUT='TEDAM', OUTPUT='single-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.1420\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    }
   ],
   "source": [
    "run_path = \"hokarami/TEEDAM_supervised/56ecgyrq\" # [Q20-TEDA__nextmark-concat]1588433\n",
    "run_path = \"hokarami/TEEDAM_supervised/3x52mwgi\" # https://wandb.ai/hokarami/TEEDAM_supervised/runs/3x52mwgi/overview?workspace=user-g-hojatkarami\n",
    "run_path = \"hokarami/TEEDAM_unsupervised/ibzmm7wm\" # https://wandb.ai/hokarami/TEEDAM_unsupervised/runs/ibzmm7wm/overview?workspace=\n",
    "# run_path = \"hokarami/TEEDAM_supervised/v1nb7bhq\" # https://wandb.ai/hokarami/TEEDAM_supervised/runs/v1nb7bhq/overview?workspace=user-g-hojatkarami\n",
    "run_path = \"hokarami/TEEDAM_unsupervised/jvpugrlq\" # https://wandb.ai/hokarami/TEEDAM_unsupervised/runs/jvpugrlq/overview?workspace=user-g-hojatkarami\n",
    "\n",
    "\n",
    "run_path = \"hokarami/TEEDAM_unsupervised/a95wkhvj\" # https://wandb.ai/hokarami/TEEDAM_unsupervised/runs/a95wkhvj/overview?workspace=user-g-hojatkarami\n",
    "run_path = \"hokarami/TEEDAM_supervised/e2ty765j\" # https://wandb.ai/hokarami/TEEDAM_supervised/runs/e2ty765j/overview?workspace=user-g-hojatkarami\n",
    "\n",
    "# h0s0\n",
    "run_path = \"hokarami/TEEDAM_supervised/noufk1a0\" # https://wandb.ai/hokarami/TEEDAM_supervised/runs/noufk1a0/overview?workspace=user-g-hojatkarami\n",
    "\n",
    "# seft\n",
    "run_path = \"hokarami/TEEDAM_supervised/g0g8zo1n\" # https://wandb.ai/hokarami/TEEDAM_supervised/runs/g0g8zo1n/overview?workspace=user-g-hojatkarami\n",
    "\n",
    "# unsup\n",
    "run_path = \"hokarami/TEEDAM_unsupervised/fyn5cxoi\" # https://wandb.ai/hokarami/TEEDAM_unsupervised/runs/fyn5cxoi/overview?workspace=user-g-hojatkarami\n",
    "\n",
    "run_path = \"hokarami/TEEDAM_supervised/g0g8zo1n\" # https://wandb.ai/hokarami/TEEDAM_supervised/runs/g0g8zo1n/overview?workspace=user-g-hojatkarami\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# p19\n",
    "run_path = \"hokarami/TEEDAM_supervised/ah1p114x\" # https://wandb.ai/hokarami/TEEDAM_supervised/runs/ah1p114x?workspace=user-g-hojatkarami\n",
    "\n",
    "\n",
    "# p12 unsup TE only\n",
    "run_path = \"hokarami/TEEDAM_unsupervised/agefradk\" # https://wandb.ai/hokarami/TEEDAM_unsupervised/runs/agefradk/overview?workspace=user-g-hojatkarami\n",
    "# run_path = \"hokarami/TEEDAM_unsupervised/00gzdjvg\" # https://wandb.ai/hokarami/TEEDAM_unsupervised/runs/7732nkn7/overview?workspace=user-g-hojatkarami\n",
    "\n",
    "# # p19 sc tedam diag 0\n",
    "# run_path = \"hokarami/TEEDAM_unsupervised/lg21r2z2\" # https://wandb.ai/hokarami/TEEDAM_unsupervised/runs/lg21r2z2/overview?workspace=user-g-hojatkarami\n",
    "\n",
    "# # TEDA freeze TE\n",
    "# run_path = \"hokarami/TEEDAM_supervised/mfn0tkkj\" # https://wandb.ai/hokarami/TEEDAM_unsupervised/runs/347dttsz/overview?workspace=user-g-hojatkarami\n",
    "# # TEDA no freeze\n",
    "# run_path = \"hokarami/TEEDAM_supervised/5ft25axi\" # https://wandb.ai/hokarami/TEEDAM_unsupervised/runs/347dttsz/overview?workspace=user-g-hojatkarami\n",
    "# # DAM baseline\n",
    "# # run_path = \"hokarami/TEEDAM_supervised/jjolnx6e\" # https://wandb.ai/hokarami/TEEDAM_unsupervised/runs/347dttsz/overview?workspace=user-g-hojatkarami\n",
    "\n",
    "# p19 raindrop TE\n",
    "# run_path = \"hokarami/TEEDAM_unsupervised/5jw5p26v\" # https://wandb.ai/hokarami/TEEDAM_unsupervised/runs/5jw5p26v/overview?workspace=user-g-hojatkarami\n",
    "run_path = \"hokarami/TEEDAM_unsupervised/rn1lepki\"\n",
    "\n",
    "\n",
    "# p12 TEDAM sup rain\n",
    "run_path = \"hokarami/TEEDAM_supervised/kn42cnta\"\n",
    "# rain\n",
    "run_path = \"hokarami/TEEDAM_supervised/978ladk1\"\n",
    "# run_path = 'hokarami/TEEDAM_supervised/9qay1a75' # https://wandb.ai/hokarami/TEEDAM_supervised/runs/9qay1a75/overview?workspace=\n",
    "\n",
    "\n",
    "################ FINAL\n",
    "run_path = 'hokarami/TEEDAM_unsupervised/6gzv82mg' # https://wandb.ai/hokarami/TEEDAM_unsupervised/runs/6gzv82mg/overview?workspace=user-g-hojatkarami\n",
    "\n",
    "model1, opt1, run1 = read_from_wandb(run_path,consider_sample_labels=True)\n",
    "dict_metrics1, out1 = Main.valid_epoch_tsne(model1, opt1.validloader, opt1.pred_loss_func, opt1)\n",
    "X_tsne1 = compute_tsne(out1['r_enc_list'], model1, TSNE_LIMIT=6000)\n",
    "\n",
    "res_labels = opt1.dict_map_events.keys()\n",
    "\n",
    "df1 = build_df(out1,opt1, X_tsne1['full'],TSNE_LIMIT=100000)\n",
    "fig_tsne1 = plot_tsne(df1,title=run1.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = build_df(out1,opt1, X_tsne1['full'])\n",
    "fig_temp = plot_tsne(df_temp,title=run1.name)\n",
    "fig_temp\n",
    "\n",
    "\n",
    "df_temp = build_df(out1,opt1, X_tsne1['dam'])\n",
    "fig_temp = plot_tsne(df_temp,title=run1.name)\n",
    "fig_temp\n",
    "\n",
    "\n",
    "df_temp = build_df(out1,opt1, X_tsne1['tee'])\n",
    "fig_temp = plot_tsne(df_temp,title=run1.name)\n",
    "fig_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = build_df(out1,opt1, X_tsne1['full'])\n",
    "fig_temp = plot_tsne(df_temp,title=run1.name)\n",
    "fig_temp\n",
    "\n",
    "\n",
    "df_temp = build_df(out1,opt1, X_tsne1['dam'])\n",
    "fig_temp = plot_tsne(df_temp,title=run1.name)\n",
    "fig_temp\n",
    "\n",
    "df_temp = build_df(out1,opt1, X_tsne1['tee'])\n",
    "fig_temp = plot_tsne(df_temp,title=run1.name)\n",
    "fig_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding common patterns\n",
    "common_patterns,fig_clustering = compute_common_patterns(out1,opt1,N_CLUSTERS=10)\n",
    "# common_patterns = common_patterns[np.argsort(common_patterns.sum(1)),:]\n",
    "\n",
    "# fig_clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash app running on http://127.0.0.1:2558/\n"
     ]
    }
   ],
   "source": [
    "df1 = build_df(out1,opt1, X_tsne1['full'])\n",
    "fig_tsne1 = plot_tsne(df1,title=run1.name)\n",
    "\n",
    "run_dash_app(fig_tsne1,out1,opt1,df1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num= 100\n",
    "i_b = int(df1.iloc[num]['i_b'])\n",
    "i = int(df1.iloc[num]['i'])\n",
    "im_url, temp = cool_image(out1,i_b,i,opt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_ids =  [26, 49, 126, 133, 148, 156, 160, 197, 202, 227, 230, 371, 397, 404, 405, 422, 467, 485, 524, 558, 560, 562, 586, 644, 654, 668, 691, 730, 751]\n",
    "\n",
    "point_ids=[1]\n",
    "\n",
    "fig_agg_mat, fig_freqs, fig_patterns = plot_heatmap_att_agg(df1,out1,point_ids,event_labels=list(opt1.dict_map_events.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "x= df1.loc[df1.color_true=='Positive Samples','color_integral_']\n",
    "y= df1.loc[df1.color_true=='Negative Samples','color_integral_']\n",
    "\n",
    "x.mean(), x.std()\n",
    "y.mean(), y.std()\n",
    "\n",
    "from scipy.stats import ttest_ind\n",
    "t_statistic, p_value = ttest_ind(x, y, alternative='two-sided')\n",
    "# Print the results\n",
    "print('t-statistic =', t_statistic)\n",
    "print('p-value =', p_value)\n",
    "\n",
    "df1['color_integral_'].corr(df1['color_t_max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num=148\n",
    "i_b = int(df1.iloc[num]['i_b'])\n",
    "i = int(df1.iloc[num]['i'])\n",
    "\n",
    "merged_img,(att_mat_img,img_ev),tempp = cool_image(out1,i_b,i,opt1,CROP=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_ids = [3, 42, 56, 68, 133, 140, 209, 222, 265, 293, 302, 307, 336, 362, 368, 369, 430, 494, 549, 582, 597, 648, 650, 674, 730, 3, 42, 56, 68, 133, 140, 209, 222, 265, 293, 302, 307, 336, 362, 368, 369, 430, 494, 549, 582, 597, 648, 650, 674, 730, 3, 42, 56, 68, 133, 140, 209, 222, 265, 293, 302, 307, 336, 362, 368, 369, 430, 494, 549, 582, 597, 648, 650, 674, 730]\n",
    "\n",
    "fig_agg_mat, fig_freqs, fig_patterns = plot_heatmap_att_agg(df1,out1,point_ids,event_labels=list(opt1.dict_map_events.keys()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataVis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT DAM --> none-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p19-mc1-H0/split3/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='', freeze='', ES_pat=100, setting='mc1', test_center='0', split='3', log='log.txt', user_prefix='[H70HHGGG--DA__base-concat]', pos_alpha=1.0, epoch=50, batch_size=128, lr=0.01, smooth=0.0, weight_decay=0.1, diag_offset=0, event_enc=0, time_enc='concat', te_d_mark=32, te_d_time=16, te_d_rnn=256, te_d_inner=128, te_d_k=32, te_d_v=32, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=False, num_states=1, noise=False, mod='none', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=1, w_time=1.0, sample_label=True, w_pos_label=1.0, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p19/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'freeze': '', 'ES_pat': 100, 'setting': 'mc1', 'test_center': '0', 'split': '3', 'log': 'log.txt', 'user_prefix': '[H70HHGGG--DA__base-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 128, 'lr': 0.01, 'smooth': 0.0, 'weight_decay': 0.1, 'diag_offset': 0, 'event_enc': 0, 'time_enc': 'concat', 'te_d_mark': 32, 'te_d_time': 16, 'te_d_rnn': 256, 'te_d_inner': 128, 'te_d_k': 32, 'te_d_v': 32, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': False, 'num_states': 1, 'noise': False, 'mod': 'none', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 1, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 1.0, 'w_sample_label': 100.0}, date='18-04-23--13-57-06', run_id='2138741', dataset='P19', str_config='-mc1-H0/split3', run_name='[H70HHGGG--DA__base-concat]2138741', run_path='/mlodata1/hokarami/tedam/p19-mc1-H0/split3/[H70HHGGG--DA__base-concat]2138741/', device=device(type='cuda'), INPUT='DAM', OUTPUT='none-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.0760\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    }
   ],
   "source": [
    "run_path=\"hokarami/TEEDAM_supervised/gonf2p65\" # https://wandb.ai/hokarami/TEEDAM_supervised/runs/gonf2p65/overview?workspace=user-g-hojatkarami\n",
    "# run_path = \"hokarami/TEEDAM_unsupervised/00gzdjvg\" # https://wandb.ai/hokarami/TEEDAM_unsupervised/runs/7732nkn7/overview?workspace=user-g-hojatkarami\n",
    "\n",
    "#[H70--DA__base-concat]1886602\n",
    "# https://wandb.ai/hokarami/TEEDAM_supervised/runs/qjximpg2/overview?workspace=user-g-hojatkarami\n",
    "\n",
    "run_path = \"hokarami/TEEDAM_supervised/umanlw17\" \n",
    "model1, opt1, run1 = read_from_wandb(run_path,consider_sample_labels=True)\n",
    "dict_metrics1, out1 = Main.valid_epoch_tsne(model1, opt1.validloader, opt1.pred_loss_func, opt1)\n",
    "X_tsne1 = compute_tsne(out1['r_enc_list'], model1, TSNE_LIMIT=100000)\n",
    "\n",
    "res_labels = opt1.dict_map_events.keys()\n",
    "\n",
    "df1 = build_df(out1,opt1, X_tsne1['full'],TSNE_LIMIT=100000)\n",
    "fig_tsne1 = plot_tsne(df1,title=run1.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>color</th>\n",
       "      <th>id</th>\n",
       "      <th>color_true_pred</th>\n",
       "      <th>color_true</th>\n",
       "      <th>color_pred</th>\n",
       "      <th>i_b</th>\n",
       "      <th>i</th>\n",
       "      <th>color_t_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.302624</td>\n",
       "      <td>9.027914</td>\n",
       "      <td>True Positives</td>\n",
       "      <td>0</td>\n",
       "      <td>True Predicted</td>\n",
       "      <td>Positive Samples</td>\n",
       "      <td>Positive Predicted</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>253.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-18.577684</td>\n",
       "      <td>25.866301</td>\n",
       "      <td>True Negatives</td>\n",
       "      <td>1</td>\n",
       "      <td>True Predicted</td>\n",
       "      <td>Negative Samples</td>\n",
       "      <td>Negative Predicted</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38.309669</td>\n",
       "      <td>5.836884</td>\n",
       "      <td>True Positives</td>\n",
       "      <td>2</td>\n",
       "      <td>True Predicted</td>\n",
       "      <td>Positive Samples</td>\n",
       "      <td>Positive Predicted</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.636146</td>\n",
       "      <td>-22.101767</td>\n",
       "      <td>True Negatives</td>\n",
       "      <td>3</td>\n",
       "      <td>True Predicted</td>\n",
       "      <td>Negative Samples</td>\n",
       "      <td>Negative Predicted</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.912963</td>\n",
       "      <td>24.707033</td>\n",
       "      <td>True Negatives</td>\n",
       "      <td>4</td>\n",
       "      <td>True Predicted</td>\n",
       "      <td>Negative Samples</td>\n",
       "      <td>Negative Predicted</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2299</th>\n",
       "      <td>10.859934</td>\n",
       "      <td>-46.647694</td>\n",
       "      <td>False Positives</td>\n",
       "      <td>2299</td>\n",
       "      <td>False Predicted</td>\n",
       "      <td>Negative Samples</td>\n",
       "      <td>Positive Predicted</td>\n",
       "      <td>17</td>\n",
       "      <td>123</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2300</th>\n",
       "      <td>11.340622</td>\n",
       "      <td>-8.474674</td>\n",
       "      <td>True Negatives</td>\n",
       "      <td>2300</td>\n",
       "      <td>True Predicted</td>\n",
       "      <td>Negative Samples</td>\n",
       "      <td>Negative Predicted</td>\n",
       "      <td>17</td>\n",
       "      <td>124</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2301</th>\n",
       "      <td>9.653085</td>\n",
       "      <td>-32.591232</td>\n",
       "      <td>False Positives</td>\n",
       "      <td>2301</td>\n",
       "      <td>False Predicted</td>\n",
       "      <td>Negative Samples</td>\n",
       "      <td>Positive Predicted</td>\n",
       "      <td>17</td>\n",
       "      <td>125</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2302</th>\n",
       "      <td>20.587936</td>\n",
       "      <td>-17.835924</td>\n",
       "      <td>True Negatives</td>\n",
       "      <td>2302</td>\n",
       "      <td>True Predicted</td>\n",
       "      <td>Negative Samples</td>\n",
       "      <td>Negative Predicted</td>\n",
       "      <td>17</td>\n",
       "      <td>126</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2303</th>\n",
       "      <td>-19.895651</td>\n",
       "      <td>9.827409</td>\n",
       "      <td>True Negatives</td>\n",
       "      <td>2303</td>\n",
       "      <td>True Predicted</td>\n",
       "      <td>Negative Samples</td>\n",
       "      <td>Negative Predicted</td>\n",
       "      <td>17</td>\n",
       "      <td>127</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2304 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              x          y            color    id  color_true_pred  \\\n",
       "0     34.302624   9.027914   True Positives     0   True Predicted   \n",
       "1    -18.577684  25.866301   True Negatives     1   True Predicted   \n",
       "2     38.309669   5.836884   True Positives     2   True Predicted   \n",
       "3     -1.636146 -22.101767   True Negatives     3   True Predicted   \n",
       "4      3.912963  24.707033   True Negatives     4   True Predicted   \n",
       "...         ...        ...              ...   ...              ...   \n",
       "2299  10.859934 -46.647694  False Positives  2299  False Predicted   \n",
       "2300  11.340622  -8.474674   True Negatives  2300   True Predicted   \n",
       "2301   9.653085 -32.591232  False Positives  2301  False Predicted   \n",
       "2302  20.587936 -17.835924   True Negatives  2302   True Predicted   \n",
       "2303 -19.895651   9.827409   True Negatives  2303   True Predicted   \n",
       "\n",
       "            color_true          color_pred  i_b    i  color_t_max  \n",
       "0     Positive Samples  Positive Predicted    0    0        253.0  \n",
       "1     Negative Samples  Negative Predicted    0    1         37.0  \n",
       "2     Positive Samples  Positive Predicted    0    2        128.0  \n",
       "3     Negative Samples  Negative Predicted    0    3         48.0  \n",
       "4     Negative Samples  Negative Predicted    0    4         36.0  \n",
       "...                ...                 ...  ...  ...          ...  \n",
       "2299  Negative Samples  Positive Predicted   17  123         47.0  \n",
       "2300  Negative Samples  Negative Predicted   17  124         39.0  \n",
       "2301  Negative Samples  Positive Predicted   17  125         40.0  \n",
       "2302  Negative Samples  Negative Predicted   17  126         53.0  \n",
       "2303  Negative Samples  Negative Predicted   17  127         31.0  \n",
       "\n",
       "[2304 rows x 10 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_json = list()\n",
    "\n",
    "\n",
    "for i_b, i, label in zip(df1.i_b, df1.i, df1.color_true):\n",
    "\n",
    "\n",
    "    st=out1['state_time_list'][i_b][i]\n",
    "    sm=out1['state_mod_list'][i_b][i]\n",
    "    sv=( out1['state_value_list'][i_b][i] )\n",
    "\n",
    "    dam_att = out1['list_DAM_att'][i_b][i].mean(1)# [P,h]\n",
    "\n",
    "    dam_att = dam_att / dam_att.sum()\n",
    "\n",
    "\n",
    "    m= (st>0).sum()\n",
    "\n",
    "    temp = [ {\n",
    "                \"abs_time\": st[i].item(),\n",
    "                \"value\": round(sv[i].item(),3),\n",
    "                \"mod\": sm[i].item(),\n",
    "                \"att\": round(dam_att[i].item(),3),\n",
    "                \"label\":label\n",
    "            } for i in range(m)]\n",
    "    data_json.append(temp)\n",
    "    # out1.keys()\n",
    "    # out1['list_DAM_att'][0].shape\n",
    "    # out1['state_mod_list'][0].shape\n",
    "    # out1['state_time_list'][0].shape\n",
    "    # out1['state_value_list'][0].shape\n",
    "\n",
    "    # for i,mod in enumerate(out1['state_mod_list']):\n",
    "    #     mod.shape\n",
    "    #     m = (mod>0).sum(1)\n",
    "    #     m.max()\n",
    "    #     term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69098309"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('test.json','w') as f:\n",
    "    f.write(json.dumps(data_json))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['full', 'dam'])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(2304, 2)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "39464"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "X_tsne1.keys()\n",
    "X_tsne1['full'].shape\n",
    "type(X_tsne1['full'])\n",
    "list2save = df1.iloc[:500][['x','y','color']].to_dict('records')\n",
    "\n",
    "# save list to json\n",
    "with open('tsne_datavis.json','w') as f:\n",
    "    f.write(json.dumps(list2save))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "443"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "temp = {v:k for k,v in opt1.dict_map_states.items()}\n",
    "\n",
    "\n",
    "with open('dict_map_states.json','w') as f:\n",
    "    f.write(json.dumps(temp))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_path =  \"hokarami/TEEDAM_supervised/lzvf7erg\" # [Q20-DA__base-concat]1586915\n",
    "\n",
    "\n",
    "\n",
    "run_path = \"hokarami/TEEDAM_unsupervised/su87zi5z\" # https://wandb.ai/hokarami/TEEDAM_unsupervised/runs/su87zi5z/overview?workspace=user-g-hojatkarami\n",
    "\n",
    "# h0s0\n",
    "run_path = \"hokarami/TEEDAM_supervised/bxawmk71\" # https://wandb.ai/hokarami/TEEDAM_supervised/runs/bxawmk71/overview?workspace=user-g-hojatkarami\n",
    "\n",
    "# seft\n",
    "run_path = \"hokarami/TEEDAM_supervised/qvdve9d5\" # https://wandb.ai/hokarami/TEEDAM_supervised/runs/qvdve9d5?workspace=user-g-hojatkarami\n",
    "\n",
    "# seft\n",
    "run_path = \"hokarami/TEEDAM_supervised/qvdve9d5\" # https://wandb.ai/hokarami/TEEDAM_supervised/runs/qvdve9d5?workspace=user-g-hojatkarami\n",
    "\n",
    "\n",
    "# so\n",
    "# run_path = \"hokarami/TEEDAM_unsupervised_timeCat/22xvwu9y\" # https://wandb.ai/hokarami/TEEDAM_unsupervised/runs/su87zi5z/overview?workspace=user-g-hojatkarami\n",
    "\n",
    "\n",
    "# p19\n",
    "run_path =  \"hokarami/TEEDAM_supervised/yftm62nl\" # https://wandb.ai/hokarami/TEEDAM_supervised/runs/yftm62nl?workspace=user-g-hojatkarami\n",
    "\n",
    "\n",
    "\n",
    "model2, opt2, run2 = read_from_wandb(run_path)\n",
    "dict_metrics2, out2 = Main.valid_epoch_tsne(model2, opt2.validloader, opt2.pred_loss_func, opt2)\n",
    "X_tsne2, X_tsne_split2 = compute_tsne(out2['r_enc_list'], model2)\n",
    "\n",
    "# res_labels = opt2.dict_map_events.keys()\n",
    "\n",
    "df2 = build_df(out2,opt2, X_tsne2)\n",
    "fig_tsne2 = plot_tsne(df2,title=run2.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = build_df(out2,opt2, X_tsne2)\n",
    "fig_temp = plot_tsne(df_temp,title=run2.name)\n",
    "fig_temp\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "run_dash_app(fig_tsne2,out2,opt2,df2)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_path = \"hokarami/TEEDAM_unsupervised_timeCat/ecw38vpt\" # https://wandb.ai/hokarami/TEEDAM_unsupervised_timeCat/runs/ecw38vpt/overview?workspace=user-g-hojatkarami\n",
    "run_path = \"hokarami/TEEDAM_unsupervised_timeCat/2vxzsnyv\" # https://wandb.ai/hokarami/TEEDAM_unsupervised_timeCat/runs/ol0mjnyt/overview?workspace=user-g-hojatkarami\n",
    "\n",
    "model3, opt3, run3 = read_from_wandb(run_path)\n",
    "\n",
    "temp = [\"Nice Question\",\"Good Anser\",\"Guru\",\"Popular Question\",\"Famou Question\",\"Nice Answer\",\"Good Question\", \"Caucus\",\"Notable Question\",\"Nercromancer\",\"Promoter\",\"Yearling\",\"Revival\",\"Enlightened\",\"Greateanswer\",\"Populist\",\"Great Question\",\"Constituent\",\"Announcer\",\"Stellar Question\",\"Booster\",\"Publicist\"]\n",
    "opt3.dict_map_events = {i:x for i,x in enumerate(temp)}\n",
    "\n",
    "\n",
    "\n",
    "dict_metrics3, out3 = Main.valid_epoch_tsne(model3, opt3.validloader, opt3.pred_loss_func, opt3)\n",
    "X_tsne3, X_tsne_split3 = compute_tsne(out3['r_enc_list'], model3)\n",
    "\n",
    "if hasattr(opt3,'dict_map_events'):\n",
    "    res_labels = opt3.dict_map_events.keys()\n",
    "\n",
    "df3 = build_df(out3,opt3, X_tsne3)\n",
    "fig_tsne3 = plot_tsne(df3,title=run3.name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out=out3\n",
    "i_b=0\n",
    "\n",
    "out.keys()\n",
    "\n",
    "y = out['y_true'][:]\n",
    "y_p = out['y_pred'][:]\n",
    "e = out['event_type_list'][i_b][0,1:]\n",
    "p = out['next_event_type_list'][i_b][0,1:]\n",
    "e_next = out['event_type_list'][i_b][0,:-1]\n",
    "\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "metrics.roc_auc_score(y,y_p,average='weighted')\n",
    "metrics.roc_auc_score(y, y_p, labels= torch.arange(3) ,average=None)\n",
    "metrics.accuracy_score(y, y_p, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape\n",
    "\n",
    "# y[:100]\n",
    "\n",
    "px.imshow(y[100:200].transpose())\n",
    "px.imshow(y_p[100:200].transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(y, y_p)[:,:9]\n",
    "\n",
    "np.unique(y,return_counts=True)\n",
    "metrics.f1_score(y, y_p, labels= torch.arange(22) ,average=None, zero_division=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding common patterns\n",
    "common_patterns,fig_clustering = compute_common_patterns(out3,opt3)\n",
    "# fig_clustering\n",
    "\n",
    "df3 = build_df(out3,opt3, X_tsne3)\n",
    "fig_tsne3 = plot_tsne(df3,title=run3.name)\n",
    "\n",
    "run_dash_app(fig_tsne3,out3,opt3,df3)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid=90\n",
    "i_b = int(df1.iloc[pid]['i_b'])\n",
    "i = int(df1.iloc[pid]['i'])\n",
    "i_b,i\n",
    "_,temp = cool_image(out1,i_b,i,opt1)\n",
    "temp[0]\n",
    "\n",
    "\n",
    "fig_cif = plot_cif(out1,i_b,i)\n",
    "fig_cif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out1.keys()\n",
    "out1['next_event_type_list'][10][94].shape\n",
    "out1['event_type_list'][10][94].shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K nearest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head(2)\n",
    "df2.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## knn-ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_knn=5\n",
    "pid_all = list(df1.index)\n",
    "\n",
    "pid_positive = list(df1[df1.color_true=='Positive Samples'].index)\n",
    "\n",
    "list_sim_score1 = []\n",
    "list_sim_score2 = []\n",
    "\n",
    "X1 = np.concatenate(out1['r_enc_list'],axis=0)[:,:model1.d_out_te]\n",
    "X2 = np.concatenate(out2['r_enc_list'],axis=0)[:,:]\n",
    "\n",
    "for pid in tqdm( pid_positive ):\n",
    "    id_origin = pid\n",
    "\n",
    "    knn_pids = find_knn_pids (X1, id_origin, n_knn=n_knn)\n",
    "    sim_score1, list_summary = cal_similarity(df1, out1, pid, knn_pids)    \n",
    "\n",
    "\n",
    "    knn_pids = find_knn_pids (X2, id_origin, n_knn=n_knn)\n",
    "    sim_score2, list_summary = cal_similarity(df2, out2, pid, knn_pids)    \n",
    "    \n",
    "    if ( not np.isnan(sim_score1) ) and ( not np.isnan(sim_score2) ):\n",
    "        list_sim_score1.append(sim_score1)\n",
    "        list_sim_score2.append(sim_score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(list_sim_score1), np.std(list_sim_score1)\n",
    "np.mean(list_sim_score2), np.std(list_sim_score2)\n",
    "\n",
    "diff = np.array(list_sim_score1) - np.array(list_sim_score2)\n",
    "diff.sum()/len(diff)\n",
    "diff.argsort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "\n",
    "group1 = [x-0.0 for x in list_sim_score1]\n",
    "group2 = list_sim_score2\n",
    "t_statistic, p_value = ttest_ind(group1, group2, alternative='greater')\n",
    "\n",
    "# Print the results\n",
    "print('t-statistic =', t_statistic)\n",
    "print('p-value =', p_value)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save selected to local\n",
    "n_knn=5\n",
    "id_origin = 90\n",
    "\n",
    "len_CROP = len(opt1.dict_map_states.keys()) - len(opt1.dict_map_events.keys())\n",
    "len_CROP\n",
    "\n",
    "X1 = np.concatenate(out1['r_enc_list'],axis=0)[:,:model1.d_out_te]\n",
    "X2 = np.concatenate(out2['r_enc_list'],axis=0)[:,:]\n",
    "\n",
    "\n",
    "            # plot and save id_origin\n",
    "i_b = df1.iloc[id_origin]['i_b']\n",
    "i = df1.iloc[id_origin]['i']\n",
    "im_url, temp = cool_image(out1,i_b,i,opt1)\n",
    "im_url.save(f\"./local/images/Origin_{id_origin}.png\")\n",
    "\n",
    "            # save event attentions\n",
    "_,temp = cool_image(out1,i_b,i,opt1)\n",
    "temp[0].save(f\"./local/images/Origin_{id_origin}_att.png\")\n",
    "\n",
    "            # save cif plot\n",
    "fig_cif = plot_cif(out1,i_b,i)\n",
    "fig_cif.write_image(f\"./local/images/Origin_{id_origin}_CIF.svg\")\n",
    "\n",
    "\n",
    "i_g=0\n",
    "for out,opt,df,X in zip([out1,out2],[opt1,opt2],[df1,df2],[X1,X2]):\n",
    "    knn_pids = find_knn_pids (X, id_origin, n_knn=n_knn)\n",
    "    knn_pids\n",
    "    for pid in knn_pids:\n",
    "        # NEW\n",
    "        i_b = df.iloc[pid]['i_b']\n",
    "        i = df.iloc[pid]['i']\n",
    "        im_url, temp = cool_image(out,i_b,i,opt,CROP=len_CROP)\n",
    "        im_url.save(f\"./local/images/C{i_g}_{pid}.png\")\n",
    "\n",
    "\n",
    "\n",
    "    i_g+=1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cif diff"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$log(\\lambda)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pid_positive = list(df1[df1.color_true=='Positive Samples'].index)\n",
    "pid_negative = list(df1[df1.color_true=='Negative Samples'].index)\n",
    "\n",
    "list_sim_score1 = []\n",
    "list_sim_score2 = []\n",
    "\n",
    "lens = np.concatenate([x.sum(1).cpu().detach() for x in out1['non_pad_mask_list']])\n",
    "X = np.concatenate(out1['list_log_sum'],axis=0) # [n_samples]\n",
    "Y = np.concatenate(out1['list_integral_'],axis=0)/lens # [n_samples]\n",
    "\n",
    "\n",
    "X[pid_positive].mean(), X[pid_positive].std()\n",
    "\n",
    "X[pid_negative].mean(), X[pid_negative].std()\n",
    "\n",
    "\n",
    "\n",
    "Y[pid_positive].mean(), Y[pid_positive].std()\n",
    "\n",
    "Y[pid_negative].mean(), Y[pid_negative].std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "\n",
    "group1 = X[pid_positive]\n",
    "group2 = X[pid_negative]\n",
    "t_statistic, p_value = ttest_ind(group1, group2, alternative='greater')\n",
    "\n",
    "# Print the results\n",
    "print('t-statistic =', t_statistic)\n",
    "print('p-value =', p_value)\n",
    "\n",
    "\n",
    "group1 = Y[pid_positive]\n",
    "group2 = Y[pid_negative]\n",
    "t_statistic, p_value = ttest_ind(group1, group2, alternative='greater')\n",
    "\n",
    "# Print the results\n",
    "print('t-statistic =', t_statistic)\n",
    "print('p-value =', p_value)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "integral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clusters = [\n",
    "\n",
    "[1715, 1212, 957, 834, 1401, 1532, 33, 514, 559, 1493],\n",
    "[1715, 1542, 808, 957, 1541, 1296, 252, 978, 34, 1204]\n",
    "\n",
    "\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "df = df1\n",
    "out = out1\n",
    "\n",
    "fig2 = go.Figure()\n",
    "for i_c, cluster in enumerate(clusters):\n",
    "    list_summary = []\n",
    "    for pid in cluster:\n",
    "        \n",
    "\n",
    "        i_b = df.iloc[pid]['i_b']\n",
    "        i = df.iloc[pid]['i']\n",
    "\n",
    "        ev = out['event_type_list'][i_b][i]\n",
    "        t = out['event_time_list'][i_b][i]\n",
    "        st=out['state_time_list'][i_b][i]\n",
    "        \n",
    "        P = st.int().max().item() + 1\n",
    "\n",
    "        M = event2mat(ev,t,P)\n",
    "\n",
    "        \n",
    "\n",
    "        vector = M.sum(1)/M.shape[1]*24\n",
    "\n",
    "        \n",
    "        list_summary.append(vector)\n",
    "        \n",
    "\n",
    "    dotp = [ np.dot(j,list_summary[0])/(np.linalg.norm(j) * np.linalg.norm(list_summary[0])) for  j in list_summary]\n",
    "    np.mean( dotp )\n",
    "\n",
    "    vec_mean = np.mean(list_summary,axis=0)\n",
    "    vec_std = np.std(list_summary,axis=0)\n",
    "\n",
    "    # sum(vec_std)\n",
    "\n",
    "    \n",
    "    _ = fig2.add_trace(go.Bar(\n",
    "        name=f'Cluster {i_c}',\n",
    "        x=list(res_labels), y=vec_mean,\n",
    "        error_y=dict(type='data', array=vec_std)\n",
    "    ))\n",
    "\n",
    "fig2.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_tsne1.write_image(\"local/images/fig1.svg\")\n",
    "fig_tsne2.write_image(\"local/images/fig2.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save selected to local\n",
    "n_knn=5\n",
    "id_origin = 420\n",
    "\n",
    "X1 = np.concatenate(out1['r_enc_list'],axis=0)[:,:model1.d_out_te]\n",
    "X2 = np.concatenate(out2['r_enc_list'],axis=0)[:,:]\n",
    "\n",
    "i_g=0\n",
    "for out,opt,df,X in zip([out1,out2],[opt1,opt2],[df1,df2],[X1,X2]):\n",
    "    \n",
    "    knn_pids = find_knn_pids (X, id_origin, n_knn=n_knn)\n",
    "    knn_pids\n",
    "    # for pid in knn_pids:\n",
    "    #     # NEW\n",
    "    #     i_b = df.iloc[pid]['i_b']\n",
    "    #     i = df.iloc[pid]['i']\n",
    "    #     im_url, temp = cool_image(out,i_b,i,opt,CROP=11)\n",
    "    #     # im_url.save(f\"./local/images/C{i_g}_{pid}.png\")\n",
    "    i_g+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_fig =  go.Figure()\n",
    "# new_fig = go.Figure(data=fig_prev['data'],layout=fig_prev['layout'])\n",
    "\n",
    "\n",
    "# new_fig = bar_summary(df,out, point_ids,res_labels, fig=new_fig)\n",
    "\n",
    "n_knn=5\n",
    "id_origin = 583\n",
    "\n",
    "X1 = np.concatenate(out1['r_enc_list'],axis=0)[:,:model1.d_out_te]\n",
    "X2 = np.concatenate(out2['r_enc_list'],axis=0)[:,:]\n",
    "\n",
    "new_fig = bar_summary(df,out, [id_origin],res_labels, fig=new_fig)\n",
    "\n",
    "for out,opt,df,X in zip([out1,out2],[opt1,opt2],[df1,df2],[X1,X2]):\n",
    "    knn_pids = find_knn_pids (X, id_origin, n_knn=n_knn)\n",
    "    \n",
    "    new_fig = bar_summary(df,out, knn_pids,res_labels, fig=new_fig)\n",
    "\n",
    "new_fig\n",
    "new_fig.write_image(\"local/images/bar.svg\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIF vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df1\n",
    "out=out1\n",
    "pid_positive = list(df1[df1.color_true=='Positive Samples'].index)\n",
    "pid_negative = list(df1[df1.color_true=='Negative Samples'].index)\n",
    "\n",
    "\n",
    "\n",
    "fig=go.Figure()\n",
    "\n",
    "for pid in pid_positive[:50]:\n",
    "\n",
    "    i_b = int(df.iloc[pid]['i_b'])\n",
    "    i = int(df.iloc[pid]['i'])\n",
    "    taus,cifs_int = cif_cum(out1,i_b,i, fig=None)\n",
    "    _ = fig.add_trace(go.Scatter(x=taus,y=cifs_int,marker=dict(\n",
    "                    # size=2,\n",
    "                    color='red',\n",
    "                )))\n",
    "    \n",
    "for pid in pid_negative[:50]:\n",
    "\n",
    "    i_b = int(df.iloc[pid]['i_b'])\n",
    "    i = int(df.iloc[pid]['i'])\n",
    "    taus,cifs_int = cif_cum(out1,i_b,i, fig=None)\n",
    "    _ = fig.add_trace(go.Scatter(x=taus,y=cifs_int,marker=dict(\n",
    "                    # size=2,\n",
    "                    color='blue',\n",
    "                )))\n",
    "\n",
    "\n",
    "_=fig.update_layout(\n",
    "        # autosize=False,\n",
    "        # title=title,\n",
    "        width=600,\n",
    "        height=600,\n",
    "        showlegend=False,\n",
    "\n",
    "    )\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt1.dict_map_events.keys()\n",
    "\n",
    "\n",
    "for i,k in enumerate(opt1.dict_map_events.keys()):\n",
    "    print(f'{i}:{k}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out=out1\n",
    "opt=opt1\n",
    "out.keys()\n",
    "\n",
    "\n",
    "all_events=np.concatenate(out['event_type_list'],axis=1) # [B,LLLLLL,K] or [B,LLLL]\n",
    "\n",
    "if opt.data_label=='multiclass':\n",
    "    identity = np.eye(opt.num_marks+1,dtype=np.int8)\n",
    "    all_events = identity.take(all_events, axis=0)[:,:,1:] #  [B,LLLL] -> [B,LLLLLL,K]\n",
    "\n",
    "\n",
    "\n",
    "all_events.shape\n",
    "masks=all_events.sum(-1)>0\n",
    "\n",
    "\n",
    "\n",
    "TSNE_LIMIT=16000\n",
    "X = all_events[masks][:TSNE_LIMIT]\n",
    "\n",
    "\n",
    "X_str = [''.join(str(cell) for cell in row) for row in X]\n",
    "\n",
    "X.shape\n",
    "len(X_str)\n",
    "\n",
    "df=pd.DataFrame()\n",
    "df['val']=list(X)\n",
    "df['str']=X_str\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "tsne = TSNE(n_components=2, perplexity=60, learning_rate=10,n_jobs=4)\n",
    "X_tsne = tsne.fit_transform(X[:TSNE_LIMIT,:])\n",
    "\n",
    "df['x']=X_tsne[:,0]\n",
    "df['y']=X_tsne[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df['str'].unique())\n",
    "\n",
    "s = df['str'].value_counts()/df['str'].value_counts().sum()\n",
    "s[s>0.001].head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans,AgglomerativeClustering,DBSCAN\n",
    "import numpy as np\n",
    "\n",
    "N_CLUSTERS=22\n",
    "\n",
    "# Generate sample binary data\n",
    "data = X\n",
    "\n",
    "# Initialize KMeans object with 2 clusters\n",
    "kmeans = KMeans(n_clusters=N_CLUSTERS)\n",
    "\n",
    "# Fit the data to the KMeans object\n",
    "_ = kmeans.fit(data)\n",
    "\n",
    "# Get the labels and cluster centers\n",
    "labels = kmeans.labels_\n",
    "centers = kmeans.cluster_centers_\n",
    "\n",
    "labels\n",
    "\n",
    "\n",
    "\n",
    "df['cluster_kmeans']=labels\n",
    "\n",
    "fig=px.scatter(df,x='x',y='y',color='cluster_kmeans',hover_data=[\"str\"])\n",
    "fig\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Initialize DBSCAN object\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
    "\n",
    "# Fit the data to the DBSCAN object\n",
    "dbscan.fit(data)\n",
    "\n",
    "# Get the labels\n",
    "labels = dbscan.labels_\n",
    "\n",
    "df['cluster_dbscan']=labels\n",
    "\n",
    "fig=px.scatter(df,x='x',y='y',color='cluster_dbscan',hover_data=[\"str\"])\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METHOD = 'cluster_kmeans'\n",
    "\n",
    "common_patterns = []\n",
    "\n",
    "\n",
    "if opt.data_label=='multiclass':\n",
    "    common_patterns=np.eye(opt.num_marks,dtype=np.int8)\n",
    "\n",
    "else:\n",
    "    for i in range(N_CLUSTERS):\n",
    "        temp = df[df[METHOD]==i]['val'].values\n",
    "        temp = (temp.sum()/temp.shape[0]*100).astype(int)\n",
    "\n",
    "        temp[temp<30]=0\n",
    "        temp[temp>=30]=1\n",
    "        print(temp,'\\n')\n",
    "        common_patterns.append(temp)\n",
    "\n",
    "    common_patterns = np.array(common_patterns)\n",
    "common_patterns.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt3.diag_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_b=3\n",
    "i=3\n",
    "\n",
    "tee_mapped, norm = att_map(out3,i_b,i,common_patterns)\n",
    "\n",
    "tee_mapped[:5,:5]\n",
    "norm[:5,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df3\n",
    "out=out3\n",
    "\n",
    "point_ids = [2, 7, 15, 23, 34, 36, 37, 44, 49, 63, 74, 79, 83, 86, 87, 89, 93, 109, 115, 116, 117, 123, 128, 135, 137, 140, 153, 154, 159, 160, 168, 172, 174, 179, 202, 217, 226, 236, 245, 247, 257, 258, 259, 260, 261, 278, 281, 286, 287, 311, 319, 334, 336, 347, 348, 351, 364, 379, 386, 420, 426, 431, 443, 448, 455, 460, 466, 467, 469, 480, 487, 491, 500, 505, 517, 518, 523, 2, 7, 15, 23, 34, 36, 37, 44, 49, 63, 74, 79, 83, 86, 87, 89, 93, 109, 115, 116, 117, 123, 128, 135, 137, 140, 153, 154, 159, 160, 168, 172, 174, 179, 202, 217, 226, 236, 245, 247, 257, 258, 259, 260, 261, 278, 281, 286, 287, 311, 319, 334, 336, 347, 348, 351, 364, 379, 386, 420, 426, 431, 443, 448, 455, 460, 466, 467, 469, 480, 487, 491, 500, 505, 517, 518, 523]\n",
    "\n",
    "att_maps=[]\n",
    "att_norms=[]\n",
    "for pid in point_ids:\n",
    "\n",
    "    i_b = int(df.iloc[pid]['i_b'])\n",
    "    i = int(df.iloc[pid]['i'])\n",
    "\n",
    "    tee_mapped, norm = att_map(out,i_b,i,common_patterns)\n",
    "    att_maps.append(tee_mapped  )\n",
    "    att_norms.append(norm  )\n",
    "\n",
    "norms_matrix = sum(att_norms)\n",
    "norms_matrix[norms_matrix==0]=1\n",
    "agg_matrix = sum(att_maps)/norms_matrix\n",
    "# agg_matrix[agg_matrix<0.5]=0\n",
    "agg_matrix[norms_matrix<20]=0\n",
    "\n",
    "norms_matrix[6,16]\n",
    "agg_matrix[6,16]\n",
    "\n",
    "if len(out['event_type_list'][0].shape)==2: # if multi_class\n",
    "    patt_str = [f'C {i}' for i in range(common_patterns.shape[0])]\n",
    "else:\n",
    "    patt_str = [''.join(str(cell) for cell in row) for row in common_patterns]\n",
    "\n",
    "patt_str = [f'C {i}' for i in range(common_patterns.shape[0])]\n",
    "\n",
    "fig_agg_mat = px.imshow(agg_matrix, x=patt_str, y=patt_str)\n",
    "fig_agg_mat\n",
    "\n",
    "fig_freqs = px.imshow(norms_matrix, x=patt_str, y=patt_str)\n",
    "fig_freqs\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TL (tsne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api = wandb.Api()\n",
    "runs = api.runs(\"hokarami/TEEDAM_supervised\")\n",
    "df_filt = dl_runs(runs, selected_tag='RD74-TableIII')\n",
    "len(df_filt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array(['', 'DO'], dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_config = pd.DataFrame(   [{k:v for k,v in x.items()} for x in df_filt.config]    )\n",
    "df_summary = pd.DataFrame(   [{k:v for k,v in x.items()} for x in df_filt.summary]    )\n",
    "df_path = df_filt.path.apply(lambda x:'/'.join(x))\n",
    "df_con = pd.concat([df_config, df_summary, df_path],axis=1)\n",
    "len(df_con)\n",
    "\n",
    "df_con['transfer_learning'].unique()\n",
    "\n",
    "if 'knn-ps-mean' in df_con:\n",
    "    q = (  (df_con['transfer_learning']=='DO') & (df_con['knn-ps-mean'].isnull())  )  | ((df_con['INPUT']=='DAM') & (df_con['knn-ps-mean'].isnull())  )\n",
    "else:\n",
    "    q = df_con['transfer_learning'].astype(bool)+True\n",
    "\n",
    "  \n",
    "df_con = df_con[q]\n",
    "len(df_con)\n",
    "run_paths = df_con.path.tolist()\n",
    "\n",
    "\n",
    "# run_paths = [\"hokarami/TEEDAM_supervised/jjolnx6e\",\n",
    "#              \"hokarami/TEEDAM_supervised/mfn0tkkj\"  \n",
    "#              ]\n",
    "\n",
    "# # TEDA freeze TE\n",
    "# run_path = \"hokarami/TEEDAM_supervised/mfn0tkkj\" # https://wandb.ai/hokarami/TEEDAM_unsupervised/runs/347dttsz/overview?workspace=user-g-hojatkarami\n",
    "# # TEDA no freeze\n",
    "# # run_path = \"hokarami/TEEDAM_supervised/5ft25axi\" # https://wandb.ai/hokarami/TEEDAM_unsupervised/runs/347dttsz/overview?workspace=user-g-hojatkarami\n",
    "# # DAM baseline\n",
    "# run_path = \"hokarami/TEEDAM_supervised/jjolnx6e\" # https://wandb.ai/hokarami/TEEDAM_unsupervised/runs/347dttsz/overview?workspace=user-g-hojatkarami\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/72 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT TEDAM --> none-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p12-raindrop/split4/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='', tl_tag='TL70', freeze='', ES_pat=100, setting='raindrop', test_center='', split='4', log='log.txt', user_prefix='[RD74-TL-TEDA__nextmark-concat]', pos_alpha=1.0, epoch=50, batch_size=128, lr=0.001, smooth=0.0, weight_decay=0.1, diag_offset=0, event_enc=1, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=1, noise=False, mod='none', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=0, w_time=1.0, sample_label=True, w_pos_label=1.0, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p12/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'tl_tag': 'TL70', 'freeze': '', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '4', 'log': 'log.txt', 'user_prefix': '[RD74-TL-TEDA__nextmark-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 128, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 0.1, 'diag_offset': 0, 'event_enc': 1, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'none', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 0, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 1.0, 'w_sample_label': 100.0}, date='09-06-23--14-05-34', run_id='2651795', dataset='P12', str_config='-raindrop/split4', run_name='[RD74-TL-TEDA__nextmark-concat]2651795', run_path='/mlodata1/hokarami/tedam/p12-raindrop/split4/[RD74-TL-TEDA__nextmark-concat]2651795/', device=device(type='cuda'), INPUT='TEDAM', OUTPUT='none-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.1448\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 148/148 [00:00<00:00, 244.36it/s]\n",
      "  1%|         | 1/72 [00:27<32:02, 27.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT TEDAM --> single-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p12-raindrop/split4/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='DO', tl_tag='RD74-single', freeze=['TE'], ES_pat=100, setting='raindrop', test_center='', split='4', log='log.txt', user_prefix='[RD74-TL-TEDA__pp_single_mark-concat]', pos_alpha=1.0, epoch=50, batch_size=128, lr=0.001, smooth=0.0, weight_decay=0.1, diag_offset=0, event_enc=1, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=1, noise=False, mod='single', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=0, w_time=1.0, sample_label=True, w_pos_label=1.0, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p12/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': 'DO', 'tl_tag': 'RD74-single', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '4', 'log': 'log.txt', 'user_prefix': '[RD74-TL-TEDA__pp_single_mark-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 128, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 0.1, 'diag_offset': 0, 'event_enc': 1, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'single', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 0, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 1.0, 'w_sample_label': 100.0}, date='09-06-23--13-53-55', run_id='2655438', dataset='P12', str_config='-raindrop/split4', run_name='[RD74-TL-TEDA__pp_single_mark-concat]2655438', run_path='/mlodata1/hokarami/tedam/p12-raindrop/split4/[RD74-TL-TEDA__pp_single_mark-concat]2655438/', device=device(type='cuda'), INPUT='TEDAM', OUTPUT='single-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.1448\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 148/148 [00:00<00:00, 245.48it/s]\n",
      "  3%|         | 2/72 [00:49<28:22, 24.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT TEDAM --> ml-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p12-raindrop/split4/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='', tl_tag='TL70', freeze='', ES_pat=100, setting='raindrop', test_center='', split='4', log='log.txt', user_prefix='[RD74-TL-TEDA__pp_ml-concat]', pos_alpha=1.0, epoch=50, batch_size=128, lr=0.001, smooth=0.0, weight_decay=0.1, diag_offset=0, event_enc=1, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=1, noise=False, mod='ml', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=1, w_time=1.0, sample_label=True, w_pos_label=1.0, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p12/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'tl_tag': 'TL70', 'freeze': '', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '4', 'log': 'log.txt', 'user_prefix': '[RD74-TL-TEDA__pp_ml-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 128, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 0.1, 'diag_offset': 0, 'event_enc': 1, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'ml', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 1, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 1.0, 'w_sample_label': 100.0}, date='09-06-23--13-53-23', run_id='2654217', dataset='P12', str_config='-raindrop/split4', run_name='[RD74-TL-TEDA__pp_ml-concat]2654217', run_path='/mlodata1/hokarami/tedam/p12-raindrop/split4/[RD74-TL-TEDA__pp_ml-concat]2654217/', device=device(type='cuda'), INPUT='TEDAM', OUTPUT='ml-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.1448\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 148/148 [00:00<00:00, 192.26it/s]\n",
      "  4%|         | 3/72 [01:15<28:57, 25.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT TEDAM --> none-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p12-raindrop/split3/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='', tl_tag='TL70', freeze='', ES_pat=100, setting='raindrop', test_center='', split='3', log='log.txt', user_prefix='[RD74-TL-TEDA__nextmark-concat]', pos_alpha=1.0, epoch=50, batch_size=128, lr=0.001, smooth=0.0, weight_decay=0.1, diag_offset=0, event_enc=1, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=1, noise=False, mod='none', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=0, w_time=1.0, sample_label=True, w_pos_label=1.0, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p12/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'tl_tag': 'TL70', 'freeze': '', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '3', 'log': 'log.txt', 'user_prefix': '[RD74-TL-TEDA__nextmark-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 128, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 0.1, 'diag_offset': 0, 'event_enc': 1, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'none', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 0, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 1.0, 'w_sample_label': 100.0}, date='09-06-23--13-43-52', run_id='2657693', dataset='P12', str_config='-raindrop/split3', run_name='[RD74-TL-TEDA__nextmark-concat]2657693', run_path='/mlodata1/hokarami/tedam/p12-raindrop/split3/[RD74-TL-TEDA__nextmark-concat]2657693/', device=device(type='cuda'), INPUT='TEDAM', OUTPUT='none-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.1420\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 159/159 [00:00<00:00, 219.36it/s]\n",
      "  6%|         | 4/72 [01:37<26:59, 23.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT TEDAM --> single-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p12-raindrop/split3/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='DO', tl_tag='RD74-single', freeze=['TE'], ES_pat=100, setting='raindrop', test_center='', split='3', log='log.txt', user_prefix='[RD74-TL-TEDA__pp_single_mark-concat]', pos_alpha=1.0, epoch=50, batch_size=128, lr=0.001, smooth=0.0, weight_decay=0.1, diag_offset=0, event_enc=1, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=1, noise=False, mod='single', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=0, w_time=1.0, sample_label=True, w_pos_label=1.0, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p12/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': 'DO', 'tl_tag': 'RD74-single', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '3', 'log': 'log.txt', 'user_prefix': '[RD74-TL-TEDA__pp_single_mark-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 128, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 0.1, 'diag_offset': 0, 'event_enc': 1, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'single', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 0, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 1.0, 'w_sample_label': 100.0}, date='09-06-23--13-40-50', run_id='2658734', dataset='P12', str_config='-raindrop/split3', run_name='[RD74-TL-TEDA__pp_single_mark-concat]2658734', run_path='/mlodata1/hokarami/tedam/p12-raindrop/split3/[RD74-TL-TEDA__pp_single_mark-concat]2658734/', device=device(type='cuda'), INPUT='TEDAM', OUTPUT='single-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.1420\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 159/159 [00:00<00:00, 231.99it/s]\n",
      "  7%|         | 5/72 [02:00<26:28, 23.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT TEDAM --> ml-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p12-raindrop/split3/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='', tl_tag='TL70', freeze='', ES_pat=100, setting='raindrop', test_center='', split='3', log='log.txt', user_prefix='[RD74-TL-TEDA__pp_ml-concat]', pos_alpha=1.0, epoch=50, batch_size=128, lr=0.001, smooth=0.0, weight_decay=0.1, diag_offset=0, event_enc=1, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=1, noise=False, mod='ml', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=1, w_time=1.0, sample_label=True, w_pos_label=1.0, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p12/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'tl_tag': 'TL70', 'freeze': '', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '3', 'log': 'log.txt', 'user_prefix': '[RD74-TL-TEDA__pp_ml-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 128, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 0.1, 'diag_offset': 0, 'event_enc': 1, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'ml', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 1, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 1.0, 'w_sample_label': 100.0}, date='09-06-23--13-32-59', run_id='2651102', dataset='P12', str_config='-raindrop/split3', run_name='[RD74-TL-TEDA__pp_ml-concat]2651102', run_path='/mlodata1/hokarami/tedam/p12-raindrop/split3/[RD74-TL-TEDA__pp_ml-concat]2651102/', device=device(type='cuda'), INPUT='TEDAM', OUTPUT='ml-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.1420\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 159/159 [00:00<00:00, 237.44it/s]\n",
      "  8%|         | 6/72 [02:21<25:04, 22.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT TEDAM --> none-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p12-raindrop/split2/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='', tl_tag='TL70', freeze='', ES_pat=100, setting='raindrop', test_center='', split='2', log='log.txt', user_prefix='[RD74-TL-TEDA__nextmark-concat]', pos_alpha=1.0, epoch=50, batch_size=128, lr=0.001, smooth=0.0, weight_decay=0.1, diag_offset=0, event_enc=1, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=1, noise=False, mod='none', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=0, w_time=1.0, sample_label=True, w_pos_label=1.0, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p12/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'tl_tag': 'TL70', 'freeze': '', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '2', 'log': 'log.txt', 'user_prefix': '[RD74-TL-TEDA__nextmark-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 128, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 0.1, 'diag_offset': 0, 'event_enc': 1, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'none', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 0, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 1.0, 'w_sample_label': 100.0}, date='09-06-23--13-31-16', run_id='2656941', dataset='P12', str_config='-raindrop/split2', run_name='[RD74-TL-TEDA__nextmark-concat]2656941', run_path='/mlodata1/hokarami/tedam/p12-raindrop/split2/[RD74-TL-TEDA__nextmark-concat]2656941/', device=device(type='cuda'), INPUT='TEDAM', OUTPUT='none-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.1411\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 168/168 [00:00<00:00, 235.15it/s]\n",
      " 10%|         | 7/72 [02:43<24:06, 22.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT TEDAM --> single-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p12-raindrop/split2/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='DO', tl_tag='RD74-single', freeze=['TE'], ES_pat=100, setting='raindrop', test_center='', split='2', log='log.txt', user_prefix='[RD74-TL-TEDA__pp_single_mark-concat]', pos_alpha=1.0, epoch=50, batch_size=128, lr=0.001, smooth=0.0, weight_decay=0.1, diag_offset=0, event_enc=1, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=1, noise=False, mod='single', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=0, w_time=1.0, sample_label=True, w_pos_label=1.0, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p12/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': 'DO', 'tl_tag': 'RD74-single', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '2', 'log': 'log.txt', 'user_prefix': '[RD74-TL-TEDA__pp_single_mark-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 128, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 0.1, 'diag_offset': 0, 'event_enc': 1, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'single', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 0, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 1.0, 'w_sample_label': 100.0}, date='09-06-23--13-19-46', run_id='2659553', dataset='P12', str_config='-raindrop/split2', run_name='[RD74-TL-TEDA__pp_single_mark-concat]2659553', run_path='/mlodata1/hokarami/tedam/p12-raindrop/split2/[RD74-TL-TEDA__pp_single_mark-concat]2659553/', device=device(type='cuda'), INPUT='TEDAM', OUTPUT='single-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.1411\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 168/168 [00:00<00:00, 208.20it/s]\n",
      " 11%|         | 8/72 [03:06<24:10, 22.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT TEDAM --> ml-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p12-raindrop/split2/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='', tl_tag='TL70', freeze='', ES_pat=100, setting='raindrop', test_center='', split='2', log='log.txt', user_prefix='[RD74-TL-TEDA__pp_ml-concat]', pos_alpha=1.0, epoch=50, batch_size=128, lr=0.001, smooth=0.0, weight_decay=0.1, diag_offset=0, event_enc=1, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=1, noise=False, mod='ml', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=1, w_time=1.0, sample_label=True, w_pos_label=1.0, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p12/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'tl_tag': 'TL70', 'freeze': '', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '2', 'log': 'log.txt', 'user_prefix': '[RD74-TL-TEDA__pp_ml-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 128, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 0.1, 'diag_offset': 0, 'event_enc': 1, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'ml', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 1, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 1.0, 'w_sample_label': 100.0}, date='09-06-23--13-19-27', run_id='2651574', dataset='P12', str_config='-raindrop/split2', run_name='[RD74-TL-TEDA__pp_ml-concat]2651574', run_path='/mlodata1/hokarami/tedam/p12-raindrop/split2/[RD74-TL-TEDA__pp_ml-concat]2651574/', device=device(type='cuda'), INPUT='TEDAM', OUTPUT='ml-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.1411\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 168/168 [00:00<00:00, 230.72it/s]\n",
      " 12%|        | 9/72 [03:28<23:33, 22.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT TEDAM --> none-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p12-raindrop/split1/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='', tl_tag='TL70', freeze='', ES_pat=100, setting='raindrop', test_center='', split='1', log='log.txt', user_prefix='[RD74-TL-TEDA__nextmark-concat]', pos_alpha=1.0, epoch=50, batch_size=128, lr=0.001, smooth=0.0, weight_decay=0.1, diag_offset=0, event_enc=1, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=1, noise=False, mod='none', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=0, w_time=1.0, sample_label=True, w_pos_label=1.0, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p12/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'tl_tag': 'TL70', 'freeze': '', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '1', 'log': 'log.txt', 'user_prefix': '[RD74-TL-TEDA__nextmark-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 128, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 0.1, 'diag_offset': 0, 'event_enc': 1, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'none', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 0, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 1.0, 'w_sample_label': 100.0}, date='09-06-23--13-09-06', run_id='2658448', dataset='P12', str_config='-raindrop/split1', run_name='[RD74-TL-TEDA__nextmark-concat]2658448', run_path='/mlodata1/hokarami/tedam/p12-raindrop/split1/[RD74-TL-TEDA__nextmark-concat]2658448/', device=device(type='cuda'), INPUT='TEDAM', OUTPUT='none-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.1421\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 178/178 [00:00<00:00, 237.94it/s]\n",
      " 14%|        | 10/72 [03:49<22:43, 21.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT TEDAM --> single-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p12-raindrop/split1/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='DO', tl_tag='RD74-single', freeze=['TE'], ES_pat=100, setting='raindrop', test_center='', split='1', log='log.txt', user_prefix='[RD74-TL-TEDA__pp_single_mark-concat]', pos_alpha=1.0, epoch=50, batch_size=128, lr=0.001, smooth=0.0, weight_decay=0.1, diag_offset=0, event_enc=1, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=1, noise=False, mod='single', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=0, w_time=1.0, sample_label=True, w_pos_label=1.0, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p12/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': 'DO', 'tl_tag': 'RD74-single', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '1', 'log': 'log.txt', 'user_prefix': '[RD74-TL-TEDA__pp_single_mark-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 128, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 0.1, 'diag_offset': 0, 'event_enc': 1, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'single', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 0, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 1.0, 'w_sample_label': 100.0}, date='09-06-23--13-06-18', run_id='2659243', dataset='P12', str_config='-raindrop/split1', run_name='[RD74-TL-TEDA__pp_single_mark-concat]2659243', run_path='/mlodata1/hokarami/tedam/p12-raindrop/split1/[RD74-TL-TEDA__pp_single_mark-concat]2659243/', device=device(type='cuda'), INPUT='TEDAM', OUTPUT='single-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.1421\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 178/178 [00:00<00:00, 239.01it/s]\n",
      " 15%|        | 11/72 [04:12<22:37, 22.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT TEDAM --> ml-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p12-raindrop/split1/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='', tl_tag='TL70', freeze='', ES_pat=100, setting='raindrop', test_center='', split='1', log='log.txt', user_prefix='[RD74-TL-TEDA__pp_ml-concat]', pos_alpha=1.0, epoch=50, batch_size=128, lr=0.001, smooth=0.0, weight_decay=0.1, diag_offset=0, event_enc=1, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=1, noise=False, mod='ml', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=1, w_time=1.0, sample_label=True, w_pos_label=1.0, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p12/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'tl_tag': 'TL70', 'freeze': '', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '1', 'log': 'log.txt', 'user_prefix': '[RD74-TL-TEDA__pp_ml-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 128, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 0.1, 'diag_offset': 0, 'event_enc': 1, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'ml', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 1, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 1.0, 'w_sample_label': 100.0}, date='09-06-23--12-56-38', run_id='2657818', dataset='P12', str_config='-raindrop/split1', run_name='[RD74-TL-TEDA__pp_ml-concat]2657818', run_path='/mlodata1/hokarami/tedam/p12-raindrop/split1/[RD74-TL-TEDA__pp_ml-concat]2657818/', device=device(type='cuda'), INPUT='TEDAM', OUTPUT='ml-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.1421\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 178/178 [00:01<00:00, 155.17it/s]\n",
      " 17%|        | 12/72 [04:36<22:57, 22.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT TEDAM --> none-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p12-raindrop/split0/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='', tl_tag='TL70', freeze='', ES_pat=100, setting='raindrop', test_center='', split='0', log='log.txt', user_prefix='[RD74-TL-TEDA__nextmark-concat]', pos_alpha=1.0, epoch=50, batch_size=128, lr=0.001, smooth=0.0, weight_decay=0.1, diag_offset=0, event_enc=1, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=1, noise=False, mod='none', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=0, w_time=1.0, sample_label=True, w_pos_label=1.0, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p12/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'tl_tag': 'TL70', 'freeze': '', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '0', 'log': 'log.txt', 'user_prefix': '[RD74-TL-TEDA__nextmark-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 128, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 0.1, 'diag_offset': 0, 'event_enc': 1, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'none', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 0, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 1.0, 'w_sample_label': 100.0}, date='09-06-23--12-55-24', run_id='2658581', dataset='P12', str_config='-raindrop/split0', run_name='[RD74-TL-TEDA__nextmark-concat]2658581', run_path='/mlodata1/hokarami/tedam/p12-raindrop/split0/[RD74-TL-TEDA__nextmark-concat]2658581/', device=device(type='cuda'), INPUT='TEDAM', OUTPUT='none-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.1401\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 188/188 [00:00<00:00, 227.29it/s]\n",
      " 18%|        | 13/72 [05:01<23:02, 23.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT TEDAM --> ml-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p12-raindrop/split0/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='', tl_tag='TL70', freeze='', ES_pat=100, setting='raindrop', test_center='', split='0', log='log.txt', user_prefix='[RD74-TL-TEDA__pp_ml-concat]', pos_alpha=1.0, epoch=50, batch_size=128, lr=0.001, smooth=0.0, weight_decay=0.1, diag_offset=0, event_enc=1, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=1, noise=False, mod='ml', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=1, w_time=1.0, sample_label=True, w_pos_label=1.0, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p12/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'tl_tag': 'TL70', 'freeze': '', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '0', 'log': 'log.txt', 'user_prefix': '[RD74-TL-TEDA__pp_ml-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 128, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 0.1, 'diag_offset': 0, 'event_enc': 1, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'ml', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 1, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 1.0, 'w_sample_label': 100.0}, date='09-06-23--12-42-21', run_id='2651118', dataset='P12', str_config='-raindrop/split0', run_name='[RD74-TL-TEDA__pp_ml-concat]2651118', run_path='/mlodata1/hokarami/tedam/p12-raindrop/split0/[RD74-TL-TEDA__pp_ml-concat]2651118/', device=device(type='cuda'), INPUT='TEDAM', OUTPUT='ml-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.1401\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 188/188 [00:01<00:00, 166.38it/s]\n",
      " 19%|        | 14/72 [05:38<26:28, 27.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT TEDAM --> single-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p12-raindrop/split0/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='DO', tl_tag='RD74-single', freeze=['TE'], ES_pat=100, setting='raindrop', test_center='', split='0', log='log.txt', user_prefix='[RD74-TL-TEDA__pp_single_mark-concat]', pos_alpha=1.0, epoch=50, batch_size=128, lr=0.001, smooth=0.0, weight_decay=0.1, diag_offset=0, event_enc=1, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=1, noise=False, mod='single', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=0, w_time=1.0, sample_label=True, w_pos_label=1.0, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p12/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': 'DO', 'tl_tag': 'RD74-single', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '0', 'log': 'log.txt', 'user_prefix': '[RD74-TL-TEDA__pp_single_mark-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 128, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 0.1, 'diag_offset': 0, 'event_enc': 1, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'single', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 0, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 1.0, 'w_sample_label': 100.0}, date='09-06-23--12-42-21', run_id='2651884', dataset='P12', str_config='-raindrop/split0', run_name='[RD74-TL-TEDA__pp_single_mark-concat]2651884', run_path='/mlodata1/hokarami/tedam/p12-raindrop/split0/[RD74-TL-TEDA__pp_single_mark-concat]2651884/', device=device(type='cuda'), INPUT='TEDAM', OUTPUT='single-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.1401\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 188/188 [00:00<00:00, 192.96it/s]\n",
      " 21%|        | 15/72 [06:06<26:22, 27.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT TEDAM --> none-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p12-raindrop/split4/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='', tl_tag='TL70', freeze='', ES_pat=100, setting='raindrop', test_center='', split='4', log='log.txt', user_prefix='[RD74-TL-TEDA__nextmark-concat]', pos_alpha=1.0, epoch=50, batch_size=128, lr=0.001, smooth=0.0, weight_decay=0.1, diag_offset=0, event_enc=1, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=1, noise=False, mod='none', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=0, w_time=1.0, sample_label=True, w_pos_label=1.0, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p12/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'tl_tag': 'TL70', 'freeze': '', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '4', 'log': 'log.txt', 'user_prefix': '[RD74-TL-TEDA__nextmark-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 128, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 0.1, 'diag_offset': 0, 'event_enc': 1, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'none', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 0, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 1.0, 'w_sample_label': 100.0}, date='09-06-23--12-23-54', run_id='2657875', dataset='P12', str_config='-raindrop/split4', run_name='[RD74-TL-TEDA__nextmark-concat]2657875', run_path='/mlodata1/hokarami/tedam/p12-raindrop/split4/[RD74-TL-TEDA__nextmark-concat]2657875/', device=device(type='cuda'), INPUT='TEDAM', OUTPUT='none-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.1448\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 148/148 [00:00<00:00, 227.02it/s]\n",
      " 22%|       | 16/72 [06:28<24:18, 26.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT TEDAM --> ml-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p12-raindrop/split1/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='', tl_tag='TL70', freeze='', ES_pat=100, setting='raindrop', test_center='', split='1', log='log.txt', user_prefix='[RD74-TL-TEDA__pp_ml-concat]', pos_alpha=1.0, epoch=50, batch_size=128, lr=0.001, smooth=0.0, weight_decay=0.1, diag_offset=0, event_enc=1, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=1, noise=False, mod='ml', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=1, w_time=1.0, sample_label=True, w_pos_label=1.0, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p12/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'tl_tag': 'TL70', 'freeze': '', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '1', 'log': 'log.txt', 'user_prefix': '[RD74-TL-TEDA__pp_ml-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 128, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 0.1, 'diag_offset': 0, 'event_enc': 1, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'ml', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 1, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 1.0, 'w_sample_label': 100.0}, date='09-06-23--12-09-24', run_id='2656738', dataset='P12', str_config='-raindrop/split1', run_name='[RD74-TL-TEDA__pp_ml-concat]2656738', run_path='/mlodata1/hokarami/tedam/p12-raindrop/split1/[RD74-TL-TEDA__pp_ml-concat]2656738/', device=device(type='cuda'), INPUT='TEDAM', OUTPUT='ml-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.1421\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 178/178 [00:00<00:00, 232.11it/s]\n",
      " 24%|       | 17/72 [06:53<23:27, 25.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT TEDAM --> none-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p12-raindrop/split4/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='', tl_tag='TL70', freeze='', ES_pat=100, setting='raindrop', test_center='', split='4', log='log.txt', user_prefix='[RD74-TEDA__nextmark-concat]', pos_alpha=1.0, epoch=50, batch_size=128, lr=0.001, smooth=0.0, weight_decay=0.1, diag_offset=0, event_enc=1, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=1, noise=False, mod='none', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=0, w_time=1.0, sample_label=True, w_pos_label=1.0, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p12/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'tl_tag': 'TL70', 'freeze': '', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '4', 'log': 'log.txt', 'user_prefix': '[RD74-TEDA__nextmark-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 128, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 0.1, 'diag_offset': 0, 'event_enc': 1, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'none', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 0, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 1.0, 'w_sample_label': 100.0}, date='09-06-23--00-25-10', run_id='2652237', dataset='P12', str_config='-raindrop/split4', run_name='[RD74-TEDA__nextmark-concat]2652237', run_path='/mlodata1/hokarami/tedam/p12-raindrop/split4/[RD74-TEDA__nextmark-concat]2652237/', device=device(type='cuda'), INPUT='TEDAM', OUTPUT='none-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.1448\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 148/148 [00:00<00:00, 226.22it/s]\n",
      " 25%|       | 18/72 [07:13<21:40, 24.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT TEDAM --> single-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p12-raindrop/split4/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='', tl_tag='TL70', freeze='', ES_pat=100, setting='raindrop', test_center='', split='4', log='log.txt', user_prefix='[RD74-TEDA__pp_single_mark-concat]', pos_alpha=1.0, epoch=50, batch_size=128, lr=0.001, smooth=0.0, weight_decay=0.1, diag_offset=0, event_enc=1, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=1, noise=False, mod='single', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=0, w_time=1.0, sample_label=True, w_pos_label=1.0, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p12/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'tl_tag': 'TL70', 'freeze': '', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '4', 'log': 'log.txt', 'user_prefix': '[RD74-TEDA__pp_single_mark-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 128, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 0.1, 'diag_offset': 0, 'event_enc': 1, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'single', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 0, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 1.0, 'w_sample_label': 100.0}, date='08-06-23--22-46-41', run_id='2642838', dataset='P12', str_config='-raindrop/split4', run_name='[RD74-TEDA__pp_single_mark-concat]2642838', run_path='/mlodata1/hokarami/tedam/p12-raindrop/split4/[RD74-TEDA__pp_single_mark-concat]2642838/', device=device(type='cuda'), INPUT='TEDAM', OUTPUT='single-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.1448\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 148/148 [00:00<00:00, 223.72it/s]\n",
      " 26%|       | 19/72 [07:40<21:50, 24.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT TEDAM --> ml-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p12-raindrop/split4/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='', tl_tag='TL70', freeze='', ES_pat=100, setting='raindrop', test_center='', split='4', log='log.txt', user_prefix='[RD74-TEDA__pp_ml-concat]', pos_alpha=1.0, epoch=50, batch_size=128, lr=0.001, smooth=0.0, weight_decay=0.1, diag_offset=0, event_enc=1, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=1, noise=False, mod='ml', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=1, w_time=1.0, sample_label=True, w_pos_label=1.0, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p12/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'tl_tag': 'TL70', 'freeze': '', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '4', 'log': 'log.txt', 'user_prefix': '[RD74-TEDA__pp_ml-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 128, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 0.1, 'diag_offset': 0, 'event_enc': 1, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'ml', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 1, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 1.0, 'w_sample_label': 100.0}, date='08-06-23--22-44-17', run_id='2648578', dataset='P12', str_config='-raindrop/split4', run_name='[RD74-TEDA__pp_ml-concat]2648578', run_path='/mlodata1/hokarami/tedam/p12-raindrop/split4/[RD74-TEDA__pp_ml-concat]2648578/', device=device(type='cuda'), INPUT='TEDAM', OUTPUT='ml-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.1448\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 148/148 [00:00<00:00, 223.57it/s]\n",
      " 28%|       | 20/72 [08:01<20:40, 23.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT TEDAM --> none-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p12-raindrop/split4/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='', tl_tag='TL70', freeze='', ES_pat=100, setting='raindrop', test_center='', split='4', log='log.txt', user_prefix='[RD74-TEDA__none-concat]', pos_alpha=1.0, epoch=50, batch_size=128, lr=0.001, smooth=0.0, weight_decay=0.1, diag_offset=0, event_enc=1, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=1, noise=False, mod='none', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=1, w_time=1.0, sample_label=True, w_pos_label=1.0, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p12/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'tl_tag': 'TL70', 'freeze': '', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '4', 'log': 'log.txt', 'user_prefix': '[RD74-TEDA__none-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 128, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 0.1, 'diag_offset': 0, 'event_enc': 1, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'none', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 1, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 1.0, 'w_sample_label': 100.0}, date='08-06-23--22-41-54', run_id='2648879', dataset='P12', str_config='-raindrop/split4', run_name='[RD74-TEDA__none-concat]2648879', run_path='/mlodata1/hokarami/tedam/p12-raindrop/split4/[RD74-TEDA__none-concat]2648879/', device=device(type='cuda'), INPUT='TEDAM', OUTPUT='none-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.1448\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 148/148 [00:00<00:00, 212.44it/s]\n",
      " 29%|       | 21/72 [08:22<19:30, 22.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT DAM --> none-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p12-raindrop/split4/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='', tl_tag='TL70', freeze='', ES_pat=100, setting='raindrop', test_center='', split='4', log='log.txt', user_prefix='[RD74-DA__base-concat]', pos_alpha=1.0, epoch=50, batch_size=128, lr=0.001, smooth=0.0, weight_decay=0.1, diag_offset=0, event_enc=0, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=1, noise=False, mod='none', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=1, w_time=1.0, sample_label=True, w_pos_label=1.0, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p12/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'tl_tag': 'TL70', 'freeze': '', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '4', 'log': 'log.txt', 'user_prefix': '[RD74-DA__base-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 128, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 0.1, 'diag_offset': 0, 'event_enc': 0, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'none', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 1, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 1.0, 'w_sample_label': 100.0}, date='08-06-23--22-19-28', run_id='2647742', dataset='P12', str_config='-raindrop/split4', run_name='[RD74-DA__base-concat]2647742', run_path='/mlodata1/hokarami/tedam/p12-raindrop/split4/[RD74-DA__base-concat]2647742/', device=device(type='cuda'), INPUT='DAM', OUTPUT='none-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.1448\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 148/148 [00:00<00:00, 225.63it/s]\n",
      " 31%|       | 22/72 [08:44<18:55, 22.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT TEDAM --> none-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p12-raindrop/split3/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='', tl_tag='TL70', freeze='', ES_pat=100, setting='raindrop', test_center='', split='3', log='log.txt', user_prefix='[RD74-TEDA__nextmark-concat]', pos_alpha=1.0, epoch=50, batch_size=128, lr=0.001, smooth=0.0, weight_decay=0.1, diag_offset=0, event_enc=1, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=1, noise=False, mod='none', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=0, w_time=1.0, sample_label=True, w_pos_label=1.0, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p12/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'tl_tag': 'TL70', 'freeze': '', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '3', 'log': 'log.txt', 'user_prefix': '[RD74-TEDA__nextmark-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 128, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 0.1, 'diag_offset': 0, 'event_enc': 1, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'none', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 0, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 1.0, 'w_sample_label': 100.0}, date='08-06-23--21-18-01', run_id='2641256', dataset='P12', str_config='-raindrop/split3', run_name='[RD74-TEDA__nextmark-concat]2641256', run_path='/mlodata1/hokarami/tedam/p12-raindrop/split3/[RD74-TEDA__nextmark-concat]2641256/', device=device(type='cuda'), INPUT='TEDAM', OUTPUT='none-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.1420\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 159/159 [00:00<00:00, 227.64it/s]\n",
      " 32%|      | 23/72 [09:08<18:45, 22.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT TEDAM --> single-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p12-raindrop/split3/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='', tl_tag='TL70', freeze='', ES_pat=100, setting='raindrop', test_center='', split='3', log='log.txt', user_prefix='[RD74-TEDA__pp_single_mark-concat]', pos_alpha=1.0, epoch=50, batch_size=128, lr=0.001, smooth=0.0, weight_decay=0.1, diag_offset=0, event_enc=1, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=1, noise=False, mod='single', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=0, w_time=1.0, sample_label=True, w_pos_label=1.0, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p12/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'tl_tag': 'TL70', 'freeze': '', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '3', 'log': 'log.txt', 'user_prefix': '[RD74-TEDA__pp_single_mark-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 128, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 0.1, 'diag_offset': 0, 'event_enc': 1, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'single', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 0, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 1.0, 'w_sample_label': 100.0}, date='08-06-23--21-12-03', run_id='2644670', dataset='P12', str_config='-raindrop/split3', run_name='[RD74-TEDA__pp_single_mark-concat]2644670', run_path='/mlodata1/hokarami/tedam/p12-raindrop/split3/[RD74-TEDA__pp_single_mark-concat]2644670/', device=device(type='cuda'), INPUT='TEDAM', OUTPUT='single-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.1420\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 159/159 [00:00<00:00, 218.72it/s]\n",
      " 33%|      | 24/72 [09:30<18:04, 22.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT TEDAM --> ml-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p12-raindrop/split3/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='', tl_tag='TL70', freeze='', ES_pat=100, setting='raindrop', test_center='', split='3', log='log.txt', user_prefix='[RD74-TEDA__pp_ml-concat]', pos_alpha=1.0, epoch=50, batch_size=128, lr=0.001, smooth=0.0, weight_decay=0.1, diag_offset=0, event_enc=1, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=1, noise=False, mod='ml', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=1, w_time=1.0, sample_label=True, w_pos_label=1.0, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p12/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'tl_tag': 'TL70', 'freeze': '', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '3', 'log': 'log.txt', 'user_prefix': '[RD74-TEDA__pp_ml-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 128, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 0.1, 'diag_offset': 0, 'event_enc': 1, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'ml', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 1, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 1.0, 'w_sample_label': 100.0}, date='08-06-23--21-11-15', run_id='2645914', dataset='P12', str_config='-raindrop/split3', run_name='[RD74-TEDA__pp_ml-concat]2645914', run_path='/mlodata1/hokarami/tedam/p12-raindrop/split3/[RD74-TEDA__pp_ml-concat]2645914/', device=device(type='cuda'), INPUT='TEDAM', OUTPUT='ml-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.1420\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 159/159 [00:00<00:00, 227.61it/s]\n",
      " 35%|      | 25/72 [09:53<17:55, 22.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT TEDAM --> none-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p12-raindrop/split3/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='', tl_tag='TL70', freeze='', ES_pat=100, setting='raindrop', test_center='', split='3', log='log.txt', user_prefix='[RD74-TEDA__none-concat]', pos_alpha=1.0, epoch=50, batch_size=128, lr=0.001, smooth=0.0, weight_decay=0.1, diag_offset=0, event_enc=1, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=1, noise=False, mod='none', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=1, w_time=1.0, sample_label=True, w_pos_label=1.0, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p12/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'tl_tag': 'TL70', 'freeze': '', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '3', 'log': 'log.txt', 'user_prefix': '[RD74-TEDA__none-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 128, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 0.1, 'diag_offset': 0, 'event_enc': 1, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'none', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 1, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 1.0, 'w_sample_label': 100.0}, date='08-06-23--21-05-50', run_id='2642178', dataset='P12', str_config='-raindrop/split3', run_name='[RD74-TEDA__none-concat]2642178', run_path='/mlodata1/hokarami/tedam/p12-raindrop/split3/[RD74-TEDA__none-concat]2642178/', device=device(type='cuda'), INPUT='TEDAM', OUTPUT='none-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.1420\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 159/159 [00:00<00:00, 230.04it/s]\n",
      " 36%|      | 26/72 [10:16<17:31, 22.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT DAM --> none-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p12-raindrop/split3/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='', tl_tag='TL70', freeze='', ES_pat=100, setting='raindrop', test_center='', split='3', log='log.txt', user_prefix='[RD74-DA__base-concat]', pos_alpha=1.0, epoch=50, batch_size=128, lr=0.001, smooth=0.0, weight_decay=0.1, diag_offset=0, event_enc=0, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=1, noise=False, mod='none', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=1, w_time=1.0, sample_label=True, w_pos_label=1.0, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p12/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'tl_tag': 'TL70', 'freeze': '', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '3', 'log': 'log.txt', 'user_prefix': '[RD74-DA__base-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 128, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 0.1, 'diag_offset': 0, 'event_enc': 0, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'none', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 1, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 1.0, 'w_sample_label': 100.0}, date='08-06-23--20-10-02', run_id='2649487', dataset='P12', str_config='-raindrop/split3', run_name='[RD74-DA__base-concat]2649487', run_path='/mlodata1/hokarami/tedam/p12-raindrop/split3/[RD74-DA__base-concat]2649487/', device=device(type='cuda'), INPUT='DAM', OUTPUT='none-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.1420\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 159/159 [00:00<00:00, 223.97it/s]\n",
      " 38%|      | 27/72 [10:38<16:51, 22.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT TEDAM --> none-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p12-raindrop/split2/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='', tl_tag='TL70', freeze='', ES_pat=100, setting='raindrop', test_center='', split='2', log='log.txt', user_prefix='[RD74-TEDA__nextmark-concat]', pos_alpha=1.0, epoch=50, batch_size=128, lr=0.001, smooth=0.0, weight_decay=0.1, diag_offset=0, event_enc=1, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=1, noise=False, mod='none', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=0, w_time=1.0, sample_label=True, w_pos_label=1.0, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p12/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'tl_tag': 'TL70', 'freeze': '', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '2', 'log': 'log.txt', 'user_prefix': '[RD74-TEDA__nextmark-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 128, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 0.1, 'diag_offset': 0, 'event_enc': 1, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'none', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 0, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 1.0, 'w_sample_label': 100.0}, date='08-06-23--19-46-05', run_id='2645245', dataset='P12', str_config='-raindrop/split2', run_name='[RD74-TEDA__nextmark-concat]2645245', run_path='/mlodata1/hokarami/tedam/p12-raindrop/split2/[RD74-TEDA__nextmark-concat]2645245/', device=device(type='cuda'), INPUT='TEDAM', OUTPUT='none-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.1411\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 168/168 [00:00<00:00, 224.32it/s]\n",
      " 39%|      | 28/72 [11:01<16:36, 22.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT TEDAM --> single-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p12-raindrop/split2/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='', tl_tag='TL70', freeze='', ES_pat=100, setting='raindrop', test_center='', split='2', log='log.txt', user_prefix='[RD74-TEDA__pp_single_mark-concat]', pos_alpha=1.0, epoch=50, batch_size=128, lr=0.001, smooth=0.0, weight_decay=0.1, diag_offset=0, event_enc=1, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=1, noise=False, mod='single', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=0, w_time=1.0, sample_label=True, w_pos_label=1.0, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p12/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'tl_tag': 'TL70', 'freeze': '', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '2', 'log': 'log.txt', 'user_prefix': '[RD74-TEDA__pp_single_mark-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 128, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 0.1, 'diag_offset': 0, 'event_enc': 1, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'single', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 0, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 1.0, 'w_sample_label': 100.0}, date='08-06-23--19-45-37', run_id='2649136', dataset='P12', str_config='-raindrop/split2', run_name='[RD74-TEDA__pp_single_mark-concat]2649136', run_path='/mlodata1/hokarami/tedam/p12-raindrop/split2/[RD74-TEDA__pp_single_mark-concat]2649136/', device=device(type='cuda'), INPUT='TEDAM', OUTPUT='single-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.1411\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 168/168 [00:00<00:00, 226.51it/s]\n",
      " 40%|      | 29/72 [11:22<15:59, 22.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT TEDAM --> ml-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p12-raindrop/split2/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='', tl_tag='TL70', freeze='', ES_pat=100, setting='raindrop', test_center='', split='2', log='log.txt', user_prefix='[RD74-TEDA__pp_ml-concat]', pos_alpha=1.0, epoch=50, batch_size=128, lr=0.001, smooth=0.0, weight_decay=0.1, diag_offset=0, event_enc=1, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=1, noise=False, mod='ml', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=1, w_time=1.0, sample_label=True, w_pos_label=1.0, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p12/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'tl_tag': 'TL70', 'freeze': '', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '2', 'log': 'log.txt', 'user_prefix': '[RD74-TEDA__pp_ml-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 128, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 0.1, 'diag_offset': 0, 'event_enc': 1, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'ml', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 1, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 1.0, 'w_sample_label': 100.0}, date='08-06-23--19-41-05', run_id='2647359', dataset='P12', str_config='-raindrop/split2', run_name='[RD74-TEDA__pp_ml-concat]2647359', run_path='/mlodata1/hokarami/tedam/p12-raindrop/split2/[RD74-TEDA__pp_ml-concat]2647359/', device=device(type='cuda'), INPUT='TEDAM', OUTPUT='ml-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.1411\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 168/168 [00:00<00:00, 223.79it/s]\n",
      " 42%|     | 30/72 [11:44<15:29, 22.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT TEDAM --> none-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p12-raindrop/split2/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='', tl_tag='TL70', freeze='', ES_pat=100, setting='raindrop', test_center='', split='2', log='log.txt', user_prefix='[RD74-TEDA__none-concat]', pos_alpha=1.0, epoch=50, batch_size=128, lr=0.001, smooth=0.0, weight_decay=0.1, diag_offset=0, event_enc=1, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=1, noise=False, mod='none', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=1, w_time=1.0, sample_label=True, w_pos_label=1.0, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p12/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'tl_tag': 'TL70', 'freeze': '', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '2', 'log': 'log.txt', 'user_prefix': '[RD74-TEDA__none-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 128, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 0.1, 'diag_offset': 0, 'event_enc': 1, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'none', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 1, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 1.0, 'w_sample_label': 100.0}, date='08-06-23--18-52-45', run_id='2644686', dataset='P12', str_config='-raindrop/split2', run_name='[RD74-TEDA__none-concat]2644686', run_path='/mlodata1/hokarami/tedam/p12-raindrop/split2/[RD74-TEDA__none-concat]2644686/', device=device(type='cuda'), INPUT='TEDAM', OUTPUT='none-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.1411\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 168/168 [00:00<00:00, 210.69it/s]\n",
      " 43%|     | 31/72 [12:06<15:05, 22.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT DAM --> none-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p12-raindrop/split2/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='', tl_tag='TL70', freeze='', ES_pat=100, setting='raindrop', test_center='', split='2', log='log.txt', user_prefix='[RD74-DA__base-concat]', pos_alpha=1.0, epoch=50, batch_size=128, lr=0.001, smooth=0.0, weight_decay=0.1, diag_offset=0, event_enc=0, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=1, noise=False, mod='none', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=1, w_time=1.0, sample_label=True, w_pos_label=1.0, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p12/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'tl_tag': 'TL70', 'freeze': '', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '2', 'log': 'log.txt', 'user_prefix': '[RD74-DA__base-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 128, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 0.1, 'diag_offset': 0, 'event_enc': 0, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'none', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 1, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 1.0, 'w_sample_label': 100.0}, date='08-06-23--18-36-36', run_id='2646879', dataset='P12', str_config='-raindrop/split2', run_name='[RD74-DA__base-concat]2646879', run_path='/mlodata1/hokarami/tedam/p12-raindrop/split2/[RD74-DA__base-concat]2646879/', device=device(type='cuda'), INPUT='DAM', OUTPUT='none-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.1411\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 168/168 [00:00<00:00, 210.81it/s]\n",
      " 44%|     | 32/72 [12:27<14:29, 21.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT TEDAM --> none-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p12-raindrop/split1/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='', tl_tag='TL70', freeze='', ES_pat=100, setting='raindrop', test_center='', split='1', log='log.txt', user_prefix='[RD74-TEDA__nextmark-concat]', pos_alpha=1.0, epoch=50, batch_size=128, lr=0.001, smooth=0.0, weight_decay=0.1, diag_offset=0, event_enc=1, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=1, noise=False, mod='none', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=0, w_time=1.0, sample_label=True, w_pos_label=1.0, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p12/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'tl_tag': 'TL70', 'freeze': '', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '1', 'log': 'log.txt', 'user_prefix': '[RD74-TEDA__nextmark-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 128, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 0.1, 'diag_offset': 0, 'event_enc': 1, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'none', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 0, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 1.0, 'w_sample_label': 100.0}, date='08-06-23--18-24-33', run_id='2642572', dataset='P12', str_config='-raindrop/split1', run_name='[RD74-TEDA__nextmark-concat]2642572', run_path='/mlodata1/hokarami/tedam/p12-raindrop/split1/[RD74-TEDA__nextmark-concat]2642572/', device=device(type='cuda'), INPUT='TEDAM', OUTPUT='none-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.1421\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 178/178 [00:00<00:00, 228.98it/s]\n",
      " 46%|     | 33/72 [12:50<14:25, 22.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT TEDAM --> single-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p12-raindrop/split1/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='', tl_tag='TL70', freeze='', ES_pat=100, setting='raindrop', test_center='', split='1', log='log.txt', user_prefix='[RD74-TEDA__pp_single_mark-concat]', pos_alpha=1.0, epoch=50, batch_size=128, lr=0.001, smooth=0.0, weight_decay=0.1, diag_offset=0, event_enc=1, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=1, noise=False, mod='single', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=0, w_time=1.0, sample_label=True, w_pos_label=1.0, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p12/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'tl_tag': 'TL70', 'freeze': '', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '1', 'log': 'log.txt', 'user_prefix': '[RD74-TEDA__pp_single_mark-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 128, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 0.1, 'diag_offset': 0, 'event_enc': 1, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'single', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 0, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 1.0, 'w_sample_label': 100.0}, date='08-06-23--18-13-20', run_id='2649056', dataset='P12', str_config='-raindrop/split1', run_name='[RD74-TEDA__pp_single_mark-concat]2649056', run_path='/mlodata1/hokarami/tedam/p12-raindrop/split1/[RD74-TEDA__pp_single_mark-concat]2649056/', device=device(type='cuda'), INPUT='TEDAM', OUTPUT='single-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.1421\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 178/178 [00:00<00:00, 230.59it/s]\n",
      " 47%|     | 34/72 [13:12<13:56, 22.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT TEDAM --> ml-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p12-raindrop/split1/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='', tl_tag='TL70', freeze='', ES_pat=100, setting='raindrop', test_center='', split='1', log='log.txt', user_prefix='[RD74-TEDA__pp_ml-concat]', pos_alpha=1.0, epoch=50, batch_size=128, lr=0.001, smooth=0.0, weight_decay=0.1, diag_offset=0, event_enc=1, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=1, noise=False, mod='ml', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=1, w_time=1.0, sample_label=True, w_pos_label=1.0, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p12/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'tl_tag': 'TL70', 'freeze': '', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '1', 'log': 'log.txt', 'user_prefix': '[RD74-TEDA__pp_ml-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 128, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 0.1, 'diag_offset': 0, 'event_enc': 1, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'ml', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 1, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 1.0, 'w_sample_label': 100.0}, date='08-06-23--17-21-13', run_id='2641987', dataset='P12', str_config='-raindrop/split1', run_name='[RD74-TEDA__pp_ml-concat]2641987', run_path='/mlodata1/hokarami/tedam/p12-raindrop/split1/[RD74-TEDA__pp_ml-concat]2641987/', device=device(type='cuda'), INPUT='TEDAM', OUTPUT='ml-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.1421\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 178/178 [00:00<00:00, 221.47it/s]\n",
      " 49%|     | 35/72 [13:34<13:32, 21.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT TEDAM --> none-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p12-raindrop/split1/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='', tl_tag='TL70', freeze='', ES_pat=100, setting='raindrop', test_center='', split='1', log='log.txt', user_prefix='[RD74-TEDA__none-concat]', pos_alpha=1.0, epoch=50, batch_size=128, lr=0.001, smooth=0.0, weight_decay=0.1, diag_offset=0, event_enc=1, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=1, noise=False, mod='none', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=1, w_time=1.0, sample_label=True, w_pos_label=1.0, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p12/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'tl_tag': 'TL70', 'freeze': '', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '1', 'log': 'log.txt', 'user_prefix': '[RD74-TEDA__none-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 128, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 0.1, 'diag_offset': 0, 'event_enc': 1, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'none', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 1, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 1.0, 'w_sample_label': 100.0}, date='08-06-23--17-18-16', run_id='2649936', dataset='P12', str_config='-raindrop/split1', run_name='[RD74-TEDA__none-concat]2649936', run_path='/mlodata1/hokarami/tedam/p12-raindrop/split1/[RD74-TEDA__none-concat]2649936/', device=device(type='cuda'), INPUT='TEDAM', OUTPUT='none-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.1421\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 178/178 [00:00<00:00, 220.12it/s]\n",
      " 50%|     | 36/72 [13:56<13:13, 22.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT DAM --> none-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p12-raindrop/split1/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='', tl_tag='TL70', freeze='', ES_pat=100, setting='raindrop', test_center='', split='1', log='log.txt', user_prefix='[RD74-DA__base-concat]', pos_alpha=1.0, epoch=50, batch_size=128, lr=0.001, smooth=0.0, weight_decay=0.1, diag_offset=0, event_enc=0, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=1, noise=False, mod='none', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=1, w_time=1.0, sample_label=True, w_pos_label=1.0, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p12/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'tl_tag': 'TL70', 'freeze': '', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '1', 'log': 'log.txt', 'user_prefix': '[RD74-DA__base-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 128, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 0.1, 'diag_offset': 0, 'event_enc': 0, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'none', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 1, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 1.0, 'w_sample_label': 100.0}, date='08-06-23--17-15-01', run_id='2645831', dataset='P12', str_config='-raindrop/split1', run_name='[RD74-DA__base-concat]2645831', run_path='/mlodata1/hokarami/tedam/p12-raindrop/split1/[RD74-DA__base-concat]2645831/', device=device(type='cuda'), INPUT='DAM', OUTPUT='none-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.1421\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 178/178 [00:00<00:00, 225.09it/s]\n",
      " 51%|    | 37/72 [14:16<12:36, 21.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT TEDAM --> none-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p12-raindrop/split0/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='', tl_tag='TL70', freeze='', ES_pat=100, setting='raindrop', test_center='', split='0', log='log.txt', user_prefix='[RD74-TEDA__nextmark-concat]', pos_alpha=1.0, epoch=50, batch_size=128, lr=0.001, smooth=0.0, weight_decay=0.1, diag_offset=0, event_enc=1, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=1, noise=False, mod='none', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=0, w_time=1.0, sample_label=True, w_pos_label=1.0, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p12/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'tl_tag': 'TL70', 'freeze': '', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '0', 'log': 'log.txt', 'user_prefix': '[RD74-TEDA__nextmark-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 128, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 0.1, 'diag_offset': 0, 'event_enc': 1, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'none', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 0, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 1.0, 'w_sample_label': 100.0}, date='08-06-23--16-58-01', run_id='2645475', dataset='P12', str_config='-raindrop/split0', run_name='[RD74-TEDA__nextmark-concat]2645475', run_path='/mlodata1/hokarami/tedam/p12-raindrop/split0/[RD74-TEDA__nextmark-concat]2645475/', device=device(type='cuda'), INPUT='TEDAM', OUTPUT='none-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.1401\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 188/188 [00:00<00:00, 228.88it/s]\n",
      " 53%|    | 38/72 [14:38<12:12, 21.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT TEDAM --> single-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p12-raindrop/split0/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='', tl_tag='TL70', freeze='', ES_pat=100, setting='raindrop', test_center='', split='0', log='log.txt', user_prefix='[RD74-TEDA__pp_single_mark-concat]', pos_alpha=1.0, epoch=50, batch_size=128, lr=0.001, smooth=0.0, weight_decay=0.1, diag_offset=0, event_enc=1, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=1, noise=False, mod='single', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=0, w_time=1.0, sample_label=True, w_pos_label=1.0, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p12/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'tl_tag': 'TL70', 'freeze': '', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '0', 'log': 'log.txt', 'user_prefix': '[RD74-TEDA__pp_single_mark-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 128, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 0.1, 'diag_offset': 0, 'event_enc': 1, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'single', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 0, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 1.0, 'w_sample_label': 100.0}, date='08-06-23--16-19-23', run_id='2643241', dataset='P12', str_config='-raindrop/split0', run_name='[RD74-TEDA__pp_single_mark-concat]2643241', run_path='/mlodata1/hokarami/tedam/p12-raindrop/split0/[RD74-TEDA__pp_single_mark-concat]2643241/', device=device(type='cuda'), INPUT='TEDAM', OUTPUT='single-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.1401\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 188/188 [00:00<00:00, 220.40it/s]\n",
      " 54%|    | 39/72 [15:01<12:04, 21.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT DAM --> none-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p12-raindrop/split0/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='', tl_tag='TL70', freeze='', ES_pat=100, setting='raindrop', test_center='', split='0', log='log.txt', user_prefix='[RD74-DA__base-concat]', pos_alpha=1.0, epoch=50, batch_size=128, lr=0.001, smooth=0.0, weight_decay=0.1, diag_offset=0, event_enc=0, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=1, noise=False, mod='none', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=1, w_time=1.0, sample_label=True, w_pos_label=1.0, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p12/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'tl_tag': 'TL70', 'freeze': '', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '0', 'log': 'log.txt', 'user_prefix': '[RD74-DA__base-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 128, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 0.1, 'diag_offset': 0, 'event_enc': 0, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'none', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 1, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 1.0, 'w_sample_label': 100.0}, date='08-06-23--16-19-23', run_id='2645662', dataset='P12', str_config='-raindrop/split0', run_name='[RD74-DA__base-concat]2645662', run_path='/mlodata1/hokarami/tedam/p12-raindrop/split0/[RD74-DA__base-concat]2645662/', device=device(type='cuda'), INPUT='DAM', OUTPUT='none-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.1401\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 188/188 [00:00<00:00, 229.69it/s]\n",
      " 56%|    | 40/72 [15:21<11:23, 21.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT TEDAM --> none-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p12-raindrop/split0/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='', tl_tag='TL70', freeze='', ES_pat=100, setting='raindrop', test_center='', split='0', log='log.txt', user_prefix='[RD74-TEDA__none-concat]', pos_alpha=1.0, epoch=50, batch_size=128, lr=0.001, smooth=0.0, weight_decay=0.1, diag_offset=0, event_enc=1, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=1, noise=False, mod='none', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=1, w_time=1.0, sample_label=True, w_pos_label=1.0, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p12/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'tl_tag': 'TL70', 'freeze': '', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '0', 'log': 'log.txt', 'user_prefix': '[RD74-TEDA__none-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 128, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 0.1, 'diag_offset': 0, 'event_enc': 1, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'none', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 1, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 1.0, 'w_sample_label': 100.0}, date='08-06-23--16-19-23', run_id='2644428', dataset='P12', str_config='-raindrop/split0', run_name='[RD74-TEDA__none-concat]2644428', run_path='/mlodata1/hokarami/tedam/p12-raindrop/split0/[RD74-TEDA__none-concat]2644428/', device=device(type='cuda'), INPUT='TEDAM', OUTPUT='none-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.1401\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 188/188 [00:00<00:00, 216.45it/s]\n",
      " 57%|    | 41/72 [15:44<11:17, 21.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT TEDAM --> ml-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p12-raindrop/split0/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='', tl_tag='TL70', freeze='', ES_pat=100, setting='raindrop', test_center='', split='0', log='log.txt', user_prefix='[RD74-TEDA__pp_ml-concat]', pos_alpha=1.0, epoch=50, batch_size=128, lr=0.001, smooth=0.0, weight_decay=0.1, diag_offset=0, event_enc=1, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=1, noise=False, mod='ml', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=1, w_time=1.0, sample_label=True, w_pos_label=1.0, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p12/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'tl_tag': 'TL70', 'freeze': '', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '0', 'log': 'log.txt', 'user_prefix': '[RD74-TEDA__pp_ml-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 128, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 0.1, 'diag_offset': 0, 'event_enc': 1, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'ml', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 1, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 1.0, 'w_sample_label': 100.0}, date='08-06-23--16-19-23', run_id='2648994', dataset='P12', str_config='-raindrop/split0', run_name='[RD74-TEDA__pp_ml-concat]2648994', run_path='/mlodata1/hokarami/tedam/p12-raindrop/split0/[RD74-TEDA__pp_ml-concat]2648994/', device=device(type='cuda'), INPUT='TEDAM', OUTPUT='ml-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.1401\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 188/188 [00:00<00:00, 203.47it/s]\n",
      " 58%|    | 42/72 [16:07<11:07, 22.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT TEDAM --> single-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p19-raindrop/split0/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='DO', tl_tag='RD74-single', freeze=['TE'], ES_pat=100, setting='raindrop', test_center='', split='0', log='log.txt', user_prefix='[RD74-TL-TEDA__pp_single_mark-concat]', pos_alpha=1.0, epoch=50, batch_size=64, lr=0.001, smooth=0.0, weight_decay=1.0, diag_offset=0, event_enc=1, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=1, noise=False, mod='single', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=0, w_time=1.0, sample_label=True, w_pos_label=0.3, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p19/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': 'DO', 'tl_tag': 'RD74-single', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '0', 'log': 'log.txt', 'user_prefix': '[RD74-TL-TEDA__pp_single_mark-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 64, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 1.0, 'diag_offset': 0, 'event_enc': 1, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'single', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 0, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 0.3, 'w_sample_label': 100.0}, date='08-06-23--11-48-10', run_id='2646389', dataset='P19', str_config='-raindrop/split0', run_name='[RD74-TL-TEDA__pp_single_mark-concat]2646389', run_path='/mlodata1/hokarami/tedam/p19-raindrop/split0/[RD74-TL-TEDA__pp_single_mark-concat]2646389/', device=device(type='cuda'), INPUT='TEDAM', OUTPUT='single-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.0406\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6191/2718700144.py:75: RuntimeWarning: invalid value encountered in divide\n",
      "  df['color_log_sum'] = np.concatenate(out['list_log_sum'],axis=0) / t_max\n",
      "/tmp/ipykernel_6191/2718700144.py:76: RuntimeWarning: invalid value encountered in divide\n",
      "  df['color_integral_'] = np.concatenate(out['list_integral_'],axis=0) / t_max\n",
      "/tmp/ipykernel_6191/2941533224.py:51: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  dotp = [ np.dot(j,list_summary[0])/(np.linalg.norm(j) * np.linalg.norm(list_summary[0])) for  j in list_summary]\n",
      "100%|| 135/135 [00:00<00:00, 190.45it/s]\n",
      " 60%|    | 43/72 [17:23<18:34, 38.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT TEDAM --> single-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p19-raindrop/split3/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='DO', tl_tag='RD74-single', freeze=['TE'], ES_pat=100, setting='raindrop', test_center='', split='3', log='log.txt', user_prefix='[RD74-TL-TEDA__pp_single_mark-concat]', pos_alpha=1.0, epoch=50, batch_size=64, lr=0.001, smooth=0.0, weight_decay=1.0, diag_offset=0, event_enc=1, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=1, noise=False, mod='single', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=0, w_time=1.0, sample_label=True, w_pos_label=0.3, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p19/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': 'DO', 'tl_tag': 'RD74-single', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '3', 'log': 'log.txt', 'user_prefix': '[RD74-TL-TEDA__pp_single_mark-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 64, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 1.0, 'diag_offset': 0, 'event_enc': 1, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'single', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 0, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 0.3, 'w_sample_label': 100.0}, date='08-06-23--11-48-10', run_id='2644964', dataset='P19', str_config='-raindrop/split3', run_name='[RD74-TL-TEDA__pp_single_mark-concat]2644964', run_path='/mlodata1/hokarami/tedam/p19-raindrop/split3/[RD74-TL-TEDA__pp_single_mark-concat]2644964/', device=device(type='cuda'), INPUT='TEDAM', OUTPUT='single-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.0403\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6191/2718700144.py:75: RuntimeWarning: invalid value encountered in divide\n",
      "  df['color_log_sum'] = np.concatenate(out['list_log_sum'],axis=0) / t_max\n",
      "/tmp/ipykernel_6191/2718700144.py:76: RuntimeWarning: invalid value encountered in divide\n",
      "  df['color_integral_'] = np.concatenate(out['list_integral_'],axis=0) / t_max\n",
      "/tmp/ipykernel_6191/2941533224.py:51: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  dotp = [ np.dot(j,list_summary[0])/(np.linalg.norm(j) * np.linalg.norm(list_summary[0])) for  j in list_summary]\n",
      "100%|| 156/156 [00:00<00:00, 187.42it/s]\n",
      " 61%|    | 44/72 [18:19<20:24, 43.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT TEDAM --> single-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p19-raindrop/split2/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='DO', tl_tag='RD74-single', freeze=['TE'], ES_pat=100, setting='raindrop', test_center='', split='2', log='log.txt', user_prefix='[RD74-TL-TEDA__pp_single_mark-concat]', pos_alpha=1.0, epoch=50, batch_size=64, lr=0.001, smooth=0.0, weight_decay=1.0, diag_offset=0, event_enc=1, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=1, noise=False, mod='single', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=0, w_time=1.0, sample_label=True, w_pos_label=0.3, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p19/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': 'DO', 'tl_tag': 'RD74-single', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '2', 'log': 'log.txt', 'user_prefix': '[RD74-TL-TEDA__pp_single_mark-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 64, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 1.0, 'diag_offset': 0, 'event_enc': 1, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'single', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 0, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 0.3, 'w_sample_label': 100.0}, date='08-06-23--11-48-10', run_id='2647319', dataset='P19', str_config='-raindrop/split2', run_name='[RD74-TL-TEDA__pp_single_mark-concat]2647319', run_path='/mlodata1/hokarami/tedam/p19-raindrop/split2/[RD74-TL-TEDA__pp_single_mark-concat]2647319/', device=device(type='cuda'), INPUT='TEDAM', OUTPUT='single-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.0400\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6191/2718700144.py:75: RuntimeWarning: invalid value encountered in divide\n",
      "  df['color_log_sum'] = np.concatenate(out['list_log_sum'],axis=0) / t_max\n",
      "/tmp/ipykernel_6191/2718700144.py:76: RuntimeWarning: invalid value encountered in divide\n",
      "  df['color_integral_'] = np.concatenate(out['list_integral_'],axis=0) / t_max\n",
      "/tmp/ipykernel_6191/2941533224.py:51: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  dotp = [ np.dot(j,list_summary[0])/(np.linalg.norm(j) * np.linalg.norm(list_summary[0])) for  j in list_summary]\n",
      "100%|| 152/152 [00:00<00:00, 194.10it/s]\n",
      " 62%|   | 45/72 [19:12<20:57, 46.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT TEDAM --> single-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p19-raindrop/split1/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='DO', tl_tag='RD74-single', freeze=['TE'], ES_pat=100, setting='raindrop', test_center='', split='1', log='log.txt', user_prefix='[RD74-TL-TEDA__pp_single_mark-concat]', pos_alpha=1.0, epoch=50, batch_size=64, lr=0.001, smooth=0.0, weight_decay=1.0, diag_offset=0, event_enc=1, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=1, noise=False, mod='single', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=0, w_time=1.0, sample_label=True, w_pos_label=0.3, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p19/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': 'DO', 'tl_tag': 'RD74-single', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '1', 'log': 'log.txt', 'user_prefix': '[RD74-TL-TEDA__pp_single_mark-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 64, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 1.0, 'diag_offset': 0, 'event_enc': 1, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'single', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 0, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 0.3, 'w_sample_label': 100.0}, date='08-06-23--11-48-10', run_id='2642294', dataset='P19', str_config='-raindrop/split1', run_name='[RD74-TL-TEDA__pp_single_mark-concat]2642294', run_path='/mlodata1/hokarami/tedam/p19-raindrop/split1/[RD74-TL-TEDA__pp_single_mark-concat]2642294/', device=device(type='cuda'), INPUT='TEDAM', OUTPUT='single-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.0401\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6191/2718700144.py:75: RuntimeWarning: invalid value encountered in divide\n",
      "  df['color_log_sum'] = np.concatenate(out['list_log_sum'],axis=0) / t_max\n",
      "/tmp/ipykernel_6191/2718700144.py:76: RuntimeWarning: invalid value encountered in divide\n",
      "  df['color_integral_'] = np.concatenate(out['list_integral_'],axis=0) / t_max\n",
      "/tmp/ipykernel_6191/2941533224.py:51: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  dotp = [ np.dot(j,list_summary[0])/(np.linalg.norm(j) * np.linalg.norm(list_summary[0])) for  j in list_summary]\n",
      "100%|| 144/144 [00:00<00:00, 194.95it/s]\n",
      " 64%|   | 46/72 [20:05<20:59, 48.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT TEDAM --> single-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p19-raindrop/split4/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='DO', tl_tag='RD74-single', freeze=['TE'], ES_pat=100, setting='raindrop', test_center='', split='4', log='log.txt', user_prefix='[RD74-TL-TEDA__pp_single_mark-concat]', pos_alpha=1.0, epoch=50, batch_size=64, lr=0.001, smooth=0.0, weight_decay=1.0, diag_offset=0, event_enc=1, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=1, noise=False, mod='single', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=0, w_time=1.0, sample_label=True, w_pos_label=0.3, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p19/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': 'DO', 'tl_tag': 'RD74-single', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '4', 'log': 'log.txt', 'user_prefix': '[RD74-TL-TEDA__pp_single_mark-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 64, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 1.0, 'diag_offset': 0, 'event_enc': 1, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'single', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 0, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 0.3, 'w_sample_label': 100.0}, date='08-06-23--11-48-10', run_id='2649321', dataset='P19', str_config='-raindrop/split4', run_name='[RD74-TL-TEDA__pp_single_mark-concat]2649321', run_path='/mlodata1/hokarami/tedam/p19-raindrop/split4/[RD74-TL-TEDA__pp_single_mark-concat]2649321/', device=device(type='cuda'), INPUT='TEDAM', OUTPUT='single-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.0401\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6191/2718700144.py:75: RuntimeWarning: invalid value encountered in divide\n",
      "  df['color_log_sum'] = np.concatenate(out['list_log_sum'],axis=0) / t_max\n",
      "/tmp/ipykernel_6191/2718700144.py:76: RuntimeWarning: invalid value encountered in divide\n",
      "  df['color_integral_'] = np.concatenate(out['list_integral_'],axis=0) / t_max\n",
      "/tmp/ipykernel_6191/2941533224.py:51: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  dotp = [ np.dot(j,list_summary[0])/(np.linalg.norm(j) * np.linalg.norm(list_summary[0])) for  j in list_summary]\n",
      "100%|| 169/169 [00:00<00:00, 183.04it/s]\n",
      " 65%|   | 47/72 [20:57<20:41, 49.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT TEDAM --> none-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p19-raindrop/split4/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='', freeze='', ES_pat=100, setting='raindrop', test_center='', split='4', log='log.txt', user_prefix='[RD74-TEDA__nextmark-concat]', pos_alpha=1.0, epoch=50, batch_size=64, lr=0.001, smooth=0.0, weight_decay=1.0, diag_offset=0, event_enc=1, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=1, noise=False, mod='none', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=0, w_time=1.0, sample_label=True, w_pos_label=0.3, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p19/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'freeze': '', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '4', 'log': 'log.txt', 'user_prefix': '[RD74-TEDA__nextmark-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 64, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 1.0, 'diag_offset': 0, 'event_enc': 1, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'none', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 0, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 0.3, 'w_sample_label': 100.0}, date='07-06-23--20-02-12', run_id='2634777', dataset='P19', str_config='-raindrop/split4', run_name='[RD74-TEDA__nextmark-concat]2634777', run_path='/mlodata1/hokarami/tedam/p19-raindrop/split4/[RD74-TEDA__nextmark-concat]2634777/', device=device(type='cuda'), INPUT='TEDAM', OUTPUT='none-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.0401\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6191/2941533224.py:51: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  dotp = [ np.dot(j,list_summary[0])/(np.linalg.norm(j) * np.linalg.norm(list_summary[0])) for  j in list_summary]\n",
      "100%|| 169/169 [00:00<00:00, 195.69it/s]\n",
      " 67%|   | 48/72 [21:45<19:32, 48.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT TEDAM --> single-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p19-raindrop/split4/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='', freeze='', ES_pat=100, setting='raindrop', test_center='', split='4', log='log.txt', user_prefix='[RD74-TEDA__pp_single_mark-concat]', pos_alpha=1.0, epoch=50, batch_size=64, lr=0.001, smooth=0.0, weight_decay=1.0, diag_offset=0, event_enc=1, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=1, noise=False, mod='single', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=0, w_time=1.0, sample_label=True, w_pos_label=0.3, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p19/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'freeze': '', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '4', 'log': 'log.txt', 'user_prefix': '[RD74-TEDA__pp_single_mark-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 64, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 1.0, 'diag_offset': 0, 'event_enc': 1, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'single', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 0, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 0.3, 'w_sample_label': 100.0}, date='07-06-23--19-59-04', run_id='2637051', dataset='P19', str_config='-raindrop/split4', run_name='[RD74-TEDA__pp_single_mark-concat]2637051', run_path='/mlodata1/hokarami/tedam/p19-raindrop/split4/[RD74-TEDA__pp_single_mark-concat]2637051/', device=device(type='cuda'), INPUT='TEDAM', OUTPUT='single-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.0401\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6191/2718700144.py:75: RuntimeWarning: invalid value encountered in divide\n",
      "  df['color_log_sum'] = np.concatenate(out['list_log_sum'],axis=0) / t_max\n",
      "/tmp/ipykernel_6191/2718700144.py:76: RuntimeWarning: invalid value encountered in divide\n",
      "  df['color_integral_'] = np.concatenate(out['list_integral_'],axis=0) / t_max\n",
      "/tmp/ipykernel_6191/2941533224.py:51: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  dotp = [ np.dot(j,list_summary[0])/(np.linalg.norm(j) * np.linalg.norm(list_summary[0])) for  j in list_summary]\n",
      "100%|| 169/169 [00:00<00:00, 189.53it/s]\n",
      " 68%|   | 49/72 [22:35<18:54, 49.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT TEDAM --> ml-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p19-raindrop/split4/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='', freeze='', ES_pat=100, setting='raindrop', test_center='', split='4', log='log.txt', user_prefix='[RD74-TEDA__pp_ml-concat]', pos_alpha=1.0, epoch=50, batch_size=64, lr=0.001, smooth=0.0, weight_decay=1.0, diag_offset=0, event_enc=1, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=1, noise=False, mod='ml', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=1, w_time=1.0, sample_label=True, w_pos_label=0.3, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p19/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'freeze': '', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '4', 'log': 'log.txt', 'user_prefix': '[RD74-TEDA__pp_ml-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 64, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 1.0, 'diag_offset': 0, 'event_enc': 1, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'ml', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 1, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 0.3, 'w_sample_label': 100.0}, date='07-06-23--19-47-36', run_id='2634321', dataset='P19', str_config='-raindrop/split4', run_name='[RD74-TEDA__pp_ml-concat]2634321', run_path='/mlodata1/hokarami/tedam/p19-raindrop/split4/[RD74-TEDA__pp_ml-concat]2634321/', device=device(type='cuda'), INPUT='TEDAM', OUTPUT='ml-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.0401\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WTF\n",
      "WTF\n",
      "WTF\n",
      "WTF\n",
      "WTF\n",
      "WTF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WTF\n",
      "WTF\n",
      "WTF\n",
      "WTF\n",
      "WTF\n",
      "WTF\n",
      "WTF\n",
      "WTF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WTF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WTF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6191/2718700144.py:75: RuntimeWarning: invalid value encountered in divide\n",
      "  df['color_log_sum'] = np.concatenate(out['list_log_sum'],axis=0) / t_max\n",
      "/tmp/ipykernel_6191/2718700144.py:76: RuntimeWarning: invalid value encountered in divide\n",
      "  df['color_integral_'] = np.concatenate(out['list_integral_'],axis=0) / t_max\n",
      "/tmp/ipykernel_6191/2941533224.py:51: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  dotp = [ np.dot(j,list_summary[0])/(np.linalg.norm(j) * np.linalg.norm(list_summary[0])) for  j in list_summary]\n",
      "100%|| 169/169 [00:00<00:00, 180.70it/s]\n",
      " 69%|   | 50/72 [23:30<18:45, 51.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT TEDAM --> none-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p19-raindrop/split4/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='', freeze='', ES_pat=100, setting='raindrop', test_center='', split='4', log='log.txt', user_prefix='[RD74-TEDA__none-concat]', pos_alpha=1.0, epoch=50, batch_size=64, lr=0.001, smooth=0.0, weight_decay=1.0, diag_offset=0, event_enc=1, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=1, noise=False, mod='none', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=1, w_time=1.0, sample_label=True, w_pos_label=0.3, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p19/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'freeze': '', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '4', 'log': 'log.txt', 'user_prefix': '[RD74-TEDA__none-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 64, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 1.0, 'diag_offset': 0, 'event_enc': 1, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'none', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 1, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 0.3, 'w_sample_label': 100.0}, date='07-06-23--19-32-00', run_id='2638560', dataset='P19', str_config='-raindrop/split4', run_name='[RD74-TEDA__none-concat]2638560', run_path='/mlodata1/hokarami/tedam/p19-raindrop/split4/[RD74-TEDA__none-concat]2638560/', device=device(type='cuda'), INPUT='TEDAM', OUTPUT='none-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.0401\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6191/2941533224.py:51: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  dotp = [ np.dot(j,list_summary[0])/(np.linalg.norm(j) * np.linalg.norm(list_summary[0])) for  j in list_summary]\n",
      "100%|| 169/169 [00:01<00:00, 156.54it/s]\n",
      " 71%|   | 51/72 [24:40<19:51, 56.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT DAM --> none-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p19-raindrop/split4/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='', freeze='', ES_pat=100, setting='raindrop', test_center='', split='4', log='log.txt', user_prefix='[RD74-DA__base-concat]', pos_alpha=1.0, epoch=50, batch_size=64, lr=0.001, smooth=0.0, weight_decay=1.0, diag_offset=0, event_enc=0, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=1, noise=False, mod='none', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=1, w_time=1.0, sample_label=True, w_pos_label=0.3, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p19/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'freeze': '', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '4', 'log': 'log.txt', 'user_prefix': '[RD74-DA__base-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 64, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 1.0, 'diag_offset': 0, 'event_enc': 0, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'none', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 1, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 0.3, 'w_sample_label': 100.0}, date='07-06-23--19-03-10', run_id='2638875', dataset='P19', str_config='-raindrop/split4', run_name='[RD74-DA__base-concat]2638875', run_path='/mlodata1/hokarami/tedam/p19-raindrop/split4/[RD74-DA__base-concat]2638875/', device=device(type='cuda'), INPUT='DAM', OUTPUT='none-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.0401\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6191/2941533224.py:51: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  dotp = [ np.dot(j,list_summary[0])/(np.linalg.norm(j) * np.linalg.norm(list_summary[0])) for  j in list_summary]\n",
      "100%|| 169/169 [00:00<00:00, 195.27it/s]\n",
      " 72%|  | 52/72 [25:29<18:10, 54.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT TEDAM --> none-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p19-raindrop/split3/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='', freeze='', ES_pat=100, setting='raindrop', test_center='', split='3', log='log.txt', user_prefix='[RD74-TEDA__nextmark-concat]', pos_alpha=1.0, epoch=50, batch_size=64, lr=0.001, smooth=0.0, weight_decay=1.0, diag_offset=0, event_enc=1, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=1, noise=False, mod='none', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=0, w_time=1.0, sample_label=True, w_pos_label=0.3, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p19/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'freeze': '', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '3', 'log': 'log.txt', 'user_prefix': '[RD74-TEDA__nextmark-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 64, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 1.0, 'diag_offset': 0, 'event_enc': 1, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'none', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 0, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 0.3, 'w_sample_label': 100.0}, date='07-06-23--19-00-42', run_id='2632400', dataset='P19', str_config='-raindrop/split3', run_name='[RD74-TEDA__nextmark-concat]2632400', run_path='/mlodata1/hokarami/tedam/p19-raindrop/split3/[RD74-TEDA__nextmark-concat]2632400/', device=device(type='cuda'), INPUT='TEDAM', OUTPUT='none-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.0403\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6191/2941533224.py:51: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  dotp = [ np.dot(j,list_summary[0])/(np.linalg.norm(j) * np.linalg.norm(list_summary[0])) for  j in list_summary]\n",
      "100%|| 156/156 [00:00<00:00, 193.84it/s]\n",
      " 74%|  | 53/72 [26:22<17:04, 53.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT TEDAM --> single-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p19-raindrop/split3/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='', freeze='', ES_pat=100, setting='raindrop', test_center='', split='3', log='log.txt', user_prefix='[RD74-TEDA__pp_single_mark-concat]', pos_alpha=1.0, epoch=50, batch_size=64, lr=0.001, smooth=0.0, weight_decay=1.0, diag_offset=0, event_enc=1, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=1, noise=False, mod='single', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=0, w_time=1.0, sample_label=True, w_pos_label=0.3, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p19/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'freeze': '', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '3', 'log': 'log.txt', 'user_prefix': '[RD74-TEDA__pp_single_mark-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 64, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 1.0, 'diag_offset': 0, 'event_enc': 1, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'single', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 0, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 0.3, 'w_sample_label': 100.0}, date='07-06-23--19-00-32', run_id='2633391', dataset='P19', str_config='-raindrop/split3', run_name='[RD74-TEDA__pp_single_mark-concat]2633391', run_path='/mlodata1/hokarami/tedam/p19-raindrop/split3/[RD74-TEDA__pp_single_mark-concat]2633391/', device=device(type='cuda'), INPUT='TEDAM', OUTPUT='single-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.0403\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6191/2718700144.py:75: RuntimeWarning: invalid value encountered in divide\n",
      "  df['color_log_sum'] = np.concatenate(out['list_log_sum'],axis=0) / t_max\n",
      "/tmp/ipykernel_6191/2718700144.py:76: RuntimeWarning: invalid value encountered in divide\n",
      "  df['color_integral_'] = np.concatenate(out['list_integral_'],axis=0) / t_max\n",
      "/tmp/ipykernel_6191/2941533224.py:51: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  dotp = [ np.dot(j,list_summary[0])/(np.linalg.norm(j) * np.linalg.norm(list_summary[0])) for  j in list_summary]\n",
      "100%|| 156/156 [00:00<00:00, 191.51it/s]\n",
      " 75%|  | 54/72 [27:14<15:59, 53.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT TEDAM --> ml-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p19-raindrop/split3/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='', freeze='', ES_pat=100, setting='raindrop', test_center='', split='3', log='log.txt', user_prefix='[RD74-TEDA__pp_ml-concat]', pos_alpha=1.0, epoch=50, batch_size=64, lr=0.001, smooth=0.0, weight_decay=1.0, diag_offset=0, event_enc=1, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=1, noise=False, mod='ml', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=1, w_time=1.0, sample_label=True, w_pos_label=0.3, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p19/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'freeze': '', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '3', 'log': 'log.txt', 'user_prefix': '[RD74-TEDA__pp_ml-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 64, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 1.0, 'diag_offset': 0, 'event_enc': 1, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'ml', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 1, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 0.3, 'w_sample_label': 100.0}, date='07-06-23--18-59-23', run_id='2637000', dataset='P19', str_config='-raindrop/split3', run_name='[RD74-TEDA__pp_ml-concat]2637000', run_path='/mlodata1/hokarami/tedam/p19-raindrop/split3/[RD74-TEDA__pp_ml-concat]2637000/', device=device(type='cuda'), INPUT='TEDAM', OUTPUT='ml-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.0403\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WTF\n",
      "WTF\n",
      "WTF\n",
      "WTF\n",
      "WTF\n",
      "WTF\n",
      "WTF\n",
      "WTF\n",
      "WTF\n",
      "WTF\n",
      "WTF\n",
      "WTF\n",
      "WTF\n",
      "WTF\n",
      "WTF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WTF\n",
      "WTF\n",
      "WTF\n",
      "WTF\n",
      "WTF\n",
      "WTF\n",
      "WTF\n",
      "WTF\n",
      "WTF\n",
      "WTF\n",
      "WTF\n",
      "WTF\n",
      "WTF\n",
      "WTF\n",
      "WTF\n",
      "WTF\n",
      "WTF\n",
      "WTF\n",
      "WTF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WTF\n",
      "WTF\n",
      "WTF\n",
      "WTF\n",
      "WTF\n",
      "WTF\n",
      "WTF\n",
      "WTF\n",
      "WTF\n",
      "WTF\n",
      "WTF\n",
      "WTF\n",
      "WTF\n",
      "WTF\n",
      "WTF\n",
      "WTF\n",
      "WTF\n",
      "WTF\n",
      "WTF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WTF\n",
      "WTF\n",
      "WTF\n",
      "WTF\n",
      "WTF\n",
      "WTF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WTF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6191/2718700144.py:75: RuntimeWarning: invalid value encountered in divide\n",
      "  df['color_log_sum'] = np.concatenate(out['list_log_sum'],axis=0) / t_max\n",
      "/tmp/ipykernel_6191/2718700144.py:76: RuntimeWarning: invalid value encountered in divide\n",
      "  df['color_integral_'] = np.concatenate(out['list_integral_'],axis=0) / t_max\n",
      "/tmp/ipykernel_6191/2941533224.py:51: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  dotp = [ np.dot(j,list_summary[0])/(np.linalg.norm(j) * np.linalg.norm(list_summary[0])) for  j in list_summary]\n",
      "100%|| 156/156 [00:01<00:00, 151.20it/s]\n",
      " 76%|  | 55/72 [28:06<15:02, 53.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT TEDAM --> none-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p19-raindrop/split3/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='', freeze='', ES_pat=100, setting='raindrop', test_center='', split='3', log='log.txt', user_prefix='[RD74-TEDA__none-concat]', pos_alpha=1.0, epoch=50, batch_size=64, lr=0.001, smooth=0.0, weight_decay=1.0, diag_offset=0, event_enc=1, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=1, noise=False, mod='none', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=1, w_time=1.0, sample_label=True, w_pos_label=0.3, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p19/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'freeze': '', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '3', 'log': 'log.txt', 'user_prefix': '[RD74-TEDA__none-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 64, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 1.0, 'diag_offset': 0, 'event_enc': 1, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'none', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 1, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 0.3, 'w_sample_label': 100.0}, date='07-06-23--18-41-55', run_id='2634067', dataset='P19', str_config='-raindrop/split3', run_name='[RD74-TEDA__none-concat]2634067', run_path='/mlodata1/hokarami/tedam/p19-raindrop/split3/[RD74-TEDA__none-concat]2634067/', device=device(type='cuda'), INPUT='TEDAM', OUTPUT='none-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.0403\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6191/2941533224.py:51: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  dotp = [ np.dot(j,list_summary[0])/(np.linalg.norm(j) * np.linalg.norm(list_summary[0])) for  j in list_summary]\n",
      "100%|| 156/156 [00:00<00:00, 192.83it/s]\n",
      " 78%|  | 56/72 [28:57<13:56, 52.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT DAM --> none-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p19-raindrop/split3/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='', freeze='', ES_pat=100, setting='raindrop', test_center='', split='3', log='log.txt', user_prefix='[RD74-DA__base-concat]', pos_alpha=1.0, epoch=50, batch_size=64, lr=0.001, smooth=0.0, weight_decay=1.0, diag_offset=0, event_enc=0, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=1, noise=False, mod='none', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=1, w_time=1.0, sample_label=True, w_pos_label=0.3, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p19/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'freeze': '', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '3', 'log': 'log.txt', 'user_prefix': '[RD74-DA__base-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 64, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 1.0, 'diag_offset': 0, 'event_enc': 0, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'none', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 1, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 0.3, 'w_sample_label': 100.0}, date='07-06-23--18-17-18', run_id='2636791', dataset='P19', str_config='-raindrop/split3', run_name='[RD74-DA__base-concat]2636791', run_path='/mlodata1/hokarami/tedam/p19-raindrop/split3/[RD74-DA__base-concat]2636791/', device=device(type='cuda'), INPUT='DAM', OUTPUT='none-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.0403\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6191/2941533224.py:51: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  dotp = [ np.dot(j,list_summary[0])/(np.linalg.norm(j) * np.linalg.norm(list_summary[0])) for  j in list_summary]\n",
      "100%|| 156/156 [00:00<00:00, 201.86it/s]\n",
      " 79%|  | 57/72 [29:49<13:03, 52.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT TEDAM --> none-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p19-raindrop/split2/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='', freeze='', ES_pat=100, setting='raindrop', test_center='', split='2', log='log.txt', user_prefix='[RD74-TEDA__nextmark-concat]', pos_alpha=1.0, epoch=50, batch_size=64, lr=0.001, smooth=0.0, weight_decay=1.0, diag_offset=0, event_enc=1, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=1, noise=False, mod='none', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=0, w_time=1.0, sample_label=True, w_pos_label=0.3, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p19/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'freeze': '', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '2', 'log': 'log.txt', 'user_prefix': '[RD74-TEDA__nextmark-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 64, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 1.0, 'diag_offset': 0, 'event_enc': 1, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'none', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 0, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 0.3, 'w_sample_label': 100.0}, date='07-06-23--18-08-37', run_id='2636223', dataset='P19', str_config='-raindrop/split2', run_name='[RD74-TEDA__nextmark-concat]2636223', run_path='/mlodata1/hokarami/tedam/p19-raindrop/split2/[RD74-TEDA__nextmark-concat]2636223/', device=device(type='cuda'), INPUT='TEDAM', OUTPUT='none-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.0400\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6191/2941533224.py:51: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  dotp = [ np.dot(j,list_summary[0])/(np.linalg.norm(j) * np.linalg.norm(list_summary[0])) for  j in list_summary]\n",
      "100%|| 152/152 [00:00<00:00, 194.75it/s]\n",
      " 81%|  | 58/72 [30:42<12:13, 52.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT TEDAM --> single-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p19-raindrop/split2/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='', freeze='', ES_pat=100, setting='raindrop', test_center='', split='2', log='log.txt', user_prefix='[RD74-TEDA__pp_single_mark-concat]', pos_alpha=1.0, epoch=50, batch_size=64, lr=0.001, smooth=0.0, weight_decay=1.0, diag_offset=0, event_enc=1, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=1, noise=False, mod='single', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=0, w_time=1.0, sample_label=True, w_pos_label=0.3, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p19/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'freeze': '', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '2', 'log': 'log.txt', 'user_prefix': '[RD74-TEDA__pp_single_mark-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 64, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 1.0, 'diag_offset': 0, 'event_enc': 1, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'single', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 0, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 0.3, 'w_sample_label': 100.0}, date='07-06-23--18-07-00', run_id='2637610', dataset='P19', str_config='-raindrop/split2', run_name='[RD74-TEDA__pp_single_mark-concat]2637610', run_path='/mlodata1/hokarami/tedam/p19-raindrop/split2/[RD74-TEDA__pp_single_mark-concat]2637610/', device=device(type='cuda'), INPUT='TEDAM', OUTPUT='single-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.0400\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6191/2718700144.py:75: RuntimeWarning: invalid value encountered in divide\n",
      "  df['color_log_sum'] = np.concatenate(out['list_log_sum'],axis=0) / t_max\n",
      "/tmp/ipykernel_6191/2718700144.py:76: RuntimeWarning: invalid value encountered in divide\n",
      "  df['color_integral_'] = np.concatenate(out['list_integral_'],axis=0) / t_max\n",
      "/tmp/ipykernel_6191/2941533224.py:51: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  dotp = [ np.dot(j,list_summary[0])/(np.linalg.norm(j) * np.linalg.norm(list_summary[0])) for  j in list_summary]\n",
      "100%|| 152/152 [00:00<00:00, 178.30it/s]\n",
      " 82%| | 59/72 [31:34<11:21, 52.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT TEDAM --> ml-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p19-raindrop/split2/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='', freeze='', ES_pat=100, setting='raindrop', test_center='', split='2', log='log.txt', user_prefix='[RD74-TEDA__pp_ml-concat]', pos_alpha=1.0, epoch=50, batch_size=64, lr=0.001, smooth=0.0, weight_decay=1.0, diag_offset=0, event_enc=1, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=1, noise=False, mod='ml', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=1, w_time=1.0, sample_label=True, w_pos_label=0.3, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p19/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'freeze': '', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '2', 'log': 'log.txt', 'user_prefix': '[RD74-TEDA__pp_ml-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 64, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 1.0, 'diag_offset': 0, 'event_enc': 1, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'ml', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 1, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 0.3, 'w_sample_label': 100.0}, date='07-06-23--18-01-19', run_id='2637236', dataset='P19', str_config='-raindrop/split2', run_name='[RD74-TEDA__pp_ml-concat]2637236', run_path='/mlodata1/hokarami/tedam/p19-raindrop/split2/[RD74-TEDA__pp_ml-concat]2637236/', device=device(type='cuda'), INPUT='TEDAM', OUTPUT='ml-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.0400\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6191/2718700144.py:75: RuntimeWarning: invalid value encountered in divide\n",
      "  df['color_log_sum'] = np.concatenate(out['list_log_sum'],axis=0) / t_max\n",
      "/tmp/ipykernel_6191/2718700144.py:76: RuntimeWarning: invalid value encountered in divide\n",
      "  df['color_integral_'] = np.concatenate(out['list_integral_'],axis=0) / t_max\n",
      "/tmp/ipykernel_6191/2941533224.py:51: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  dotp = [ np.dot(j,list_summary[0])/(np.linalg.norm(j) * np.linalg.norm(list_summary[0])) for  j in list_summary]\n",
      "100%|| 152/152 [00:01<00:00, 146.17it/s]\n",
      " 83%| | 60/72 [32:32<10:46, 53.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT TEDAM --> none-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p19-raindrop/split2/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='', freeze='', ES_pat=100, setting='raindrop', test_center='', split='2', log='log.txt', user_prefix='[RD74-TEDA__none-concat]', pos_alpha=1.0, epoch=50, batch_size=64, lr=0.001, smooth=0.0, weight_decay=1.0, diag_offset=0, event_enc=1, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=1, noise=False, mod='none', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=1, w_time=1.0, sample_label=True, w_pos_label=0.3, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p19/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'freeze': '', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '2', 'log': 'log.txt', 'user_prefix': '[RD74-TEDA__none-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 64, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 1.0, 'diag_offset': 0, 'event_enc': 1, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'none', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 1, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 0.3, 'w_sample_label': 100.0}, date='07-06-23--17-54-34', run_id='2632380', dataset='P19', str_config='-raindrop/split2', run_name='[RD74-TEDA__none-concat]2632380', run_path='/mlodata1/hokarami/tedam/p19-raindrop/split2/[RD74-TEDA__none-concat]2632380/', device=device(type='cuda'), INPUT='TEDAM', OUTPUT='none-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.0400\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6191/2941533224.py:51: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  dotp = [ np.dot(j,list_summary[0])/(np.linalg.norm(j) * np.linalg.norm(list_summary[0])) for  j in list_summary]\n",
      "100%|| 152/152 [00:00<00:00, 177.76it/s]\n",
      " 85%| | 61/72 [33:27<09:58, 54.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT DAM --> none-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p19-raindrop/split2/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='', freeze='', ES_pat=100, setting='raindrop', test_center='', split='2', log='log.txt', user_prefix='[RD74-DA__base-concat]', pos_alpha=1.0, epoch=50, batch_size=64, lr=0.001, smooth=0.0, weight_decay=1.0, diag_offset=0, event_enc=0, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=1, noise=False, mod='none', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=1, w_time=1.0, sample_label=True, w_pos_label=0.3, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p19/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'freeze': '', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '2', 'log': 'log.txt', 'user_prefix': '[RD74-DA__base-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 64, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 1.0, 'diag_offset': 0, 'event_enc': 0, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'none', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 1, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 0.3, 'w_sample_label': 100.0}, date='07-06-23--17-36-18', run_id='2632332', dataset='P19', str_config='-raindrop/split2', run_name='[RD74-DA__base-concat]2632332', run_path='/mlodata1/hokarami/tedam/p19-raindrop/split2/[RD74-DA__base-concat]2632332/', device=device(type='cuda'), INPUT='DAM', OUTPUT='none-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.0400\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6191/2941533224.py:51: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  dotp = [ np.dot(j,list_summary[0])/(np.linalg.norm(j) * np.linalg.norm(list_summary[0])) for  j in list_summary]\n",
      "100%|| 152/152 [00:00<00:00, 177.37it/s]\n",
      " 86%| | 62/72 [34:21<09:01, 54.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT TEDAM --> none-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p19-raindrop/split1/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='', freeze='', ES_pat=100, setting='raindrop', test_center='', split='1', log='log.txt', user_prefix='[RD74-TEDA__nextmark-concat]', pos_alpha=1.0, epoch=50, batch_size=64, lr=0.001, smooth=0.0, weight_decay=1.0, diag_offset=0, event_enc=1, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=1, noise=False, mod='none', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=0, w_time=1.0, sample_label=True, w_pos_label=0.3, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p19/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'freeze': '', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '1', 'log': 'log.txt', 'user_prefix': '[RD74-TEDA__nextmark-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 64, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 1.0, 'diag_offset': 0, 'event_enc': 1, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'none', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 0, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 0.3, 'w_sample_label': 100.0}, date='07-06-23--17-15-06', run_id='2631431', dataset='P19', str_config='-raindrop/split1', run_name='[RD74-TEDA__nextmark-concat]2631431', run_path='/mlodata1/hokarami/tedam/p19-raindrop/split1/[RD74-TEDA__nextmark-concat]2631431/', device=device(type='cuda'), INPUT='TEDAM', OUTPUT='none-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.0401\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6191/2941533224.py:51: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  dotp = [ np.dot(j,list_summary[0])/(np.linalg.norm(j) * np.linalg.norm(list_summary[0])) for  j in list_summary]\n",
      "100%|| 144/144 [00:00<00:00, 146.86it/s]\n",
      " 88%| | 63/72 [35:16<08:09, 54.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT TEDAM --> single-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p19-raindrop/split1/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='', freeze='', ES_pat=100, setting='raindrop', test_center='', split='1', log='log.txt', user_prefix='[RD74-TEDA__pp_single_mark-concat]', pos_alpha=1.0, epoch=50, batch_size=64, lr=0.001, smooth=0.0, weight_decay=1.0, diag_offset=0, event_enc=1, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=1, noise=False, mod='single', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=0, w_time=1.0, sample_label=True, w_pos_label=0.3, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p19/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'freeze': '', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '1', 'log': 'log.txt', 'user_prefix': '[RD74-TEDA__pp_single_mark-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 64, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 1.0, 'diag_offset': 0, 'event_enc': 1, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'single', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 0, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 0.3, 'w_sample_label': 100.0}, date='07-06-23--17-11-33', run_id='2631751', dataset='P19', str_config='-raindrop/split1', run_name='[RD74-TEDA__pp_single_mark-concat]2631751', run_path='/mlodata1/hokarami/tedam/p19-raindrop/split1/[RD74-TEDA__pp_single_mark-concat]2631751/', device=device(type='cuda'), INPUT='TEDAM', OUTPUT='single-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.0401\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6191/2718700144.py:75: RuntimeWarning: invalid value encountered in divide\n",
      "  df['color_log_sum'] = np.concatenate(out['list_log_sum'],axis=0) / t_max\n",
      "/tmp/ipykernel_6191/2718700144.py:76: RuntimeWarning: invalid value encountered in divide\n",
      "  df['color_integral_'] = np.concatenate(out['list_integral_'],axis=0) / t_max\n",
      "/tmp/ipykernel_6191/2941533224.py:51: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  dotp = [ np.dot(j,list_summary[0])/(np.linalg.norm(j) * np.linalg.norm(list_summary[0])) for  j in list_summary]\n",
      "100%|| 144/144 [00:00<00:00, 188.27it/s]\n",
      " 89%| | 64/72 [36:15<07:25, 55.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT TEDAM --> ml-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p19-raindrop/split1/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='', freeze='', ES_pat=100, setting='raindrop', test_center='', split='1', log='log.txt', user_prefix='[RD74-TEDA__pp_ml-concat]', pos_alpha=1.0, epoch=50, batch_size=64, lr=0.001, smooth=0.0, weight_decay=1.0, diag_offset=0, event_enc=1, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=1, noise=False, mod='ml', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=1, w_time=1.0, sample_label=True, w_pos_label=0.3, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p19/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'freeze': '', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '1', 'log': 'log.txt', 'user_prefix': '[RD74-TEDA__pp_ml-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 64, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 1.0, 'diag_offset': 0, 'event_enc': 1, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'ml', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 1, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 0.3, 'w_sample_label': 100.0}, date='07-06-23--17-10-09', run_id='2634549', dataset='P19', str_config='-raindrop/split1', run_name='[RD74-TEDA__pp_ml-concat]2634549', run_path='/mlodata1/hokarami/tedam/p19-raindrop/split1/[RD74-TEDA__pp_ml-concat]2634549/', device=device(type='cuda'), INPUT='TEDAM', OUTPUT='ml-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.0401\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WTF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WTF\n",
      "WTF\n",
      "WTF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WTF\n",
      "WTF\n",
      "WTF\n",
      "WTF\n",
      "WTF\n",
      "WTF\n",
      "WTF\n",
      "WTF\n",
      "WTF\n",
      "WTF\n",
      "WTF\n",
      "WTF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WTF\n",
      "WTF\n",
      "WTF\n",
      "WTF\n",
      "WTF\n",
      "WTF\n",
      "WTF\n",
      "WTF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6191/2718700144.py:75: RuntimeWarning: invalid value encountered in divide\n",
      "  df['color_log_sum'] = np.concatenate(out['list_log_sum'],axis=0) / t_max\n",
      "/tmp/ipykernel_6191/2718700144.py:76: RuntimeWarning: invalid value encountered in divide\n",
      "  df['color_integral_'] = np.concatenate(out['list_integral_'],axis=0) / t_max\n",
      "/tmp/ipykernel_6191/2941533224.py:51: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  dotp = [ np.dot(j,list_summary[0])/(np.linalg.norm(j) * np.linalg.norm(list_summary[0])) for  j in list_summary]\n",
      "100%|| 144/144 [00:00<00:00, 174.55it/s]\n",
      " 90%| | 65/72 [37:07<06:22, 54.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT TEDAM --> none-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p19-raindrop/split1/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='', freeze='', ES_pat=100, setting='raindrop', test_center='', split='1', log='log.txt', user_prefix='[RD74-TEDA__none-concat]', pos_alpha=1.0, epoch=50, batch_size=64, lr=0.001, smooth=0.0, weight_decay=1.0, diag_offset=0, event_enc=1, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=1, noise=False, mod='none', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=1, w_time=1.0, sample_label=True, w_pos_label=0.3, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p19/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'freeze': '', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '1', 'log': 'log.txt', 'user_prefix': '[RD74-TEDA__none-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 64, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 1.0, 'diag_offset': 0, 'event_enc': 1, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'none', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 1, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 0.3, 'w_sample_label': 100.0}, date='07-06-23--17-02-09', run_id='2636201', dataset='P19', str_config='-raindrop/split1', run_name='[RD74-TEDA__none-concat]2636201', run_path='/mlodata1/hokarami/tedam/p19-raindrop/split1/[RD74-TEDA__none-concat]2636201/', device=device(type='cuda'), INPUT='TEDAM', OUTPUT='none-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.0401\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6191/2941533224.py:51: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  dotp = [ np.dot(j,list_summary[0])/(np.linalg.norm(j) * np.linalg.norm(list_summary[0])) for  j in list_summary]\n",
      "100%|| 144/144 [00:00<00:00, 180.89it/s]\n",
      " 92%|| 66/72 [37:59<05:23, 53.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT DAM --> none-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p19-raindrop/split1/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='', freeze='', ES_pat=100, setting='raindrop', test_center='', split='1', log='log.txt', user_prefix='[RD74-DA__base-concat]', pos_alpha=1.0, epoch=50, batch_size=64, lr=0.001, smooth=0.0, weight_decay=1.0, diag_offset=0, event_enc=0, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=1, noise=False, mod='none', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=1, w_time=1.0, sample_label=True, w_pos_label=0.3, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p19/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'freeze': '', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '1', 'log': 'log.txt', 'user_prefix': '[RD74-DA__base-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 64, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 1.0, 'diag_offset': 0, 'event_enc': 0, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'none', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 1, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 0.3, 'w_sample_label': 100.0}, date='07-06-23--16-58-27', run_id='2637078', dataset='P19', str_config='-raindrop/split1', run_name='[RD74-DA__base-concat]2637078', run_path='/mlodata1/hokarami/tedam/p19-raindrop/split1/[RD74-DA__base-concat]2637078/', device=device(type='cuda'), INPUT='DAM', OUTPUT='none-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.0401\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6191/2941533224.py:51: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  dotp = [ np.dot(j,list_summary[0])/(np.linalg.norm(j) * np.linalg.norm(list_summary[0])) for  j in list_summary]\n",
      "100%|| 144/144 [00:00<00:00, 199.69it/s]\n",
      " 93%|| 67/72 [38:53<04:29, 53.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT DAM --> none-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p19-raindrop/split0/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='', freeze='', ES_pat=100, setting='raindrop', test_center='', split='0', log='log.txt', user_prefix='[RD74-DA__base-concat]', pos_alpha=1.0, epoch=50, batch_size=64, lr=0.001, smooth=0.0, weight_decay=1.0, diag_offset=0, event_enc=0, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=1, noise=False, mod='none', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=1, w_time=1.0, sample_label=True, w_pos_label=0.3, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p19/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'freeze': '', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '0', 'log': 'log.txt', 'user_prefix': '[RD74-DA__base-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 64, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 1.0, 'diag_offset': 0, 'event_enc': 0, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'none', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 1, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 0.3, 'w_sample_label': 100.0}, date='07-06-23--16-20-05', run_id='2633985', dataset='P19', str_config='-raindrop/split0', run_name='[RD74-DA__base-concat]2633985', run_path='/mlodata1/hokarami/tedam/p19-raindrop/split0/[RD74-DA__base-concat]2633985/', device=device(type='cuda'), INPUT='DAM', OUTPUT='none-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.0406\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6191/2941533224.py:51: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  dotp = [ np.dot(j,list_summary[0])/(np.linalg.norm(j) * np.linalg.norm(list_summary[0])) for  j in list_summary]\n",
      "100%|| 135/135 [00:00<00:00, 171.36it/s]\n",
      " 94%|| 68/72 [39:48<03:37, 54.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT TEDAM --> none-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p19-raindrop/split0/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='', freeze='', ES_pat=100, setting='raindrop', test_center='', split='0', log='log.txt', user_prefix='[RD74-TEDA__nextmark-concat]', pos_alpha=1.0, epoch=50, batch_size=64, lr=0.001, smooth=0.0, weight_decay=1.0, diag_offset=0, event_enc=1, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=1, noise=False, mod='none', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=0, w_time=1.0, sample_label=True, w_pos_label=0.3, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p19/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'freeze': '', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '0', 'log': 'log.txt', 'user_prefix': '[RD74-TEDA__nextmark-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 64, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 1.0, 'diag_offset': 0, 'event_enc': 1, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'none', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 0, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 0.3, 'w_sample_label': 100.0}, date='07-06-23--16-20-05', run_id='2636184', dataset='P19', str_config='-raindrop/split0', run_name='[RD74-TEDA__nextmark-concat]2636184', run_path='/mlodata1/hokarami/tedam/p19-raindrop/split0/[RD74-TEDA__nextmark-concat]2636184/', device=device(type='cuda'), INPUT='TEDAM', OUTPUT='none-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.0406\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6191/2941533224.py:51: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  dotp = [ np.dot(j,list_summary[0])/(np.linalg.norm(j) * np.linalg.norm(list_summary[0])) for  j in list_summary]\n",
      "100%|| 135/135 [00:00<00:00, 184.06it/s]\n",
      " 96%|| 69/72 [40:39<02:40, 53.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT TEDAM --> none-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p19-raindrop/split0/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='', freeze='', ES_pat=100, setting='raindrop', test_center='', split='0', log='log.txt', user_prefix='[RD74-TEDA__none-concat]', pos_alpha=1.0, epoch=50, batch_size=64, lr=0.001, smooth=0.0, weight_decay=1.0, diag_offset=0, event_enc=1, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=1, noise=False, mod='none', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=1, w_time=1.0, sample_label=True, w_pos_label=0.3, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p19/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'freeze': '', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '0', 'log': 'log.txt', 'user_prefix': '[RD74-TEDA__none-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 64, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 1.0, 'diag_offset': 0, 'event_enc': 1, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'none', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 1, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 0.3, 'w_sample_label': 100.0}, date='07-06-23--16-20-05', run_id='2631150', dataset='P19', str_config='-raindrop/split0', run_name='[RD74-TEDA__none-concat]2631150', run_path='/mlodata1/hokarami/tedam/p19-raindrop/split0/[RD74-TEDA__none-concat]2631150/', device=device(type='cuda'), INPUT='TEDAM', OUTPUT='none-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.0406\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6191/2941533224.py:51: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  dotp = [ np.dot(j,list_summary[0])/(np.linalg.norm(j) * np.linalg.norm(list_summary[0])) for  j in list_summary]\n",
      "100%|| 135/135 [00:01<00:00, 134.26it/s]\n",
      " 97%|| 70/72 [41:31<01:45, 52.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT TEDAM --> single-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p19-raindrop/split0/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='', freeze='', ES_pat=100, setting='raindrop', test_center='', split='0', log='log.txt', user_prefix='[RD74-TEDA__pp_single_mark-concat]', pos_alpha=1.0, epoch=50, batch_size=64, lr=0.001, smooth=0.0, weight_decay=1.0, diag_offset=0, event_enc=1, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=1, noise=False, mod='single', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=0, w_time=1.0, sample_label=True, w_pos_label=0.3, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p19/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'freeze': '', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '0', 'log': 'log.txt', 'user_prefix': '[RD74-TEDA__pp_single_mark-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 64, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 1.0, 'diag_offset': 0, 'event_enc': 1, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'single', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 0, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 0.3, 'w_sample_label': 100.0}, date='07-06-23--16-20-05', run_id='2633146', dataset='P19', str_config='-raindrop/split0', run_name='[RD74-TEDA__pp_single_mark-concat]2633146', run_path='/mlodata1/hokarami/tedam/p19-raindrop/split0/[RD74-TEDA__pp_single_mark-concat]2633146/', device=device(type='cuda'), INPUT='TEDAM', OUTPUT='single-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.0406\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6191/2718700144.py:75: RuntimeWarning: invalid value encountered in divide\n",
      "  df['color_log_sum'] = np.concatenate(out['list_log_sum'],axis=0) / t_max\n",
      "/tmp/ipykernel_6191/2718700144.py:76: RuntimeWarning: invalid value encountered in divide\n",
      "  df['color_integral_'] = np.concatenate(out['list_integral_'],axis=0) / t_max\n",
      "/tmp/ipykernel_6191/2941533224.py:51: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  dotp = [ np.dot(j,list_summary[0])/(np.linalg.norm(j) * np.linalg.norm(list_summary[0])) for  j in list_summary]\n",
      "100%|| 135/135 [00:00<00:00, 195.93it/s]\n",
      " 99%|| 71/72 [42:21<00:52, 52.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT TEDAM --> ml-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p19-raindrop/split0/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='', freeze='', ES_pat=100, setting='raindrop', test_center='', split='0', log='log.txt', user_prefix='[RD74-TEDA__pp_ml-concat]', pos_alpha=1.0, epoch=50, batch_size=64, lr=0.001, smooth=0.0, weight_decay=1.0, diag_offset=0, event_enc=1, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=1, noise=False, mod='ml', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=1, w_time=1.0, sample_label=True, w_pos_label=0.3, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p19/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'freeze': '', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '0', 'log': 'log.txt', 'user_prefix': '[RD74-TEDA__pp_ml-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 64, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 1.0, 'diag_offset': 0, 'event_enc': 1, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'ml', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 1, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 0.3, 'w_sample_label': 100.0}, date='07-06-23--16-20-05', run_id='2634174', dataset='P19', str_config='-raindrop/split0', run_name='[RD74-TEDA__pp_ml-concat]2634174', run_path='/mlodata1/hokarami/tedam/p19-raindrop/split0/[RD74-TEDA__pp_ml-concat]2634174/', device=device(type='cuda'), INPUT='TEDAM', OUTPUT='ml-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.0406\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WTF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WTF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6191/2718700144.py:75: RuntimeWarning: invalid value encountered in divide\n",
      "  df['color_log_sum'] = np.concatenate(out['list_log_sum'],axis=0) / t_max\n",
      "/tmp/ipykernel_6191/2718700144.py:76: RuntimeWarning: invalid value encountered in divide\n",
      "  df['color_integral_'] = np.concatenate(out['list_integral_'],axis=0) / t_max\n",
      "/tmp/ipykernel_6191/2941533224.py:51: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  dotp = [ np.dot(j,list_summary[0])/(np.linalg.norm(j) * np.linalg.norm(list_summary[0])) for  j in list_summary]\n",
      "100%|| 135/135 [00:00<00:00, 172.83it/s]\n",
      "                                               \r"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# run_path = \"hokarami/TEEDAM_supervised/3drow7po\" # https://wandb.ai/hokarami/TEEDAM_supervised/runs/3drow7po/overview?workspace=user-g-hojatkarami\n",
    "\n",
    "# run_paths = [\"hokarami/TEEDAM_supervised/3drow7po\"]\n",
    "n_knn=10\n",
    "temp = list()\n",
    "bad_runs=list()\n",
    "for run_path in tqdm(run_paths[:], leave=False):\n",
    "\n",
    "    try:\n",
    "        model1, opt1, run1 = read_from_wandb(run_path,consider_sample_labels=True)\n",
    "    except:\n",
    "        bad_runs.append(run_path)\n",
    "        continue\n",
    "    dict_metrics1, out1 = Main.valid_epoch_tsne(model1, opt1.validloader, opt1.pred_loss_func, opt1)\n",
    "    # X_tsne1, X_tsne_split1 = compute_tsne(out1['r_enc_list'], model1)\n",
    "    res_labels = opt1.dict_map_events.keys()\n",
    "    df1 = build_df(out1,opt1, X_tsne=None)\n",
    "\n",
    "    pid_all = list(df1.index)\n",
    "\n",
    "    pid_positive = list(df1[df1.color_true=='Positive Samples'].index)\n",
    "\n",
    "    list_sim_score1 = []\n",
    "    # X1 = np.concatenate(out1['r_enc_list'],axis=0)[:,:]\n",
    "    \n",
    "    # only DAM embeddings\n",
    "    X1 = np.concatenate(out1['r_enc_list'],axis=0)[:,model1.d_out_te:model1.d_out_te+model1.d_out_dam]\n",
    "\n",
    "    # only TEE embeddings\n",
    "    X1 = np.concatenate(out1['r_enc_list'],axis=0)[:,:model1.d_out_te]\n",
    "\n",
    "    # TEE+DAM embeddings\n",
    "    X1 = np.concatenate(out1['r_enc_list'],axis=0)[:,:model1.d_out_te+model1.d_out_dam]\n",
    "\n",
    "    for pid in tqdm( pid_positive ):\n",
    "        id_origin = pid\n",
    "\n",
    "        knn_pids = find_knn_pids (X1, id_origin, n_knn=n_knn)\n",
    "        sim_score1, list_summary = cal_similarity(df1, out1, pid, knn_pids)    \n",
    "\n",
    "        \n",
    "        if ( not np.isnan(sim_score1) ) :\n",
    "            list_sim_score1.append(sim_score1)\n",
    "\n",
    "    # np.mean(list_sim_score1), np.std(list_sim_score1)\n",
    "\n",
    "    api = wandb.Api()\n",
    "    run = api.run(run_path)\n",
    "\n",
    "    run.summary['knn-ps-mean'] = np.mean(list_sim_score1)\n",
    "    run.summary['knn-ps-std'] = np.std(list_sim_score1)\n",
    "    run.summary.update()\n",
    "\n",
    "    temptemp=dict()\n",
    "    temptemp['path']=run_path\n",
    "    temptemp['knn-ps-mean']=np.mean(list_sim_score1)\n",
    "    temptemp['knn-ps-std']=np.std(list_sim_score1)\n",
    "    temp.append(temptemp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<File best_model.pkl () 2.2MiB>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<_io.TextIOWrapper name='.local\\\\best_model.pkl' mode='r' encoding='UTF-8'>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloaded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<File opt.pkl () 1.4KiB>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<_io.TextIOWrapper name='.local\\\\opt.pkl' mode='r' encoding='UTF-8'>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloaded\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# run_path = \"hokarami/TEEDAM_supervised/s1j6o0zy\"\n",
    "run = api.run(run_paths[0])\n",
    "\n",
    "for file in run.files():\n",
    "    # if file.name contains 'best_model' or 'opt.pkl'\n",
    "    if 'best_model' in file.name or 'opt.pkl' in file.name:\n",
    "        file\n",
    "        try:\n",
    "            file.download(replace=True, root='.local')\n",
    "            print('downloaded')\n",
    "        except:\n",
    "            print('ERROR')\n",
    "            pass\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## CUDA True\n",
      "[Info] INPUT TEDAM --> none-mark-label\n",
      "[Info] parameters: Namespace(data='/mlodata1/hokarami/tedam/p12-raindrop/split4/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='', tl_tag='TL70', freeze='', ES_pat=100, setting='raindrop', test_center='', split='4', log='log.txt', user_prefix='[RD74-TL-TEDA__nextmark-concat]', pos_alpha=1.0, epoch=50, batch_size=128, lr=0.001, smooth=0.0, weight_decay=0.1, diag_offset=0, event_enc=1, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=1, noise=False, mod='none', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=0, w_time=1.0, sample_label=True, w_pos_label=1.0, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p12/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'tl_tag': 'TL70', 'freeze': '', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '4', 'log': 'log.txt', 'user_prefix': '[RD74-TL-TEDA__nextmark-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 128, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 0.1, 'diag_offset': 0, 'event_enc': 1, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'none', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 0, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 1.0, 'w_sample_label': 100.0}, date='09-06-23--14-05-34', run_id='2651795', dataset='P12', str_config='-raindrop/split4', run_name='[RD74-TL-TEDA__nextmark-concat]2651795', run_path='/mlodata1/hokarami/tedam/p12-raindrop/split4/[RD74-TL-TEDA__nextmark-concat]2651795/', device=device(type='cuda'), INPUT='TEDAM', OUTPUT='none-mark-label')\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n",
      "[Info] Loading test data...\n",
      "[info] 100% of data will be considered\n",
      "[Info] Loading train STATE...\n",
      "[Info] Loading dev STATE...\n",
      "[Info] Loading test STATE...\n",
      "[info] 100% of data will be considered\n",
      "[info] True/total = 0.1448\n",
      "[info] balanced mini batches\n",
      "[info] STATE will be considered\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(ATHP(\n",
       "   (TE): Encoder(\n",
       "     (event_emb): Linear(in_features=24, out_features=8, bias=True)\n",
       "     (layer_stack): ModuleList(\n",
       "       (0-3): 4 x EncoderLayer(\n",
       "         (slf_attn): MultiHeadAttention(\n",
       "           (w_qs): Linear(in_features=12, out_features=32, bias=False)\n",
       "           (w_ks): Linear(in_features=12, out_features=32, bias=False)\n",
       "           (w_vs): Linear(in_features=12, out_features=32, bias=False)\n",
       "           (fc): Linear(in_features=32, out_features=12, bias=True)\n",
       "           (attention): ScaledDotProductAttention(\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (layer_norm): LayerNorm((12,), eps=1e-06, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (pos_ffn): PositionwiseFeedForward(\n",
       "           (w_1): Linear(in_features=12, out_features=32, bias=True)\n",
       "           (w_2): Linear(in_features=32, out_features=12, bias=True)\n",
       "           (layer_norm): LayerNorm((12,), eps=1e-06, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (DAM): DeepAttensionModule(\n",
       "     (demo_encoder): Predictor(\n",
       "       (linear1): Linear(in_features=7, out_features=16, bias=True)\n",
       "       (linear2): Linear(in_features=16, out_features=16, bias=True)\n",
       "       (linear3): Linear(in_features=16, out_features=52, bias=True)\n",
       "       (relu): ReLU()\n",
       "       (do): Dropout(p=0.2, inplace=False)\n",
       "     )\n",
       "     (phi): MLP_state(\n",
       "       (fc1): Linear(in_features=52, out_features=128, bias=True)\n",
       "       (relu): ReLU()\n",
       "       (do): Dropout(p=0.0, inplace=False)\n",
       "       (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "     )\n",
       "     (attention): CumulativeSetAttentionLayer(\n",
       "       (psi): MLP_state(\n",
       "         (fc1): Linear(in_features=52, out_features=64, bias=True)\n",
       "         (relu): ReLU()\n",
       "         (do): Dropout(p=0.0, inplace=False)\n",
       "         (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
       "       )\n",
       "       (rho): Linear(in_features=64, out_features=128, bias=True)\n",
       "     )\n",
       "     (rho): MLP_state(\n",
       "       (fc1): Linear(in_features=512, out_features=128, bias=True)\n",
       "       (relu): ReLU()\n",
       "       (do): Dropout(p=0.0, inplace=False)\n",
       "       (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "     )\n",
       "   )\n",
       "   (demo_encoder): Predictor(\n",
       "     (linear1): Linear(in_features=7, out_features=16, bias=True)\n",
       "     (linear2): Linear(in_features=16, out_features=16, bias=True)\n",
       "     (linear3): Linear(in_features=16, out_features=4, bias=True)\n",
       "     (relu): ReLU()\n",
       "     (do): Dropout(p=0.2, inplace=False)\n",
       "   )\n",
       "   (pred_label): Predictor(\n",
       "     (linear1): Linear(in_features=144, out_features=16, bias=True)\n",
       "     (linear2): Linear(in_features=16, out_features=16, bias=True)\n",
       "     (linear3): Linear(in_features=16, out_features=1, bias=True)\n",
       "     (relu): ReLU()\n",
       "     (do): Dropout(p=0.2, inplace=False)\n",
       "   )\n",
       "   (pred_next_time): Predictor(\n",
       "     (linear1): Linear(in_features=144, out_features=16, bias=True)\n",
       "     (linear2): Linear(in_features=16, out_features=16, bias=True)\n",
       "     (linear3): Linear(in_features=16, out_features=1, bias=True)\n",
       "     (relu): ReLU()\n",
       "     (do): Dropout(p=0.2, inplace=False)\n",
       "   )\n",
       "   (pred_next_type): Predictor(\n",
       "     (linear1): Linear(in_features=144, out_features=16, bias=True)\n",
       "     (linear2): Linear(in_features=16, out_features=16, bias=True)\n",
       "     (linear3): Linear(in_features=16, out_features=24, bias=True)\n",
       "     (relu): ReLU()\n",
       "     (do): Dropout(p=0.2, inplace=False)\n",
       "   )\n",
       " ),\n",
       " Namespace(data='/mlodata1/hokarami/tedam/p12-raindrop/split4/', data_label='multilabel', cuda=1, wandb=True, wandb_project='TEEDAM_supervised', log_freq=1, prof=False, per=100, balanced_batch=True, transfer_learning='', tl_tag='TL70', freeze='', ES_pat=100, setting='raindrop', test_center='', split='4', log='log.txt', user_prefix='[RD74-TL-TEDA__nextmark-concat]', pos_alpha=1.0, epoch=50, batch_size=128, lr=0.001, smooth=0.0, weight_decay=0.1, diag_offset=0, event_enc=1, time_enc='concat', te_d_mark=8, te_d_time=4, te_d_rnn=256, te_d_inner=32, te_d_k=8, te_d_v=8, te_n_head=4, te_n_layers=4, te_dropout=0.1, state=True, demo=True, num_states=35, noise=False, mod='none', int_dec='sahp', w_event=1.0, next_mark=1, w_class=False, w_pos=False, mark_detach=0, w_time=1.0, sample_label=True, w_pos_label=1.0, w_sample_label=100.0, hparams2write={'data': '/mlodata1/hokarami/tedam/p12/', 'data_label': 'multilabel', 'cuda': 1, 'wandb': True, 'wandb_project': 'TEEDAM_supervised', 'log_freq': 1, 'prof': False, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'tl_tag': 'TL70', 'freeze': '', 'ES_pat': 100, 'setting': 'raindrop', 'test_center': '', 'split': '4', 'log': 'log.txt', 'user_prefix': '[RD74-TL-TEDA__nextmark-concat]', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 128, 'lr': 0.001, 'smooth': 0.0, 'weight_decay': 0.1, 'diag_offset': 0, 'event_enc': 1, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 4, 'te_d_rnn': 256, 'te_d_inner': 32, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'noise': False, 'mod': 'none', 'int_dec': 'sahp', 'w_event': 1.0, 'next_mark': 1, 'w_class': False, 'w_pos': False, 'mark_detach': 0, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 1.0, 'w_sample_label': 100.0}, date='09-06-23--14-05-34', run_id='2651795', dataset='P12', str_config='-raindrop/split4', run_name='[RD74-TL-TEDA__nextmark-concat]2651795', run_path='/mlodata1/hokarami/tedam/p12-raindrop/split4/[RD74-TL-TEDA__nextmark-concat]2651795/', device=device(type='cuda'), INPUT='TEDAM', OUTPUT='none-mark-label', trainloader=<torch.utils.data.dataloader.DataLoader object at 0x7f62129de6a0>, validloader=<torch.utils.data.dataloader.DataLoader object at 0x7f62129de250>, testloader=<torch.utils.data.dataloader.DataLoader object at 0x7f6224014b20>, num_types=1, dict_map_events={'BUN': 0, 'Creatinine': 1, 'Glucose': 2, 'HCO3': 3, 'Na': 4, 'K': 5, 'Mg': 6, 'HCT': 7, 'Platelets': 8, 'WBC': 9, 'FiO2': 10, 'PaCO2': 11, 'PaO2': 12, 'pH': 13, 'SaO2': 14, 'ALP': 15, 'ALT': 16, 'AST': 17, 'Albumin': 18, 'Bilirubin': 19, 'Lactate': 20, 'Cholesterol': 21, 'TroponinI': 22, 'TroponinT': 23}, dict_map_states={'HR': 0, 'NIDiasABP': 1, 'NIMAP': 2, 'NISysABP': 3, 'RespRate': 4, 'Temp': 5, 'DiasABP': 6, 'MAP': 7, 'SysABP': 8, 'GCS': 9, 'Urine': 10, 'BUN': 11, 'Creatinine': 12, 'Glucose': 13, 'HCO3': 14, 'Na': 15, 'K': 16, 'Mg': 17, 'HCT': 18, 'Platelets': 19, 'WBC': 20, 'FiO2': 21, 'PaCO2': 22, 'PaO2': 23, 'pH': 24, 'SaO2': 25, 'ALP': 26, 'ALT': 27, 'AST': 28, 'Albumin': 29, 'Bilirubin': 30, 'Lactate': 31, 'Cholesterol': 32, 'TroponinI': 33, 'TroponinT': 34}, num_marks=24, pos_weight=tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1.], device='cuda:0'), num_demos=7, w=tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1.], device='cuda:0'), type_loss=<function type_loss_BCE at 0x7f622a0c21f0>, pred_loss_func=BCEWithLogitsLoss(), label_loss_fun=BCEWithLogitsLoss(), TE_config={'n_marks': 24, 'd_type_emb': 8, 'time_enc': 'concat', 'd_time': 4, 'd_inner': 32, 'n_layers': 4, 'n_head': 4, 'd_k': 8, 'd_v': 8, 'dropout': 0.1}, DAM_config={'output_activation': 'relu', 'output_dims': 16, 'n_phi_layers': 3, 'phi_width': 128, 'phi_dropout': 0.2, 'n_psi_layers': 2, 'psi_width': 64, 'psi_latent_width': 128, 'dot_prod_dim': 64, 'n_heads': 4, 'attn_dropout': 0.1, 'latent_width': 64, 'n_rho_layers': 2, 'rho_width': 128, 'rho_dropout': 0.1, 'max_timescale': 1000, 'n_positional_dims': 16, 'num_mods': 35, 'num_demos': 7, 'online': False}, NOISE_config={}, demo_config={'num_demos': 7, 'd_demo': 4}, CIF_config={}, next_type_config={'n_marks': 24, 'mark_detach': 0}, next_time_config=True, label_config={'sample_detach': 0}),\n",
       " <Run hokarami/TEEDAM_supervised/oevt2f3d (finished)>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_from_wandb(run_paths[0],consider_sample_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_knn=5\n",
    "pid_all = list(df1.index)\n",
    "\n",
    "pid_positive = list(df1[df1.color_true=='Positive Samples'].index)\n",
    "\n",
    "list_sim_score1 = []\n",
    "X1 = np.concatenate(out1['r_enc_list'],axis=0)[:,:model1.d_out_te]\n",
    "\n",
    "\n",
    "for pid in tqdm( pid_positive ):\n",
    "    id_origin = pid\n",
    "\n",
    "    knn_pids = find_knn_pids (X1, id_origin, n_knn=n_knn)\n",
    "    sim_score1, list_summary = cal_similarity(df1, out1, pid, knn_pids)    \n",
    "\n",
    "    \n",
    "    if ( not np.isnan(sim_score1) ) :\n",
    "        list_sim_score1.append(sim_score1)\n",
    "\n",
    "np.mean(list_sim_score1), np.std(list_sim_score1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = wandb.Api()\n",
    "run = api.run(run_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.summary['knn-ps-mean'] = np.mean(list_sim_score1)\n",
    "run.summary['knn-ps-std'] = np.std(list_sim_score1)\n",
    "run.summary.update()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compare\n",
    "\n",
    "P19-sc-H0-s3\n",
    "\n",
    "[H70HHG--DA__base-concat]2094041\n",
    "hokarami/TEEDAM_supervised/gl1y64zk\n",
    "\n",
    "[H70HHG--TEDA__none-concat]2096437\n",
    "hokarami/TEEDAM_supervised/b1u14qh0\n",
    "\n",
    "[H70HHG--TEDA__none-concat]2096437 no pre training\n",
    "hokarami/TEEDAM_supervised/mkue3rz4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_path = \"hokarami/TEEDAM_supervised/gl1y64zk\"\n",
    "\n",
    "model1, opt1, run1 = read_from_wandb(run_path,consider_sample_labels=True)\n",
    "dict_metrics1, out1 = Main.valid_epoch_tsne(model1, opt1.validloader, opt1.pred_loss_func, opt1)\n",
    "X_tsne1 = compute_tsne(out1['r_enc_list'], model1, TSNE_LIMIT=6000)\n",
    "\n",
    "res_labels = opt1.dict_map_events.keys()\n",
    "\n",
    "df1 = build_df(out1,opt1, X_tsne1['full'],TSNE_LIMIT=100000)\n",
    "fig_tsne1 = plot_tsne(df1,title=run1.name)\n",
    "\n",
    "\n",
    "print('Baseline: DAM model')\n",
    "fig_tsne1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_path = \"hokarami/TEEDAM_supervised/mkue3rz4\"\n",
    "\n",
    "model2, opt2, run2 = read_from_wandb(run_path,consider_sample_labels=True)\n",
    "dict_metrics2, out2 = Main.valid_epoch_tsne(model2, opt2.validloader, opt2.pred_loss_func, opt2)\n",
    "X_tsne2 = compute_tsne(out2['r_enc_list'], model2, TSNE_LIMIT=6000)\n",
    "\n",
    "res_labels = opt2.dict_map_events.keys()\n",
    "\n",
    "df2 = build_df(out2,opt2, X_tsne2['full'],TSNE_LIMIT=100000)\n",
    "fig_tsne2 = plot_tsne(df2,title=run2.name)\n",
    "\n",
    "\n",
    "print('Baseline: TEDAM model')\n",
    "fig_tsne2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = build_df(out2,opt2, X_tsne2['full'],TSNE_LIMIT=100000)\n",
    "fig_tsne2 = plot_tsne(df2,title=run2.name)\n",
    "\n",
    "\n",
    "print('Baseline: TEDAM model > full')\n",
    "fig_tsne2\n",
    "\n",
    "df2 = build_df(out2,opt2, X_tsne2['tee'],TSNE_LIMIT=100000)\n",
    "fig_tsne2 = plot_tsne(df2,title=run2.name)\n",
    "\n",
    "\n",
    "print('Baseline: TEDAM model > tee')\n",
    "fig_tsne2\n",
    "\n",
    "df2 = build_df(out2,opt2, X_tsne2['dam'],TSNE_LIMIT=100000)\n",
    "fig_tsne2 = plot_tsne(df2,title=run2.name)\n",
    "\n",
    "\n",
    "print('Baseline: TEDAM model > dam')\n",
    "fig_tsne2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sudo conda install -c conda-forge transformers datasets tokenizers --name paper2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(out1['event_type_list'])\n",
    "out1['event_type_list'][0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=out1['event_type_list'][0]\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out=out1\n",
    "df=df1\n",
    "i_b=0\n",
    "i=0\n",
    "\n",
    "ev = out['event_type_list'][i_b][i]\n",
    "t = out['event_time_list'][i_b][i]\n",
    "P = t.int().max().item() + 1\n",
    "m = (ev.sum(1)>0).sum() # False are masked\n",
    "\n",
    "ev = event2mat(ev,t,P)\n",
    "ev.shape\n",
    "ev.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ev=[]\n",
    "\n",
    "for pid in df['id']:\n",
    "    i_b = int(df.iloc[pid]['i_b'])\n",
    "    i = int(df.iloc[pid]['i'])\n",
    "\n",
    "    ev = out['event_type_list'][i_b][i]\n",
    "    t = out['event_time_list'][i_b][i]\n",
    "    P = t.int().max().item() + 1\n",
    "    m = (ev.sum(1)>0).sum() # False are masked\n",
    "\n",
    "    ev = event2mat(ev,t,P) # [M,L]\n",
    "    list_ev.append(ev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.concatenate(list_ev,axis=1)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_cols, unique_counts = np.unique(x, axis=1, return_counts=True)\n",
    "unique_cols.shape\n",
    "unique_counts.shape\n",
    "\n",
    "idx = np.argsort(-unique_counts)\n",
    "unique_counts = unique_counts[idx]\n",
    "unique_cols = unique_cols[:,idx]\n",
    "\n",
    "\n",
    "unique_counts = np.round(unique_counts/unique_counts.sum()*100,2)\n",
    "\n",
    "unique_counts[:10]\n",
    "unique_cols[:,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = list(opt1.dict_map_events.keys())\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ev[0].shape\n",
    "list_text = []\n",
    "for ev in list_ev[:]:\n",
    "    text = [] #[\"<CLS>\"]\n",
    "    for e in ev.transpose():\n",
    "        # e\n",
    "        measured = np.where(e==1.0)[0]\n",
    "        if np.any(measured):\n",
    "            temp=[d[i] for i in measured] + [\".\"]\n",
    "            text.extend( temp )\n",
    "        else:\n",
    "            text.extend([\"Nothing\",\".\"])\n",
    "    \n",
    "\n",
    "    list_text.append(\" \".join(text))\n",
    "    # ev.shape\n",
    "    # text = '<CLS> '\n",
    "list_text[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_inputs = [\n",
    "    \"I've been waiting for a HuggingFace course my whole life.\",\n",
    "    \"I hate this so much!\",\n",
    "]\n",
    "inputs = tokenizer(raw_inputs, padding=True, truncation=True)\n",
    "print(inputs)\n",
    "\n",
    "# raw_inputs =list_text\n",
    "# inputs = tokenizer(raw_inputs, padding=True, truncation=True)\n",
    "# len(inputs.input_ids)\n",
    "# len(inputs.input_ids[0])\n",
    "# inputs.input_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "tokenizer(\"Using a Transformer network is simple\")\n",
    "\n",
    "tokenizer.tokenize(\"Using a Transformer network is simple\")\n",
    "\n",
    "tokens = tokenizer.tokenize(list_text[0])\n",
    "tokens\n",
    "\n",
    "input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "input_ids\n",
    "\n",
    "inputs = tokenizer(list_text[0])\n",
    "\n",
    "tokenizer.decode(inputs['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(list_text)\n",
    "inputs['input_ids'][0]\n",
    "\n",
    "tokenizer.decode(inputs['input_ids'][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
    "sequences = [\"I've been waiting for a HuggingFace course my whole life.\", \"So have I!\"]\n",
    "\n",
    "tokens = tokenizer(sequences, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "output = model(**tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_tokens = tokenizer.tokenize(sequences[0])\n",
    " \n",
    "ex_ids = tokenizer.convert_tokens_to_ids(ex_tokens)\n",
    "ex_ids\n",
    "tokenizer.decode(ex_ids)\n",
    "\n",
    "tokens['input_ids'][0]\n",
    "tokenizer.decode(tokens['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(list_text)\n",
    "# inputs['input_ids'][0]\n",
    "\n",
    "tokenizer.decode(inputs['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "\n",
    "raw_datasets = load_dataset(\"glue\", \"mrpc\")\n",
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation=True)\n",
    "\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\"test-trainer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    metric = evaluate.load(\"glue\", \"mrpc\")\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = trainer.predict(tokenized_datasets[\"validation\"])\n",
    "print(predictions.predictions.shape, predictions.label_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.argmax(predictions.predictions, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"glue\", \"mrpc\")\n",
    "metric.compute(predictions=preds, references=predictions.label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df1\n",
    "out=out1\n",
    "opt=opt1\n",
    "\n",
    "vocab_list = list(opt.dict_map_events.keys())\n",
    "vocab_list = [x.lower() for x in vocab_list] + ['nothing','.']\n",
    "\n",
    "vocab_list\n",
    "\n",
    "# Open file in write mode\n",
    "with open('vocab_list.txt', 'w') as f:\n",
    "    # Convert list to a string and write to file\n",
    "    f.write('\\n'.join(map(str, vocab_list)))\n",
    "\n",
    "# Close file\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = build_df(out,opt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders=['trainloader','validloader','testloader']\n",
    "\n",
    "\n",
    "\n",
    "for loader in loaders:\n",
    "    _, out = Main.valid_epoch_tsne(model1, getattr(opt1,loader), opt1.pred_loss_func, opt1)\n",
    "    # X_tsne, X_tsne_split = compute_tsne(out1['r_enc_list'], model1)\n",
    "    len(out['event_type_list'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(out)\n",
    "\n",
    "len(out['event_type_list'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.keys()\n",
    "dict_temp = {v:k for k,v in opt.dict_map_states.items()}\n",
    "\n",
    "\n",
    "sv = out['state_value_list'][0][0]\n",
    "sm = out['state_mod_list'][0][0]\n",
    "st = out['state_time_list'][0][0]\n",
    "\n",
    "m = sm!=0\n",
    "\n",
    "q_H = sv[m]>2\n",
    "q_L = sv[m]<-2\n",
    "q = (q_H.int()-q_L.int()).tolist()\n",
    "\n",
    "dict_range = {-1:\"_L\", 0:\"_N\", 1:\"_H\"}\n",
    "q_range = [dict_range[x] for x in q]\n",
    "# q_range\n",
    "\n",
    "mods = (sm[m]-1).tolist()\n",
    "\n",
    "mods_final = [ dict_temp[int(mod)]+r for mod,r in zip(mods,q_range)]\n",
    "\n",
    "dot_indices = torch.nonzero( st[m].diff() ).flatten().tolist()\n",
    "elements_to_insert = [\".\" for i in dot_indices]\n",
    "\n",
    "k=1\n",
    "for i, e in zip(dot_indices, elements_to_insert):\n",
    "    \n",
    "    mods_final.insert(i+k, e)\n",
    "    k+=1\n",
    "\n",
    "mods_final\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## event data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders=['trainloader','validloader','testloader']\n",
    "\n",
    "\n",
    "\n",
    "for loader in loaders:\n",
    "    \n",
    "\n",
    "    _, out = Main.valid_epoch_tsne(model1, getattr(opt1,loader), opt1.pred_loss_func, opt1)\n",
    "    # X_tsne, X_tsne_split = compute_tsne(out1['r_enc_list'], model1)\n",
    "\n",
    "\n",
    "    # df = build_df(out,opt1)\n",
    "    # fig_tsne = plot_tsne(df,title=run1.name)\n",
    "\n",
    "\n",
    "\n",
    "    # a list of dictionaries {'mat'}\n",
    "    myData = []\n",
    "    N_patients = len(out['event_type_list']) * opt.batch_size\n",
    "    for pid in range(N_patients):\n",
    "        # i_b = int(df.iloc[pid]['i_b'])\n",
    "        # i = int(df.iloc[pid]['i'])\n",
    "        i_b, i = divmod(pid, opt.batch_size)\n",
    "\n",
    "        ev = out['event_type_list'][i_b][i]\n",
    "        t = out['event_time_list'][i_b][i]\n",
    "        P = t.int().max().item() + 1\n",
    "        m = (ev.sum(1)>0).sum() # False are masked\n",
    "        term\n",
    "        ev = event2mat(ev,t,P) # [M,L]\n",
    "        myData.append({'mat':ev})\n",
    "\n",
    "    len(myData)\n",
    "    myData[0]['mat'].shape\n",
    "\n",
    "\n",
    "\n",
    "    # add 'text' field to dict\n",
    "    # list_text = []\n",
    "    for sample in myData[:]:\n",
    "        text = [] #[\"<CLS>\"]\n",
    "        for e in sample['mat'].transpose(): # mat[L,K] e[K]\n",
    "            # e\n",
    "            measured = np.where(e==1.0)[0]\n",
    "            if np.any(measured):\n",
    "                temp=[vocab_list[i] for i in measured] #+ [\".\"]\n",
    "                temp[-1] += '.'\n",
    "                text.extend( temp )\n",
    "            else:\n",
    "                text.extend([\"nothing.\"])\n",
    "        \n",
    "        sample['text'] = \" \".join(text)\n",
    "        # list_text.append(\" \".join(text))\n",
    "        # ev.shape\n",
    "        # text = '<CLS> '\n",
    "\n",
    "    myData[0].keys()\n",
    "    myData[0]['text']\n",
    "\n",
    "\n",
    "\n",
    "    # saving\n",
    "\n",
    "    myData = [{'mat':sample['mat'].tolist(),'text':sample['text']} for sample in myData]\n",
    "\n",
    "    raw_data = \"\".join(  [x['text'] for x in myData]  )\n",
    "\n",
    "    import json\n",
    "\n",
    "    with open(f\"ehr_bert_data/{loader}.json\", \"w\") as fp:\n",
    "        json.dump(myData,fp) \n",
    "\n",
    "    # with open(f\"ehr_bert_data/{loader}.json\", \"w\") as fp:\n",
    "    #     json.dump(myData,fp) \n",
    "\n",
    "    with open(f\"ehr_bert_data/{loader}_raw.txt\", \"w\") as file:\n",
    "        file.write(raw_data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## state data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.keys()\n",
    "dict_temp = {v:k for k,v in opt.dict_map_states.items()}\n",
    "dict_range = {-1:\"_L\", 0:\"_N\", 1:\"_H\"}\n",
    "\n",
    "loaders=['trainloader','validloader','testloader']\n",
    "\n",
    "\n",
    "\n",
    "for loader in loaders:\n",
    "    \n",
    "\n",
    "    _, out = Main.valid_epoch_tsne(model1, getattr(opt1,loader), opt1.pred_loss_func, opt1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # a list of dictionaries {'mat'}\n",
    "    myData = []\n",
    "    N_patients = len(out['event_type_list']) * opt.batch_size\n",
    "    for pid in range(N_patients):\n",
    "        # i_b = int(df.iloc[pid]['i_b'])\n",
    "        # i = int(df.iloc[pid]['i'])\n",
    "        i_b, i = divmod(pid, opt.batch_size)\n",
    "\n",
    "        sv = out['state_value_list'][i_b][i]\n",
    "        sm = out['state_mod_list'][i_b][i]\n",
    "        st = out['state_time_list'][i_b][i]\n",
    "        m = sm!=0\n",
    "\n",
    "        q_H = sv[m]>2\n",
    "        q_L = sv[m]<-2\n",
    "        q = (q_H.int()-q_L.int()).tolist()\n",
    "\n",
    "        q_range = [dict_range[x] for x in q]\n",
    "        # q_range\n",
    "\n",
    "        mods = (sm[m]-1).tolist()\n",
    "\n",
    "        mods_final = [ dict_temp[int(mod)]+r for mod,r in zip(mods,q_range)]\n",
    "\n",
    "        dot_indices = torch.nonzero( st[m].diff() ).flatten().tolist()\n",
    "        elements_to_insert = [\".\" for i in dot_indices]\n",
    "\n",
    "        k=1\n",
    "        for i, e in zip(dot_indices, elements_to_insert):\n",
    "            \n",
    "            mods_final.insert(i+k, e)\n",
    "            k+=1\n",
    "\n",
    "        sample_string = \" \".join(mods_final).replace(\" .\",\".\")+\". DISCHARGE.\"\n",
    "        myData.append({'text':sample_string})\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "    # saving\n",
    "\n",
    "    myData = [{'text':sample['text']} for sample in myData]\n",
    "\n",
    "    raw_data = \"\".join(  [x['text'] for x in myData]  )\n",
    "\n",
    "    import json\n",
    "\n",
    "    with open(f\"ehr_states_llm_data/{loader}.json\", \"w\") as file:\n",
    "        json.dump(myData,file) \n",
    "\n",
    "    # with open(f\"ehr_states_llm_data/{loader}.json\", \"w\") as fp:\n",
    "    #     json.dump(myData,fp) \n",
    "\n",
    "    with open(f\"ehr_states_llm_data/{loader}_raw.txt\", \"w\") as file:\n",
    "        file.write(raw_data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\" \".join(mods_final).replace(\" .\",\".\")+\". DISCHARGE.\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ridi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.keys()\n",
    "dict_temp = {v:k for k,v in opt.dict_map_states.items()}\n",
    "dict_range = {-1:\"_L\", 0:\"_N\", 1:\"_H\"}\n",
    "\n",
    "loaders=['trainloader','validloader','testloader']\n",
    "\n",
    "\n",
    "\n",
    "for loader in loaders:\n",
    "    \n",
    "\n",
    "    _, out = Main.valid_epoch_tsne(model1, getattr(opt1,loader), opt1.pred_loss_func, opt1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # a list of dictionaries {'mat'}\n",
    "    myData = []\n",
    "    N_patients = len(out['event_type_list']) * opt.batch_size\n",
    "    for pid in range(N_patients):\n",
    "        # i_b = int(df.iloc[pid]['i_b'])\n",
    "        # i = int(df.iloc[pid]['i'])\n",
    "        i_b, i = divmod(pid, opt.batch_size)\n",
    "\n",
    "        sv = out['state_value_list'][i_b][i]\n",
    "        sm = out['state_mod_list'][i_b][i]\n",
    "        st = out['state_time_list'][i_b][i]\n",
    "        m = sm!=0\n",
    "\n",
    "        q_H = sv[m]>2\n",
    "        q_L = sv[m]<-2\n",
    "        q = (q_H.int()-q_L.int()).tolist()\n",
    "\n",
    "        q_range = [dict_range[x] for x in q]\n",
    "        # q_range\n",
    "\n",
    "        mods = (sm[m]-1).tolist()\n",
    "\n",
    "        mods_final = [ dict_temp[int(mod)]+r for mod,r in zip(mods,q_range)]\n",
    "\n",
    "        dot_indices = torch.nonzero( st[m].diff() ).flatten().tolist()\n",
    "        elements_to_insert = [\".\" for i in dot_indices]\n",
    "\n",
    "        k=1\n",
    "        for i, e in zip(dot_indices, elements_to_insert):\n",
    "            \n",
    "            mods_final.insert(i+k, e)\n",
    "            k+=1\n",
    "\n",
    "        sample_string = \" \".join(mods_final).replace(\" .\",\".\")+\". DISCHARGE.\"\n",
    "\n",
    "        \n",
    "        # added part\n",
    "        temp = sample_string.split(\". \")\n",
    "        # temp[0]\n",
    "        temp = [\"_\".join(x.split(\" \")) for x in temp]\n",
    "        # temp[0]\n",
    "\n",
    "        sample_string = \". \".join(temp)\n",
    "\n",
    "\n",
    "        myData.append({'text':sample_string})\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "    # saving\n",
    "\n",
    "    myData = [{'text':sample['text']} for sample in myData]\n",
    "\n",
    "    raw_data = \"\".join(  [x['text'] for x in myData]  )\n",
    "\n",
    "    import json\n",
    "\n",
    "    with open(f\"ehr_states_llm_data/{loader}_ridi.json\", \"w\") as file:\n",
    "        json.dump(myData,file) \n",
    "\n",
    "    # with open(f\"ehr_states_llm_data/{loader}_ridi.json\", \"w\") as fp:\n",
    "    #     json.dump(myData,fp) \n",
    "\n",
    "    with open(f\"ehr_states_llm_data/{loader}_ridi_raw.txt\", \"w\") as file:\n",
    "        file.write(raw_data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = sample_string.split(\". \")\n",
    "temp[0]\n",
    "temp = [\"_\".join(x.split(\" \")) for x in temp]\n",
    "temp[0]\n",
    "\n",
    "\". \".join(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "my_dataset = load_dataset(\"json\",\n",
    "    data_files={\n",
    "            \"train\": \"ehr_bert_data/trainloader.json\",\n",
    "            \"validation\": \"ehr_bert_data/validloader.json\",\n",
    "            \"test\": \"ehr_bert_data/testloader.json\",\n",
    "        })\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create TKZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/docs/tokenizers/pipeline\n",
    "\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import WordPiece, WordLevel\n",
    "bert_tokenizer = Tokenizer(WordPiece(unk_token=\"[UNK]\"))\n",
    "bert_tokenizer = Tokenizer(WordLevel(unk_token=\"[UNK]\"))\n",
    "\n",
    "from tokenizers import normalizers\n",
    "from tokenizers.normalizers import NFD, Lowercase, StripAccents\n",
    "bert_tokenizer.normalizer = normalizers.Sequence([NFD(), Lowercase(), StripAccents()])\n",
    "\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "bert_tokenizer.pre_tokenizer = Whitespace()\n",
    "\n",
    "from tokenizers.processors import TemplateProcessing\n",
    "bert_tokenizer.post_processor = TemplateProcessing(\n",
    "    single=\"[CLS] $A [SEP]\",\n",
    "    pair=\"[CLS] $A [SEP] $B:1 [SEP]:1\",\n",
    "    special_tokens=[\n",
    "        (\"[CLS]\", 1),\n",
    "        (\"[SEP]\", 2),\n",
    "    ],\n",
    ")\n",
    "\n",
    "from tokenizers.trainers import WordPieceTrainer, WordLevelTrainer\n",
    "# trainer = WordPieceTrainer(vocab_size=len(vocab_list), special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"])\n",
    "trainer = WordLevelTrainer(vocab_size=len(vocab_list), special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"])\n",
    "\n",
    "\n",
    "# files = [f\"data/wikitext-103-raw/wiki.{split}.raw\" for split in [\"test\", \"train\", \"valid\"]]\n",
    "\n",
    "files = [\"myData_raw.txt\"]\n",
    "bert_tokenizer.train(files, trainer)\n",
    "bert_tokenizer.save(\"bert-ehr-tkz.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(bert_tokenizer.get_vocab())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activate line execution\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# my_dataset = load_dataset(\"json\", data_files=\"myData.json\", split=\"train\")\n",
    "\n",
    "\n",
    "# my_dataset = load_dataset(\"json\",\n",
    "#     data_files={\n",
    "#             \"train\": \"ehr_bert_data/trainloader.json\",\n",
    "#             \"validation\": \"ehr_bert_data/validloader.json\",\n",
    "#             \"test\": \"ehr_bert_data/testloader.json\",\n",
    "#         })\n",
    "\n",
    "\n",
    "data_files={\n",
    "            \"train\": \"ehr_bert_data/trainloader.json\",\n",
    "            \"validation\": \"ehr_bert_data/validloader.json\",\n",
    "            \"test\": \"ehr_bert_data/testloader.json\",\n",
    "        }\n",
    "my_dataset = load_dataset(\"json\", data_files=data_files)\n",
    "\n",
    "my_dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sample = my_dataset[\"train\"].shuffle(seed=42).select(range(3))\n",
    "# sample = my_dataset.shuffle(seed=42).select(range(3))\n",
    "\n",
    "for row in sample:\n",
    "    print(f\"\\n'>>> text: {row['text']}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vocab_list.txt', 'r') as file:\n",
    "    content = file.read()\n",
    "    vocab_list = content.split()\n",
    "    print(vocab_list)\n",
    "\n",
    "len(vocab_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PreTrainedTokenizerFast, AutoTokenizer \n",
    "\n",
    "\n",
    "model_checkpoint = \"distilbert-base-uncased\"\n",
    "model_checkpoint = \"prajjwal1/bert-tiny\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "len(tokenizer.get_vocab())\n",
    "\n",
    "tokenizer.add_tokens(vocab_list)\n",
    "# tokenizer = PreTrainedTokenizerFast(\n",
    "#     # tokenizer_object=bert_tokenizer,\n",
    "#     tokenizer_file=\"bert-ehr-tkz.json\", # You can load from the tokenizer file, alternatively\n",
    "#     unk_token=\"[UNK]\",\n",
    "#     pad_token=\"[PAD]\",\n",
    "#     cls_token=\"[CLS]\",\n",
    "#     sep_token=\"[SEP]\",\n",
    "#     mask_token=\"[MASK]\",\n",
    "# )\n",
    "\n",
    "len(tokenizer.get_vocab())\n",
    "# tokenizer.get_vocab()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.tokenize(my_dataset['train'][0]['text'])\n",
    "# wrapped_tokenizer.tokenize(my_dataset[0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertConfig, BertModel, AutoModelForMaskedLM\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Initializing a BERT bert-base-uncased style configuration\n",
    "configuration = BertConfig(vocab_size = len(tokenizer.get_vocab()), hidden_size=32, num_hidden_layers=4, num_attention_heads=4, intermediate_size=128,  )\n",
    "\n",
    "\n",
    "# configuration = BertConfig()\n",
    "\n",
    "\n",
    "\n",
    "# Initializing a model (with random weights) from the bert-base-uncased style configuration\n",
    "model = AutoModelForMaskedLM.from_config(configuration)\n",
    "\n",
    "# Accessing the model configuration\n",
    "configuration = model.config\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_checkpoint = \"distilbert-base-uncased\"\n",
    "model_checkpoint = \"prajjwal1/bert-tiny\"\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_checkpoint)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    result = tokenizer(examples[\"text\"])\n",
    "    if tokenizer.is_fast:\n",
    "        result[\"word_ids\"] = [result.word_ids(i) for i in range(len(result[\"input_ids\"]))]\n",
    "    return result\n",
    "\n",
    "\n",
    "# Use batched=True to activate fast multithreading!\n",
    "tokenized_datasets = my_dataset.map(\n",
    "    tokenize_function, batched=True, remove_columns=['text', \"mat\"]\n",
    ")\n",
    "tokenized_datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 128\n",
    "\n",
    "# Slicing produces a list of lists for each feature\n",
    "# tokenized_samples = tokenized_datasets[\"train\"][:3]\n",
    "tokenized_samples = tokenized_datasets['train'][:3]\n",
    "\n",
    "\n",
    "for idx, sample in enumerate(tokenized_samples[\"input_ids\"]):\n",
    "    print(f\"'>>> Example {idx} length: {len(sample)}'\")\n",
    "\n",
    "tokenized_samples.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_examples = {\n",
    "    k: sum(tokenized_samples[k], []) for k in tokenized_samples.keys()\n",
    "}\n",
    "total_length = len(concatenated_examples[\"input_ids\"])\n",
    "print(f\"'>>> Concatenated reviews length: {total_length}'\")\n",
    "\n",
    "\n",
    "chunks = {\n",
    "    k: [t[i : i + chunk_size] for i in range(0, total_length, chunk_size)]\n",
    "    for k, t in concatenated_examples.items()\n",
    "}\n",
    "\n",
    "for chunk in chunks[\"input_ids\"]:\n",
    "    print(f\"'>>> Chunk length: {len(chunk)}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_texts(examples):\n",
    "    # Concatenate all texts\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    # Compute length of concatenated texts\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # We drop the last chunk if it's smaller than chunk_size\n",
    "    total_length = (total_length // chunk_size) * chunk_size\n",
    "    # Split by chunks of max_len\n",
    "    result = {\n",
    "        k: [t[i : i + chunk_size] for i in range(0, total_length, chunk_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    # Create a new labels column\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_datasets = tokenized_datasets.map(group_texts, batched=True)\n",
    "lm_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(lm_datasets['train'][1][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples = [lm_datasets[\"train\"][i] for i in range(2)]\n",
    "samples = [lm_datasets['train'][i] for i in range(2)]\n",
    "\n",
    "for sample in samples:\n",
    "    \n",
    "    _ = sample.pop(\"word_ids\")\n",
    "\n",
    "for chunk in data_collator(samples)[\"input_ids\"]:\n",
    "    print(f\"\\n'>>> {tokenizer.decode(chunk)}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import numpy as np\n",
    "\n",
    "from transformers import default_data_collator\n",
    "\n",
    "wwm_probability = 0.2\n",
    "\n",
    "\n",
    "def whole_word_masking_data_collator(features):\n",
    "    for feature in features:\n",
    "        word_ids = feature.pop(\"word_ids\")\n",
    "\n",
    "        # Create a map between words and corresponding token indices\n",
    "        mapping = collections.defaultdict(list)\n",
    "        current_word_index = -1\n",
    "        current_word = None\n",
    "        for idx, word_id in enumerate(word_ids):\n",
    "            if word_id is not None:\n",
    "                if word_id != current_word:\n",
    "                    current_word = word_id\n",
    "                    current_word_index += 1\n",
    "                mapping[current_word_index].append(idx)\n",
    "\n",
    "        # Randomly mask words\n",
    "        mask = np.random.binomial(1, wwm_probability, (len(mapping),))\n",
    "        input_ids = feature[\"input_ids\"]\n",
    "        labels = feature[\"labels\"]\n",
    "        new_labels = [-100] * len(labels)\n",
    "        for word_id in np.where(mask)[0]:\n",
    "            word_id = word_id.item()\n",
    "            for idx in mapping[word_id]:\n",
    "                new_labels[idx] = labels[idx]\n",
    "                input_ids[idx] = tokenizer.mask_token_id\n",
    "        feature[\"labels\"] = new_labels\n",
    "\n",
    "    return default_data_collator(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples = [lm_datasets[\"train\"][i] for i in range(2)]\n",
    "samples = [lm_datasets['train'][i] for i in range(2)]\n",
    "\n",
    "batch = whole_word_masking_data_collator(samples)\n",
    "\n",
    "for chunk in batch[\"input_ids\"]:\n",
    "    print(f\"\\n'>>> {tokenizer.decode(chunk)}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_size = 0.8\n",
    "# test_size = 0.2\n",
    "# # test_size = int(0.1 * train_size)\n",
    "\n",
    "# downsampled_dataset = lm_datasets.train_test_split(\n",
    "#     train_size=train_size, test_size=test_size, seed=42\n",
    "# )\n",
    "# downsampled_dataset\n",
    "\n",
    "downsampled_dataset=lm_datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "batch_size = 8\n",
    "# Show the training loss with every epoch\n",
    "logging_steps = len(downsampled_dataset[\"train\"]) // batch_size\n",
    "model_name = 'EHRpattern'\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"{model_name}-finetuned-imdb\",\n",
    "    overwrite_output_dir=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=2e-3,\n",
    "    weight_decay=0.1,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    push_to_hub=True,\n",
    "    fp16=True,\n",
    "    logging_steps=logging_steps,\n",
    "\n",
    "    dataloader_num_workers=0,\n",
    "    # debug='underflow_overflow',\n",
    "    \n",
    "    # use_multiprocessing=False,\n",
    "    # use_multiprocessing_for_evaluation=False,\n",
    ")\n",
    "\n",
    "training_args = training_args.set_optimizer(name=\"adamw_torch\", beta1=0.8)\n",
    "\n",
    "# torch.optim.AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\")\n",
    "device\n",
    "_ = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"HF_TOKEN\"] = \"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\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()\n",
    "\n",
    "# curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash\n",
    "# sudo apt-get install git-lfs\n",
    "\n",
    "# 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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=downsampled_dataset[\"train\"],\n",
    "    eval_dataset=downsampled_dataset[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "\n",
    "    \n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\">>> Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.num_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"./saved_models/ehr-distilbert-base-uncased\"\n",
    "model.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "mask_filler = pipeline(\n",
    "    \"fill-mask\", model=model, tokenizer=tokenizer,device=model.device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = my_dataset['train'][0]['text']\n",
    "text\n",
    "text = 'nothing. nothing. bun creatinine glucose hco3 na k mg [MASK] platelets wbc.'\n",
    "\n",
    "tokenizer.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = mask_filler(text)\n",
    "\n",
    "for pred in preds:\n",
    "    print(f\">>> {pred['sequence']}\\t\\t\\t{pred['score']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = my_dataset['train'][0]['text']\n",
    "text\n",
    "seq = text.replace(\".\", \" .\").split(\" \")\n",
    "\n",
    "for i in range(1,len(seq)):\n",
    "    if seq[i]=='.':\n",
    "        continue\n",
    "    temp = seq[:i+1].copy()\n",
    "    temp[i]= '[MASK]'\n",
    "    temp = ' '.join(temp).replace(\" .\", \".\")\n",
    "\n",
    "    # temp\n",
    "    # mask_filler(temp)\n",
    "    print(mask_filler(temp)[1]['token_str'], ' ### ', seq[i], '###', mask_filler(temp)[0]['score']) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/course/chapter7/3?fw=pt\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForMaskedLM\n",
    "\n",
    "model_checkpoint = \"distilbert-base-uncased\"\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_checkpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distilbert_num_parameters = model.num_parameters() / 1_000_000\n",
    "print(f\"'>>> DistilBERT number of parameters: {round(distilbert_num_parameters)}M'\")\n",
    "print(f\"'>>> BERT number of parameters: 110M'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "my_dataset = load_dataset(\"json\", data_files=\"myData.json\", split=\"train\")\n",
    "# my_dataset = load_dataset(\"imdb\")['train'].rename_column('label','mat')\n",
    "# my_dataset = my_dataset.remove_columns(['mat'])\n",
    "my_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample = my_dataset[\"train\"].shuffle(seed=42).select(range(3))\n",
    "sample = my_dataset.shuffle(seed=42).select(range(3))\n",
    "\n",
    "for row in sample:\n",
    "    print(f\"\\n'>>> text: {row['text']}'\")\n",
    "    # print(f\"'>>> Label: {row['label']}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "tokenizer.model_max_length\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    result = tokenizer(examples[\"text\"])\n",
    "    if tokenizer.is_fast:\n",
    "        result[\"word_ids\"] = [result.word_ids(i) for i in range(len(result[\"input_ids\"]))]\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "# Use batched=True to activate fast multithreading!\n",
    "tokenized_datasets = my_dataset.map(\n",
    "    tokenize_function, batched=True, remove_columns=['text', 'mat']\n",
    ")\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 128\n",
    "\n",
    "# Slicing produces a list of lists for each feature\n",
    "# tokenized_samples = tokenized_datasets[\"train\"][:3]\n",
    "tokenized_samples = tokenized_datasets[:3]\n",
    "\n",
    "\n",
    "for idx, sample in enumerate(tokenized_samples[\"input_ids\"]):\n",
    "    print(f\"'>>> Example {idx} length: {len(sample)}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_examples = {\n",
    "    k: sum(tokenized_samples[k], []) for k in tokenized_samples.keys()\n",
    "}\n",
    "total_length = len(concatenated_examples[\"input_ids\"])\n",
    "print(f\"'>>> Concatenated reviews length: {total_length}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = {\n",
    "    k: [t[i : i + chunk_size] for i in range(0, total_length, chunk_size)]\n",
    "    for k, t in concatenated_examples.items()\n",
    "}\n",
    "\n",
    "for chunk in chunks[\"input_ids\"]:\n",
    "    print(f\"'>>> Chunk length: {len(chunk)}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_texts(examples):\n",
    "    # Concatenate all texts\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    # Compute length of concatenated texts\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # We drop the last chunk if it's smaller than chunk_size\n",
    "    total_length = (total_length // chunk_size) * chunk_size\n",
    "    # Split by chunks of max_len\n",
    "    result = {\n",
    "        k: [t[i : i + chunk_size] for i in range(0, total_length, chunk_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    # Create a new labels column\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_datasets = tokenized_datasets.map(group_texts, batched=True)\n",
    "lm_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.decode(lm_datasets[\"train\"][1][\"input_ids\"])\n",
    "tokenizer.decode(lm_datasets[1][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples = [lm_datasets[\"train\"][i] for i in range(2)]\n",
    "samples = [lm_datasets[i] for i in range(2)]\n",
    "\n",
    "for sample in samples:\n",
    "    \n",
    "    _ = sample.pop(\"word_ids\")\n",
    "\n",
    "for chunk in data_collator(samples)[\"input_ids\"]:\n",
    "    print(f\"\\n'>>> {tokenizer.decode(chunk)}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import numpy as np\n",
    "\n",
    "from transformers import default_data_collator\n",
    "\n",
    "wwm_probability = 0.2\n",
    "\n",
    "\n",
    "def whole_word_masking_data_collator(features):\n",
    "    for feature in features:\n",
    "        word_ids = feature.pop(\"word_ids\")\n",
    "\n",
    "        # Create a map between words and corresponding token indices\n",
    "        mapping = collections.defaultdict(list)\n",
    "        current_word_index = -1\n",
    "        current_word = None\n",
    "        for idx, word_id in enumerate(word_ids):\n",
    "            if word_id is not None:\n",
    "                if word_id != current_word:\n",
    "                    current_word = word_id\n",
    "                    current_word_index += 1\n",
    "                mapping[current_word_index].append(idx)\n",
    "\n",
    "        # Randomly mask words\n",
    "        mask = np.random.binomial(1, wwm_probability, (len(mapping),))\n",
    "        input_ids = feature[\"input_ids\"]\n",
    "        labels = feature[\"labels\"]\n",
    "        new_labels = [-100] * len(labels)\n",
    "        for word_id in np.where(mask)[0]:\n",
    "            word_id = word_id.item()\n",
    "            for idx in mapping[word_id]:\n",
    "                new_labels[idx] = labels[idx]\n",
    "                input_ids[idx] = tokenizer.mask_token_id\n",
    "        feature[\"labels\"] = new_labels\n",
    "\n",
    "    return default_data_collator(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples = [lm_datasets[\"train\"][i] for i in range(2)]\n",
    "samples = [lm_datasets[i] for i in range(2)]\n",
    "\n",
    "batch = whole_word_masking_data_collator(samples)\n",
    "\n",
    "for chunk in batch[\"input_ids\"]:\n",
    "    print(f\"\\n'>>> {tokenizer.decode(chunk)}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.8\n",
    "test_size = 0.2\n",
    "# test_size = int(0.1 * train_size)\n",
    "\n",
    "downsampled_dataset = lm_datasets.train_test_split(\n",
    "    train_size=train_size, test_size=test_size, seed=42\n",
    ")\n",
    "downsampled_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "batch_size = 8\n",
    "# Show the training loss with every epoch\n",
    "logging_steps = len(downsampled_dataset[\"train\"]) // batch_size\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"{model_name}-finetuned-imdb\",\n",
    "    overwrite_output_dir=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    num_train_epochs=1,\n",
    "    learning_rate=2e-4,\n",
    "    weight_decay=0.01,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    push_to_hub=False,\n",
    "    fp16=True,\n",
    "    logging_steps=logging_steps,\n",
    "\n",
    "    dataloader_num_workers=0,\n",
    "    # debug='underflow_overflow',\n",
    "\n",
    "    # report_to=None\n",
    "    \n",
    "    # use_multiprocessing=False,\n",
    "    # use_multiprocessing_for_evaluation=False,\n",
    ")\n",
    "\n",
    "training_args = training_args.set_optimizer(name=\"adamw_torch\", beta1=0.8)\n",
    "\n",
    "# torch.optim.AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "device\n",
    "_ = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()\n",
    "\n",
    "# curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash\n",
    "# sudo apt-get install git-lfs\n",
    "\n",
    "# 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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=downsampled_dataset[\"train\"],\n",
    "    eval_dataset=downsampled_dataset[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "\n",
    "    # optimizers=(torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9),\n",
    "    #                 None\n",
    "    #                 )\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\">>> Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sudo conda create --name hf python=3.9\n",
    "\n",
    "sudo conda install -c anaconda ipykernel  --name hf\n",
    "\n",
    "sudo conda install pytorch torchvision torchaudio pytorch-cuda=11.7 -c pytorch -c nvidia --name hf\n",
    "\n",
    "sudo conda install -c conda-forge transformers datasets tokenizers --name hf\n",
    "\n",
    "\n",
    "sudo conda install -c conda-forge wandb --name hf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paper2022",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ca5b395ee1d8a1cd2783c3fccc5aaaf2f1d95e614c8b133e284cded792af89cd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
