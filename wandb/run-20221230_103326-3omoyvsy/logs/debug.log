2022-12-30 10:33:26,891 INFO    MainThread:28680 [wandb_setup.py:_flush():68] Configure stats pid to 28680
2022-12-30 10:33:26,891 INFO    MainThread:28680 [wandb_setup.py:_flush():68] Loading settings from C:\Users\hokarami\.config\wandb\settings
2022-12-30 10:33:26,891 INFO    MainThread:28680 [wandb_setup.py:_flush():68] Loading settings from C:\DATA\Tasks\220702\codes\thp_final\wandb\settings
2022-12-30 10:33:26,891 INFO    MainThread:28680 [wandb_setup.py:_flush():68] Loading settings from environment variables: {'_require_service': 'True', 'api_key': '***REDACTED***'}
2022-12-30 10:33:26,891 INFO    MainThread:28680 [wandb_setup.py:_flush():68] Inferring run settings from compute environment: {'program_relpath': 'optuna1.py', 'program': 'C:\\DATA\\Tasks\\220702\\codes\\thp_final\\optuna1.py'}
2022-12-30 10:33:26,901 INFO    MainThread:28680 [wandb_init.py:_log_setup():476] Logging user logs to C:\DATA\Tasks\220702\codes\thp_final\wandb\run-20221230_103326-3omoyvsy\logs\debug.log
2022-12-30 10:33:26,902 INFO    MainThread:28680 [wandb_init.py:_log_setup():477] Logging internal logs to C:\DATA\Tasks\220702\codes\thp_final\wandb\run-20221230_103326-3omoyvsy\logs\debug-internal.log
2022-12-30 10:33:26,902 INFO    MainThread:28680 [wandb_init.py:init():516] calling init triggers
2022-12-30 10:33:26,903 INFO    MainThread:28680 [wandb_init.py:init():519] wandb.init called with sweep_config: {}
config: {'data': 'C:/DATA/data/processed/p12_full_seft/', 'data_label': 'multilabel', 'cuda': False, 'wandb': True, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'freeze': '', 'log': 'log.txt', 'user_prefix': '[Opt]DA__label-', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 32, 'lr': 5.046463218919207e-05, 'smooth': 0.0, 'event_enc': 0, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 8, 'te_d_rnn': 256, 'te_d_inner': 16, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 35, 'w_sample_label': 100.0, 'mod': 'none', 'int_dec': 'sahp', 'w_event': 1, 'next_mark': 0, 'w_class': False, 'w_pos': True, 'mark_detach': 0, 'w_time': 1.0, 'sample_label': 1, 'hparams2write': {'data': 'C:/DATA/data/processed/p12_full_seft/', 'data_label': 'multilabel', 'cuda': False, 'wandb': True, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'freeze': '', 'log': 'log.txt', 'user_prefix': '[Opt]DA__label-', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 8, 'lr': 0.00245, 'smooth': 0.0, 'event_enc': 0, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 8, 'te_d_rnn': 256, 'te_d_inner': 16, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'w_sample_label': 100.0, 'mod': 'none', 'int_dec': 'sahp', 'w_event': 1, 'next_mark': 0, 'w_class': False, 'w_pos': True, 'mark_detach': 0, 'w_time': 1.0, 'sample_label': 1}, 'date': '30-12-22--10-33-12', 'run_id': '1043799', 'str_config': '-none-state1-per100', 'run_name': '[Opt]DA__label-1043799-none-state1-per100', 'run_folder': 'C:/DATA/data/processed/p12_full_seft/[Opt]DA__label-1043799-none-state1-per100/', 'device': device(type='cpu'), 'trainloader': <torch.utils.data.dataloader.DataLoader object at 0x000002638FC2C880>, 'testloader': <torch.utils.data.dataloader.DataLoader object at 0x000002638FC2C850>, 'num_marks': 25, 'pos_weight': tensor([13.3299, 13.2649, 14.2023, 13.6398,  9.8851, 12.6716, 13.6233, 13.6036,
        13.0283,  0.4717, 14.3766,  5.2823,  7.6584,  7.6795, 23.9278,  7.2796,
        50.0000, 50.0000, 50.0000, 50.0000, 50.0000, 23.5461, 50.0000, 50.0000,
        50.0000], dtype=torch.float64), 'num_demos': 4, 'w': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1.]), 'type_loss': <function type_loss_BCE at 0x0000026387253AF0>, 'pred_loss_func': BCEWithLogitsLoss(), 'TE_config': {}, 'DAM_config': {'output_activation': 'relu', 'output_dims': 4, 'n_phi_layers': 3, 'phi_width': 32, 'phi_dropout': 0.1, 'n_psi_layers': 2, 'psi_width': 32, 'psi_latent_width': 64, 'dot_prod_dim': 64, 'n_heads': 2, 'attn_dropout': 0.1, 'latent_width': 16, 'n_rho_layers': 2, 'rho_width': 256, 'rho_dropout': 0.1, 'max_timescale': 1000, 'n_positional_dims': 8, 'num_mods': 35, 'num_demos': 4, 'online': False}, 'demo_config': {'num_demos': 4, 'd_demo': 4}, 'CIF_config': {}, 'next_type_config': {}, 'next_time_config': True, 'label_config': 1, 'hparams': {'lr': 5.046463218919207e-05, 'batch_size': 32, 'dot_prod_dim': 64, 'n_heads': 2, 'latent_width': 16, 'rho_width': 256, 'trial.number': 0}}
2022-12-30 10:33:26,903 INFO    MainThread:28680 [wandb_init.py:init():569] starting backend
2022-12-30 10:33:26,903 INFO    MainThread:28680 [wandb_init.py:init():573] setting up manager
2022-12-30 10:33:26,911 INFO    MainThread:28680 [backend.py:_multiprocessing_setup():102] multiprocessing start_methods=spawn, using: spawn
2022-12-30 10:33:26,920 INFO    MainThread:28680 [wandb_init.py:init():580] backend started and connected
2022-12-30 10:33:26,927 INFO    MainThread:28680 [wandb_init.py:init():658] updated telemetry
2022-12-30 10:33:26,971 INFO    MainThread:28680 [wandb_init.py:init():693] communicating run to backend with 60 second timeout
2022-12-30 10:33:27,416 INFO    MainThread:28680 [wandb_run.py:_on_init():2006] communicating current version
2022-12-30 10:33:27,518 INFO    MainThread:28680 [wandb_run.py:_on_init():2010] got version response 
2022-12-30 10:33:27,518 INFO    MainThread:28680 [wandb_init.py:init():728] starting run threads in backend
2022-12-30 10:33:28,736 INFO    MainThread:28680 [wandb_run.py:_console_start():1986] atexit reg
2022-12-30 10:33:28,737 INFO    MainThread:28680 [wandb_run.py:_redirect():1844] redirect: SettingsConsole.WRAP_RAW
2022-12-30 10:33:28,737 INFO    MainThread:28680 [wandb_run.py:_redirect():1909] Wrapping output streams.
2022-12-30 10:33:28,737 INFO    MainThread:28680 [wandb_run.py:_redirect():1931] Redirects installed.
2022-12-30 10:33:28,737 INFO    MainThread:28680 [wandb_init.py:init():765] run started, returning control to user process
