2023-01-03 14:00:48,987 INFO    MainThread:18836 [wandb_setup.py:_flush():68] Configure stats pid to 18836
2023-01-03 14:00:48,988 INFO    MainThread:18836 [wandb_setup.py:_flush():68] Loading settings from C:\Users\hokarami\.config\wandb\settings
2023-01-03 14:00:48,988 INFO    MainThread:18836 [wandb_setup.py:_flush():68] Loading settings from C:\DATA\Tasks\220702\codes\thp_final\wandb\settings
2023-01-03 14:00:48,988 INFO    MainThread:18836 [wandb_setup.py:_flush():68] Loading settings from environment variables: {'_require_service': 'True', 'api_key': '***REDACTED***'}
2023-01-03 14:00:48,988 INFO    MainThread:18836 [wandb_setup.py:_flush():68] Inferring run settings from compute environment: {'program_relpath': 'Main.py', 'program': 'C:\\DATA\\Tasks\\220702\\codes\\thp_final\\Main.py'}
2023-01-03 14:00:48,989 INFO    MainThread:18836 [wandb_init.py:_log_setup():476] Logging user logs to C:\DATA\Tasks\220702\codes\thp_final\wandb\run-20230103_140048-3pf7wn4m\logs\debug.log
2023-01-03 14:00:48,989 INFO    MainThread:18836 [wandb_init.py:_log_setup():477] Logging internal logs to C:\DATA\Tasks\220702\codes\thp_final\wandb\run-20230103_140048-3pf7wn4m\logs\debug-internal.log
2023-01-03 14:00:48,990 INFO    MainThread:18836 [wandb_init.py:init():516] calling init triggers
2023-01-03 14:00:49,007 INFO    MainThread:18836 [wandb_init.py:init():519] wandb.init called with sweep_config: {}
config: {'data': 'C:/DATA/data/processed/p12_full_hosp/', 'data_label': 'multilabel', 'cuda': True, 'wandb': True, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'freeze': '', 'log': 'log.txt', 'user_prefix': '[hosp1]DA__label-', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 8, 'lr': 0.00245, 'smooth': 0.0, 'event_enc': 0, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 8, 'te_d_rnn': 256, 'te_d_inner': 16, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 35, 'w_sample_label': 100.0, 'mod': 'none', 'int_dec': 'sahp', 'w_event': 1, 'next_mark': 0, 'w_class': False, 'w_pos': True, 'mark_detach': 0, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 1.0, 'hparams2write': {'data': 'C:/DATA/data/processed/p12_full_hosp/', 'data_label': 'multilabel', 'cuda': True, 'wandb': True, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'freeze': '', 'log': 'log.txt', 'user_prefix': '[hosp1]DA__label-', 'pos_alpha': 1.0, 'epoch': 50, 'batch_size': 8, 'lr': 0.00245, 'smooth': 0.0, 'event_enc': 0, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 8, 'te_d_rnn': 256, 'te_d_inner': 16, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': True, 'num_states': 1, 'w_sample_label': 100.0, 'mod': 'none', 'int_dec': 'sahp', 'w_event': 1, 'next_mark': 0, 'w_class': False, 'w_pos': True, 'mark_detach': 0, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 1.0}, 'date': '03-01-23--14-00-26', 'run_id': '1085042', 'str_config': '-none-state1-per100', 'run_name': '[hosp1]DA__label-1085042-none-state1-per100', 'run_folder': 'C:/DATA/data/processed/p12_full_hosp/[hosp1]DA__label-1085042-none-state1-per100/', 'device': device(type='cuda'), 'trainloader': <torch.utils.data.dataloader.DataLoader object at 0x000001CB2E1030A0>, 'validloader': <torch.utils.data.dataloader.DataLoader object at 0x000001CB1B298670>, 'testloader': <torch.utils.data.dataloader.DataLoader object at 0x000001CB2C404F70>, 'num_marks': 25, 'pos_weight': tensor([13.3299, 13.2649, 14.2023, 13.6398,  9.8851, 12.6716, 13.6233, 13.6036,
        13.0283,  0.4717, 14.3766,  5.2823,  7.6584,  7.6795, 23.9278,  7.2796,
        50.0000, 50.0000, 50.0000, 50.0000, 50.0000, 23.5461, 50.0000, 50.0000,
        50.0000], device='cuda:0', dtype=torch.float64), 'num_demos': 4, 'w': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1.], device='cuda:0'), 'type_loss': <function type_loss_BCE at 0x000001CB23AD0A60>, 'pred_loss_func': BCEWithLogitsLoss(), 'label_loss_fun': BCEWithLogitsLoss(), 'TE_config': {}, 'DAM_config': {'output_activation': 'relu', 'output_dims': 4, 'n_phi_layers': 3, 'phi_width': 32, 'phi_dropout': 0.8, 'n_psi_layers': 2, 'psi_width': 32, 'psi_latent_width': 64, 'dot_prod_dim': 16, 'n_heads': 2, 'attn_dropout': 0.8, 'latent_width': 16, 'n_rho_layers': 2, 'rho_width': 256, 'rho_dropout': 0.8, 'max_timescale': 1000, 'n_positional_dims': 8, 'num_mods': 35, 'num_demos': 4, 'online': False}, 'demo_config': {'num_demos': 4, 'd_demo': 4}, 'CIF_config': {}, 'next_type_config': {}, 'next_time_config': True, 'label_config': 1}
2023-01-03 14:00:49,007 INFO    MainThread:18836 [wandb_init.py:init():569] starting backend
2023-01-03 14:00:49,007 INFO    MainThread:18836 [wandb_init.py:init():573] setting up manager
2023-01-03 14:00:49,016 INFO    MainThread:18836 [backend.py:_multiprocessing_setup():102] multiprocessing start_methods=spawn, using: spawn
2023-01-03 14:00:49,026 INFO    MainThread:18836 [wandb_init.py:init():580] backend started and connected
2023-01-03 14:00:49,038 INFO    MainThread:18836 [wandb_init.py:init():658] updated telemetry
2023-01-03 14:00:49,091 INFO    MainThread:18836 [wandb_init.py:init():693] communicating run to backend with 60 second timeout
2023-01-03 14:00:49,515 INFO    MainThread:18836 [wandb_run.py:_on_init():2006] communicating current version
2023-01-03 14:00:49,594 INFO    MainThread:18836 [wandb_run.py:_on_init():2010] got version response 
2023-01-03 14:00:49,594 INFO    MainThread:18836 [wandb_init.py:init():728] starting run threads in backend
2023-01-03 14:00:50,071 INFO    MainThread:18836 [wandb_run.py:_console_start():1986] atexit reg
2023-01-03 14:00:50,072 INFO    MainThread:18836 [wandb_run.py:_redirect():1844] redirect: SettingsConsole.WRAP_RAW
2023-01-03 14:00:50,072 INFO    MainThread:18836 [wandb_run.py:_redirect():1909] Wrapping output streams.
2023-01-03 14:00:50,072 INFO    MainThread:18836 [wandb_run.py:_redirect():1931] Redirects installed.
2023-01-03 14:00:50,073 INFO    MainThread:18836 [wandb_init.py:init():765] run started, returning control to user process
