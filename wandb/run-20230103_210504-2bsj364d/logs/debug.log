2023-01-03 21:05:04,641 INFO    MainThread:16124 [wandb_setup.py:_flush():68] Configure stats pid to 16124
2023-01-03 21:05:04,641 INFO    MainThread:16124 [wandb_setup.py:_flush():68] Loading settings from C:\Users\hokarami\.config\wandb\settings
2023-01-03 21:05:04,641 INFO    MainThread:16124 [wandb_setup.py:_flush():68] Loading settings from C:\DATA\Tasks\220702\codes\thp_final\wandb\settings
2023-01-03 21:05:04,641 INFO    MainThread:16124 [wandb_setup.py:_flush():68] Loading settings from environment variables: {'_require_service': 'True', 'api_key': '***REDACTED***'}
2023-01-03 21:05:04,641 INFO    MainThread:16124 [wandb_setup.py:_flush():68] Inferring run settings from compute environment: {'program_relpath': 'Main.py', 'program': 'C:\\DATA\\Tasks\\220702\\codes\\thp_final\\Main.py'}
2023-01-03 21:05:04,651 INFO    MainThread:16124 [wandb_init.py:_log_setup():476] Logging user logs to C:\DATA\Tasks\220702\codes\thp_final\wandb\run-20230103_210504-2bsj364d\logs\debug.log
2023-01-03 21:05:04,651 INFO    MainThread:16124 [wandb_init.py:_log_setup():477] Logging internal logs to C:\DATA\Tasks\220702\codes\thp_final\wandb\run-20230103_210504-2bsj364d\logs\debug-internal.log
2023-01-03 21:05:04,652 INFO    MainThread:16124 [wandb_init.py:init():516] calling init triggers
2023-01-03 21:05:04,665 INFO    MainThread:16124 [wandb_init.py:init():519] wandb.init called with sweep_config: {}
config: {'data': 'C:/DATA/data/processed/physio2019_1d_HP_std_AB/', 'data_label': 'multilabel', 'cuda': True, 'wandb': True, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'freeze': '', 'ES_pat': 30, 'log': 'log.txt', 'user_prefix': '[t1wd0-sgd]DA__label-', 'pos_alpha': 1.0, 'epoch': 30, 'batch_size': 8, 'lr': 0.00245, 'smooth': 0.0, 'event_enc': 0, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 8, 'te_d_rnn': 256, 'te_d_inner': 16, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': False, 'num_states': 29, 'w_sample_label': 100.0, 'mod': 'none', 'int_dec': 'sahp', 'w_event': 1, 'next_mark': 0, 'w_class': False, 'w_pos': True, 'mark_detach': 0, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 1.0, 'hparams2write': {'data': 'C:/DATA/data/processed/physio2019_1d_HP_std_AB/', 'data_label': 'multilabel', 'cuda': True, 'wandb': True, 'per': 100, 'balanced_batch': True, 'transfer_learning': '', 'freeze': '', 'ES_pat': 30, 'log': 'log.txt', 'user_prefix': '[t1wd0-sgd]DA__label-', 'pos_alpha': 1.0, 'epoch': 30, 'batch_size': 8, 'lr': 0.00245, 'smooth': 0.0, 'event_enc': 0, 'time_enc': 'concat', 'te_d_mark': 8, 'te_d_time': 8, 'te_d_rnn': 256, 'te_d_inner': 16, 'te_d_k': 8, 'te_d_v': 8, 'te_n_head': 4, 'te_n_layers': 4, 'te_dropout': 0.1, 'state': True, 'demo': False, 'num_states': 1, 'w_sample_label': 100.0, 'mod': 'none', 'int_dec': 'sahp', 'w_event': 1, 'next_mark': 0, 'w_class': False, 'w_pos': True, 'mark_detach': 0, 'w_time': 1.0, 'sample_label': 1, 'w_pos_label': 1.0}, 'date': '03-01-23--21-04-35', 'run_id': '1087587', 'str_config': '-none-state1-per100', 'run_name': '[t1wd0-sgd]DA__label-1087587-none-state1-per100', 'run_folder': 'C:/DATA/data/processed/physio2019_1d_HP_std_AB/[t1wd0-sgd]DA__label-1087587-none-state1-per100/', 'device': device(type='cuda'), 'trainloader': <torch.utils.data.dataloader.DataLoader object at 0x00000295D45D86D0>, 'validloader': <torch.utils.data.dataloader.DataLoader object at 0x00000295E5704F10>, 'testloader': <torch.utils.data.dataloader.DataLoader object at 0x00000295E5704EB0>, 'num_marks': 22, 'pos_weight': tensor([ 1.9162,  2.6021,  3.4605,  6.2849,  0.6980,  2.3589,  2.1721,  3.1090,
         5.2682,  3.5249,  5.8624,  3.7737,  3.8557,  4.2128,  4.3085,  6.5311,
         4.3013,  8.6554,  8.2214, 17.8121, 17.6680, 19.6713], device='cuda:0',
       dtype=torch.float64), 'num_demos': 0, 'w': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1.], device='cuda:0'), 'type_loss': <function type_loss_BCE at 0x00000295DCD63AF0>, 'pred_loss_func': BCEWithLogitsLoss(), 'label_loss_fun': BCEWithLogitsLoss(), 'TE_config': {}, 'DAM_config': {'output_activation': 'relu', 'output_dims': 4, 'n_phi_layers': 3, 'phi_width': 32, 'phi_dropout': 0.8, 'n_psi_layers': 2, 'psi_width': 32, 'psi_latent_width': 64, 'dot_prod_dim': 16, 'n_heads': 2, 'attn_dropout': 0.8, 'latent_width': 16, 'n_rho_layers': 2, 'rho_width': 256, 'rho_dropout': 0.8, 'max_timescale': 1000, 'n_positional_dims': 8, 'num_mods': 29, 'num_demos': 0, 'online': False}, 'demo_config': {}, 'CIF_config': {}, 'next_type_config': {}, 'next_time_config': True, 'label_config': 1}
2023-01-03 21:05:04,665 INFO    MainThread:16124 [wandb_init.py:init():569] starting backend
2023-01-03 21:05:04,665 INFO    MainThread:16124 [wandb_init.py:init():573] setting up manager
2023-01-03 21:05:04,673 INFO    MainThread:16124 [backend.py:_multiprocessing_setup():102] multiprocessing start_methods=spawn, using: spawn
2023-01-03 21:05:04,692 INFO    MainThread:16124 [wandb_init.py:init():580] backend started and connected
2023-01-03 21:05:04,700 INFO    MainThread:16124 [wandb_init.py:init():658] updated telemetry
2023-01-03 21:05:04,754 INFO    MainThread:16124 [wandb_init.py:init():693] communicating run to backend with 60 second timeout
2023-01-03 21:05:05,242 INFO    MainThread:16124 [wandb_run.py:_on_init():2006] communicating current version
2023-01-03 21:05:05,313 INFO    MainThread:16124 [wandb_run.py:_on_init():2010] got version response 
2023-01-03 21:05:05,313 INFO    MainThread:16124 [wandb_init.py:init():728] starting run threads in backend
2023-01-03 21:05:05,554 INFO    MainThread:16124 [wandb_run.py:_console_start():1986] atexit reg
2023-01-03 21:05:05,555 INFO    MainThread:16124 [wandb_run.py:_redirect():1844] redirect: SettingsConsole.WRAP_RAW
2023-01-03 21:05:05,555 INFO    MainThread:16124 [wandb_run.py:_redirect():1909] Wrapping output streams.
2023-01-03 21:05:05,555 INFO    MainThread:16124 [wandb_run.py:_redirect():1931] Redirects installed.
2023-01-03 21:05:05,556 INFO    MainThread:16124 [wandb_init.py:init():765] run started, returning control to user process
